{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dist_rl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/dist_rl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBVV8hQizHTI",
        "colab_type": "code",
        "outputId": "71bf65a5-5a83-47ec-e8d5-fff6ec77b0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive\n",
        "%load_ext Cython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prD6-LCFQYzW",
        "colab_type": "code",
        "outputId": "6d3b7852-10f4-41ae-f5df-07ad4bff8714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.16.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ta) (0.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->ta) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfuucG8nABQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ape_x import *\n",
        "import os\n",
        "import multiprocessing as mp\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil\n",
        "from multiprocessing import Pool\n",
        "from functools import lru_cache\n",
        "\n",
        "df = \"audpred15.csv\"\n",
        "\n",
        "_ = shutil.copy(\"/content/drive/My Drive/\"+df,\"/content\")\n",
        "# sac_one_step.ckpt\n",
        "# saver_path = \"td3\"\n",
        "saver_path = \"sac1\"\n",
        "\n",
        "restore = False\n",
        "\n",
        "# if restore == True:\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/\" + saver_path + \".data-00000-of-00001\",\"/content\")\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/\" + saver_path + \".index\",\"/content\")\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/checkpoint\",\"/content\")\n",
        "  \n",
        "# if restore == True:\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/model/\" + saver_path + \".data-00000-of-00001\",\"/content\")\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/model/\"+ saver_path + \".index\",\"/content\")\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/model/checkpoint\",\"/content\")\n",
        "\n",
        "output_size = 3\n",
        "window_size = 30\n",
        "size = 96\n",
        "num_actor = 3\n",
        "mem_size = size * num_actor * 5000\n",
        "  \n",
        "def actor_work(queues, num):\n",
        "  sess = tf.compat.v1.Session()\n",
        "  actor = Actor(sess, df, window_size, num, size, output_size, saver_path, restore)\n",
        "  actor.run(10, queues, 10, 1000,100,24,n=2,step=1)\n",
        "\n",
        "device='/device:GPU:0'\n",
        "# device = '/cpu:0'\n",
        "\n",
        "def leaner_work(queues):\n",
        "        sess = tf.compat.v1.Session()\n",
        "        leaner = Leaner(sess, df, window_size, output_size,mem_size, device, saver_path, restore)\n",
        "        leaner.leaner(queues)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FBIJ0z4zKf7",
        "colab_type": "code",
        "outputId": "9574b049-20f5-408a-848f-a7a3605c3d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content\n",
        "import concurrent.futures as futures\n",
        "# \n",
        "executor = futures.ThreadPoolExecutor(max_workers=num_actor+1)\n",
        "queue = mp.Queue()\n",
        "\n",
        "ps = [executor.submit(leaner_work, queue)]\n",
        "\n",
        "for i in range(num_actor):\n",
        "  ps.append(executor.submit(actor_work,queue,i))\n",
        "\n",
        "for p in ps:\n",
        "  p.result()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/memory.py:127: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  max_weight = (p_min * n) ** (-self.PER_b)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "action probability =  [0.7473684210526316, 0.11578947368421053, 0.13684210526315788]\n",
            "buy =  0.8421052631578947  sell =  0.1578947368421053\n",
            "trade accuracy =  0.3448275862068966\n",
            "epoch: 1, total rewards: -122.000000, mean rewards: -30.821053\n",
            "action probability =  [0.7473684210526316, 0.10526315789473684, 0.1473684210526316]\n",
            "buy =  0.8842105263157894  sell =  0.11578947368421055\n",
            "trade accuracy =  0.25806451612903225\n",
            "epoch: 11, total rewards: -682.000000, mean rewards: -172.294737\n",
            "action probability =  [0.7157894736842105, 0.1368421052631579, 0.1473684210526316]\n",
            "buy =  0.8526315789473684  sell =  0.1473684210526316\n",
            "trade accuracy =  0.18421052631578946\n",
            "epoch: 21, total rewards: -817.000000, mean rewards: -206.400000\n",
            "action probability =  [0.8210526315789474, 0.10526315789473684, 0.0736842105263158]\n",
            "buy =  0.8842105263157894  sell =  0.11578947368421055\n",
            "trade accuracy =  0.3076923076923077\n",
            "epoch: 31, total rewards: -180.000000, mean rewards: -45.473684\n",
            "action probability =  [0.7368421052631579, 0.16842105263157894, 0.09473684210526323]\n",
            "buy =  0.7894736842105263  sell =  0.21052631578947367\n",
            "trade accuracy =  0.53125\n",
            "epoch: 41, total rewards: 3640.000000, mean rewards: 919.578947\n",
            "action probability =  [0.7263157894736842, 0.15789473684210525, 0.11578947368421044]\n",
            "buy =  0.8105263157894737  sell =  0.18947368421052635\n",
            "trade accuracy =  0.4444444444444444\n",
            "epoch: 51, total rewards: 368.000000, mean rewards: 92.968421\n",
            "action probability =  [0.24210526315789474, 0.37894736842105264, 0.3789473684210526]\n",
            "buy =  0.3684210526315789  sell =  0.631578947368421\n",
            "trade accuracy =  0.27419354838709675\n",
            "epoch: 61, total rewards: -1644.000000, mean rewards: -415.326316\n",
            "action probability =  [0.29473684210526313, 0.3473684210526316, 0.35789473684210527]\n",
            "buy =  0.42105263157894735  sell =  0.5789473684210527\n",
            "trade accuracy =  0.4\n",
            "epoch: 71, total rewards: 654.000000, mean rewards: 165.221053\n",
            "action probability =  [0.3368421052631579, 0.30526315789473685, 0.35789473684210527]\n",
            "buy =  0.5894736842105263  sell =  0.41052631578947374\n",
            "trade accuracy =  0.2878787878787879\n",
            "epoch: 81, total rewards: -439.000000, mean rewards: -110.905263\n",
            "action probability =  [0.3263157894736842, 0.30526315789473685, 0.368421052631579]\n",
            "buy =  0.5052631578947369  sell =  0.49473684210526314\n",
            "trade accuracy =  0.3611111111111111\n",
            "epoch: 91, total rewards: -701.000000, mean rewards: -177.094737\n",
            "action probability =  [0.35789473684210527, 0.24210526315789474, 0.4]\n",
            "buy =  0.5894736842105263  sell =  0.41052631578947374\n",
            "trade accuracy =  0.4576271186440678\n",
            "epoch: 101, total rewards: 223.000000, mean rewards: 56.336842\n",
            "action probability =  [0.3157894736842105, 0.3263157894736842, 0.35789473684210527]\n",
            "buy =  0.5052631578947369  sell =  0.49473684210526314\n",
            "trade accuracy =  0.3442622950819672\n",
            "epoch: 111, total rewards: -123.000000, mean rewards: -31.073684\n",
            "action probability =  [0.031578947368421054, 0.021052631578947368, 0.9473684210526316]\n",
            "buy =  0.6947368421052632  sell =  0.3052631578947368\n",
            "trade accuracy =  0.25274725274725274\n",
            "epoch: 121, total rewards: -806.000000, mean rewards: -203.621053\n",
            "action probability =  [0.07368421052631578, 0.010526315789473684, 0.9157894736842105]\n",
            "buy =  0.8736842105263158  sell =  0.12631578947368416\n",
            "trade accuracy =  0.20930232558139536\n",
            "epoch: 131, total rewards: -2278.000000, mean rewards: -575.494737\n",
            "action probability =  [0.05263157894736842, 0.0, 0.9473684210526316]\n",
            "buy =  0.9578947368421052  sell =  0.04210526315789476\n",
            "trade accuracy =  0.4186046511627907\n",
            "epoch: 141, total rewards: 13155.000000, mean rewards: 3323.368421\n",
            "action probability =  [0.042105263157894736, 0.0, 0.9578947368421052]\n",
            "buy =  0.3368421052631579  sell =  0.6631578947368422\n",
            "trade accuracy =  0.14814814814814814\n",
            "epoch: 151, total rewards: -1348.000000, mean rewards: -340.547368\n",
            "action probability =  [0.42105263157894735, 0.47368421052631576, 0.10526315789473695]\n",
            "buy =  0.49473684210526314  sell =  0.5052631578947369\n",
            "trade accuracy =  0.22727272727272727\n",
            "epoch: 161, total rewards: -1074.000000, mean rewards: -271.326316\n",
            "action probability =  [0.3684210526315789, 0.5157894736842106, 0.11578947368421044]\n",
            "buy =  0.42105263157894735  sell =  0.5789473684210527\n",
            "trade accuracy =  0.3269230769230769\n",
            "epoch: 171, total rewards: -1314.000000, mean rewards: -331.957895\n",
            "action probability =  [0.4105263157894737, 0.45263157894736844, 0.13684210526315788]\n",
            "buy =  0.47368421052631576  sell =  0.5263157894736843\n",
            "trade accuracy =  0.22727272727272727\n",
            "epoch: 181, total rewards: -963.000000, mean rewards: -243.284211\n",
            "action probability =  [0.24210526315789474, 0.3263157894736842, 0.43157894736842106]\n",
            "buy =  0.4631578947368421  sell =  0.5368421052631579\n",
            "trade accuracy =  0.32786885245901637\n",
            "epoch: 191, total rewards: -9.000000, mean rewards: -2.273684\n",
            "action probability =  [0.28421052631578947, 0.30526315789473685, 0.41052631578947363]\n",
            "buy =  0.5473684210526316  sell =  0.4526315789473684\n",
            "trade accuracy =  0.3448275862068966\n",
            "epoch: 201, total rewards: -1049.000000, mean rewards: -265.010526\n",
            "action probability =  [0.22105263157894736, 0.35789473684210527, 0.42105263157894735]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.2413793103448276\n",
            "epoch: 211, total rewards: -817.000000, mean rewards: -206.400000\n",
            "action probability =  [0.42105263157894735, 0.18947368421052632, 0.3894736842105263]\n",
            "buy =  0.6631578947368421  sell =  0.33684210526315794\n",
            "trade accuracy =  0.40625\n",
            "epoch: 221, total rewards: -594.000000, mean rewards: -150.063158\n",
            "action probability =  [0.42105263157894735, 0.15789473684210525, 0.42105263157894735]\n",
            "buy =  0.7473684210526316  sell =  0.25263157894736843\n",
            "trade accuracy =  0.5344827586206896\n",
            "epoch: 231, total rewards: 4055.000000, mean rewards: 1024.421053\n",
            "action probability =  [0.5263157894736842, 0.17894736842105263, 0.2947368421052632]\n",
            "buy =  0.7789473684210526  sell =  0.2210526315789474\n",
            "trade accuracy =  0.34545454545454546\n",
            "epoch: 241, total rewards: -129.000000, mean rewards: -32.589474\n",
            "action probability =  [0.4, 0.37894736842105264, 0.2210526315789474]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.34\n",
            "epoch: 251, total rewards: 128.000000, mean rewards: 32.336842\n",
            "action probability =  [0.3894736842105263, 0.3368421052631579, 0.27368421052631575]\n",
            "buy =  0.6  sell =  0.4\n",
            "trade accuracy =  0.3409090909090909\n",
            "epoch: 261, total rewards: -437.000000, mean rewards: -110.400000\n",
            "action probability =  [0.37894736842105264, 0.4, 0.2210526315789474]\n",
            "buy =  0.5157894736842106  sell =  0.4842105263157894\n",
            "trade accuracy =  0.3137254901960784\n",
            "epoch: 271, total rewards: -598.000000, mean rewards: -151.073684\n",
            "action probability =  [0.37894736842105264, 0.4, 0.2210526315789474]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.19672131147540983\n",
            "epoch: 281, total rewards: -1658.000000, mean rewards: -418.863158\n",
            "action probability =  [0.7263157894736842, 0.08421052631578947, 0.18947368421052624]\n",
            "buy =  0.9157894736842105  sell =  0.08421052631578951\n",
            "trade accuracy =  0.34375\n",
            "epoch: 291, total rewards: -163.000000, mean rewards: -41.178947\n",
            "action probability =  [0.631578947368421, 0.08421052631578947, 0.28421052631578947]\n",
            "buy =  0.8842105263157894  sell =  0.11578947368421055\n",
            "trade accuracy =  0.23255813953488372\n",
            "epoch: 301, total rewards: -1186.000000, mean rewards: -299.621053\n",
            "action probability =  [0.6842105263157895, 0.07368421052631578, 0.2421052631578947]\n",
            "buy =  0.9263157894736842  sell =  0.0736842105263158\n",
            "trade accuracy =  0.2777777777777778\n",
            "epoch: 311, total rewards: -651.000000, mean rewards: -164.463158\n",
            "action probability =  [0.23157894736842105, 0.24210526315789474, 0.5263157894736842]\n",
            "buy =  0.42105263157894735  sell =  0.5789473684210527\n",
            "trade accuracy =  0.43283582089552236\n",
            "epoch: 321, total rewards: 431.000000, mean rewards: 108.884211\n",
            "action probability =  [0.1368421052631579, 0.30526315789473685, 0.5578947368421052]\n",
            "buy =  0.37894736842105264  sell =  0.6210526315789473\n",
            "trade accuracy =  0.29577464788732394\n",
            "epoch: 331, total rewards: -1313.000000, mean rewards: -331.705263\n",
            "action probability =  [0.17894736842105263, 0.21052631578947367, 0.6105263157894737]\n",
            "buy =  0.45263157894736844  sell =  0.5473684210526315\n",
            "trade accuracy =  0.3684210526315789\n",
            "epoch: 341, total rewards: -284.000000, mean rewards: -71.747368\n",
            "action probability =  [0.5473684210526316, 0.010526315789473684, 0.44210526315789467]\n",
            "buy =  0.9789473684210527  sell =  0.021052631578947323\n",
            "trade accuracy =  0.2222222222222222\n",
            "epoch: 351, total rewards: -1295.000000, mean rewards: -327.157895\n",
            "action probability =  [0.49473684210526314, 0.031578947368421054, 0.4736842105263158]\n",
            "buy =  0.9578947368421052  sell =  0.04210526315789476\n",
            "trade accuracy =  0.40816326530612246\n",
            "epoch: 361, total rewards: 500.000000, mean rewards: 126.315789\n",
            "action probability =  [0.47368421052631576, 0.021052631578947368, 0.5052631578947369]\n",
            "buy =  0.9263157894736842  sell =  0.0736842105263158\n",
            "trade accuracy =  0.34\n",
            "epoch: 371, total rewards: 194.000000, mean rewards: 49.010526\n",
            "action probability =  [0.06315789473684211, 0.021052631578947368, 0.9157894736842105]\n",
            "buy =  0.8842105263157894  sell =  0.11578947368421055\n",
            "trade accuracy =  0.3058823529411765\n",
            "epoch: 381, total rewards: 1339.000000, mean rewards: 338.273684\n",
            "action probability =  [0.09473684210526316, 0.042105263157894736, 0.8631578947368421]\n",
            "buy =  0.5157894736842106  sell =  0.4842105263157894\n",
            "trade accuracy =  0.3625\n",
            "epoch: 391, total rewards: -383.000000, mean rewards: -96.757895\n",
            "action probability =  [0.12631578947368421, 0.042105263157894736, 0.8315789473684211]\n",
            "buy =  0.7368421052631579  sell =  0.26315789473684215\n",
            "trade accuracy =  0.29411764705882354\n",
            "epoch: 401, total rewards: -2121.000000, mean rewards: -535.831579\n",
            "action probability =  [0.08421052631578947, 0.06315789473684211, 0.8526315789473684]\n",
            "buy =  0.5368421052631579  sell =  0.4631578947368421\n",
            "trade accuracy =  0.1375\n",
            "epoch: 411, total rewards: -3963.000000, mean rewards: -1001.178947\n",
            "action probability =  [0.4421052631578947, 0.3684210526315789, 0.18947368421052635]\n",
            "buy =  0.5473684210526316  sell =  0.4526315789473684\n",
            "trade accuracy =  0.28846153846153844\n",
            "epoch: 421, total rewards: -22.000000, mean rewards: -5.557895\n",
            "action probability =  [0.3684210526315789, 0.4631578947368421, 0.16842105263157903]\n",
            "buy =  0.42105263157894735  sell =  0.5789473684210527\n",
            "trade accuracy =  0.32432432432432434\n",
            "epoch: 431, total rewards: 137.000000, mean rewards: 34.610526\n",
            "action probability =  [0.37894736842105264, 0.4631578947368421, 0.1578947368421053]\n",
            "buy =  0.4842105263157895  sell =  0.5157894736842106\n",
            "trade accuracy =  0.4444444444444444\n",
            "epoch: 441, total rewards: -39.000000, mean rewards: -9.852632\n",
            "action probability =  [0.14736842105263157, 0.0, 0.8526315789473684]\n",
            "buy =  1.0  sell =  0.0\n",
            "trade accuracy =  0.23170731707317074\n",
            "epoch: 451, total rewards: -3430.000000, mean rewards: -866.526316\n",
            "action probability =  [0.29473684210526313, 0.031578947368421054, 0.6736842105263159]\n",
            "buy =  0.9263157894736842  sell =  0.0736842105263158\n",
            "trade accuracy =  0.19696969696969696\n",
            "epoch: 461, total rewards: -1904.000000, mean rewards: -481.010526\n",
            "action probability =  [0.29473684210526313, 0.05263157894736842, 0.6526315789473685]\n",
            "buy =  0.9052631578947369  sell =  0.09473684210526312\n",
            "trade accuracy =  0.14705882352941177\n",
            "epoch: 471, total rewards: -2418.000000, mean rewards: -610.863158\n",
            "action probability =  [0.2, 0.10526315789473684, 0.6947368421052631]\n",
            "buy =  0.4842105263157895  sell =  0.5157894736842106\n",
            "trade accuracy =  0.34615384615384615\n",
            "epoch: 481, total rewards: 1179.000000, mean rewards: 297.852632\n",
            "action probability =  [0.28421052631578947, 0.07368421052631578, 0.6421052631578947]\n",
            "buy =  0.5473684210526316  sell =  0.4526315789473684\n",
            "trade accuracy =  0.2982456140350877\n",
            "epoch: 491, total rewards: -1121.000000, mean rewards: -283.200000\n",
            "action probability =  [0.21052631578947367, 0.15789473684210525, 0.631578947368421]\n",
            "buy =  0.4421052631578947  sell =  0.5578947368421052\n",
            "trade accuracy =  0.18309859154929578\n",
            "epoch: 501, total rewards: -2590.000000, mean rewards: -654.315789\n",
            "action probability =  [0.47368421052631576, 0.12631578947368421, 0.4]\n",
            "buy =  0.6631578947368421  sell =  0.33684210526315794\n",
            "trade accuracy =  0.3090909090909091\n",
            "epoch: 511, total rewards: 1275.000000, mean rewards: 322.105263\n",
            "action probability =  [0.5157894736842106, 0.11578947368421053, 0.36842105263157887]\n",
            "buy =  0.7684210526315789  sell =  0.2315789473684211\n",
            "trade accuracy =  0.46808510638297873\n",
            "epoch: 521, total rewards: 1799.000000, mean rewards: 454.484211\n",
            "action probability =  [0.45263157894736844, 0.1368421052631579, 0.41052631578947363]\n",
            "buy =  0.6842105263157895  sell =  0.3157894736842105\n",
            "trade accuracy =  0.46551724137931033\n",
            "epoch: 531, total rewards: 1975.000000, mean rewards: 498.947368\n",
            "action probability =  [0.3473684210526316, 0.47368421052631576, 0.17894736842105263]\n",
            "buy =  0.45263157894736844  sell =  0.5473684210526315\n",
            "trade accuracy =  0.4090909090909091\n",
            "epoch: 541, total rewards: 1652.000000, mean rewards: 417.347368\n",
            "action probability =  [0.30526315789473685, 0.43157894736842106, 0.26315789473684204]\n",
            "buy =  0.4631578947368421  sell =  0.5368421052631579\n",
            "trade accuracy =  0.5319148936170213\n",
            "epoch: 551, total rewards: 2227.000000, mean rewards: 562.610526\n",
            "action probability =  [0.2736842105263158, 0.5684210526315789, 0.1578947368421053]\n",
            "buy =  0.3473684210526316  sell =  0.6526315789473685\n",
            "trade accuracy =  0.34\n",
            "epoch: 561, total rewards: -514.000000, mean rewards: -129.852632\n",
            "action probability =  [0.2631578947368421, 0.5052631578947369, 0.2315789473684211]\n",
            "buy =  0.35789473684210527  sell =  0.6421052631578947\n",
            "trade accuracy =  0.28888888888888886\n",
            "epoch: 571, total rewards: 630.000000, mean rewards: 159.157895\n",
            "action probability =  [0.2, 0.07368421052631578, 0.7263157894736842]\n",
            "buy =  0.8526315789473684  sell =  0.1473684210526316\n",
            "trade accuracy =  0.691358024691358\n",
            "epoch: 581, total rewards: 41153.000000, mean rewards: 10396.547368\n",
            "action probability =  [0.14736842105263157, 0.11578947368421053, 0.736842105263158]\n",
            "buy =  0.7368421052631579  sell =  0.26315789473684215\n",
            "trade accuracy =  0.30864197530864196\n",
            "epoch: 591, total rewards: -1193.000000, mean rewards: -301.389474\n",
            "action probability =  [0.1368421052631579, 0.08421052631578947, 0.7789473684210526]\n",
            "buy =  0.5368421052631579  sell =  0.4631578947368421\n",
            "trade accuracy =  0.3\n",
            "epoch: 601, total rewards: 3035.000000, mean rewards: 766.736842\n",
            "action probability =  [0.3684210526315789, 0.21052631578947367, 0.42105263157894735]\n",
            "buy =  0.6105263157894737  sell =  0.3894736842105263\n",
            "trade accuracy =  0.4032258064516129\n",
            "epoch: 611, total rewards: 2323.000000, mean rewards: 586.863158\n",
            "action probability =  [0.3263157894736842, 0.2736842105263158, 0.3999999999999999]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.20634920634920634\n",
            "epoch: 621, total rewards: -1605.000000, mean rewards: -405.473684\n",
            "action probability =  [0.3157894736842105, 0.21052631578947367, 0.4736842105263158]\n",
            "buy =  0.5578947368421052  sell =  0.4421052631578948\n",
            "trade accuracy =  0.288135593220339\n",
            "epoch: 631, total rewards: 2785.000000, mean rewards: 703.578947\n",
            "action probability =  [0.8421052631578947, 0.031578947368421054, 0.12631578947368427]\n",
            "buy =  0.9473684210526315  sell =  0.052631578947368474\n",
            "trade accuracy =  0.2\n",
            "epoch: 641, total rewards: -461.000000, mean rewards: -116.463158\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}