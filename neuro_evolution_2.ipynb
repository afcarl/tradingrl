{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuro evolution 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/neuro_evolution_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXpyhGyC4Cpk",
        "colab_type": "code",
        "outputId": "7e9a4e82-ae37-42a8-8ac7-73dabab073bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQVZCJv4FBu",
        "colab_type": "code",
        "outputId": "466a109f-d885-499c-8052-17ced15ac11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.16.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.24.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ta) (0.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->ta) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecmHJge38IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from numba import jit as njit\n",
        "from functools import lru_cache\n",
        "from multiprocessing import Pool\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import ta\n",
        "from net import *\n",
        "from memory import *\n",
        "from reward import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aanxg75uPulp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class neuralnetwork:\n",
        "    def __init__(self, id_, hidden_size = 128*1, window_size = 30, total=False):\n",
        "        if not total:\n",
        "          self.W1 = np.random.randn(window_size, hidden_size)# / np.sqrt(window_size)\n",
        "          self.W2 = np.random.randn(hidden_size, hidden_size)# / np.sqrt(hidden_size)\n",
        "          self.W3 = np.random.randn(hidden_size, 3)# / np.sqrt(hidden_size)\n",
        "        else:\n",
        "          self.W1 = np.random.randn(6,12)\n",
        "          self.W2 = np.random.randn(12,24)\n",
        "          self.W3 = np.random.randn(24,3)\n",
        "        self.fitness_list = []\n",
        "        self.fitness = 0\n",
        "        self.id = id_\n",
        "\n",
        "\n",
        "\n",
        "@njit\n",
        "def gaussiandropout(w,rate,train=True):\n",
        "  if train:\n",
        "    if 0. < rate < 1.:\n",
        "      scale = np.sqrt(rate / (1. - rate))\n",
        "      w *= np.random.normal(1.,scale,w.shape)\n",
        "  return w\n",
        "\n",
        "# @njit\n",
        "def sigmoid(x):\n",
        "  x = 1 / (1 + expit(-x))\n",
        "  return x\n",
        "\n",
        "# @njit\n",
        "def swish(x):\n",
        "  x *= sigmoid(x)\n",
        "  return x\n",
        " \n",
        "def relu(X):\n",
        "    return np.maximum(X, 0)\n",
        "  \n",
        "# @njit\n",
        "def softmax(X):\n",
        "    e_x = np.exp(X - np.max(X, axis=-1, keepdims=True))\n",
        "    e_x /= np.sum(e_x, axis=-1, keepdims=True)\n",
        "    return e_x\n",
        "  \n",
        "@njit\n",
        "def pred(x,nets):\n",
        "    a1 = np.dot(x, nets.W1)\n",
        "    z1 = swish(a1)\n",
        "    a2 = np.dot(z1,nets.W2)\n",
        "    z2 = swish(a2)\n",
        "    a3 = np.dot(z2, nets.W3)\n",
        "    return np.tanh(a3)\n",
        "\n",
        "@njit\n",
        "def feed_forward(X, nets1, nets2, nets3, rate=0.2, train=True):\n",
        "    X = X.flatten().reshape(1,-1)\n",
        "    # w1 = gaussiandropout(nets.W1,rate,train)\n",
        "    o1 = pred(X,nets1)\n",
        "    o2 = pred(X,nets2)\n",
        "    o = np.concatenate([o1,o2],1)\n",
        "    o = pred(o,nets3)\n",
        "\n",
        "    return o"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqWr3GfJCnzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuroEvolution:\n",
        "    def __init__(self, population_size, mutation_rate, model_generator, state_size, window_size, path, step_size, spread=10, pip_cost=1000, los_cut=20,restore=False):\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.mutation_rate_origin = mutation_rate\n",
        "        self.model_generator = model_generator\n",
        "        self.state_size = state_size\n",
        "        self.window_size = window_size\n",
        "        self.path = path\n",
        "        self.step_size = step_size\n",
        "        self.spread = spread / pip_cost\n",
        "        self.pip_cost = pip_cost\n",
        "        self.los_cut = los_cut\n",
        "        self.restore = restore\n",
        "        self.preproc()\n",
        "        self.rewards = reward3\n",
        "        self.fittest_individual = None\n",
        "        \n",
        "    def preproc(self):\n",
        "          self.dat = df = pd.read_csv(self.path)\n",
        "          s = np.asanyarray(ta.stoch(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1)) - np.asanyarray(ta.stoch_signal(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1))\n",
        "          x = np.asanyarray(ta.daily_log_return(df[\"Close\"])).reshape((-1,1))\n",
        "          m = np.asanyarray(ta.macd_diff(df[\"Close\"])).reshape((-1,1))\n",
        "          # x = m\n",
        "          x = np.concatenate([m,s,x], 1)\n",
        "          y = np.asanyarray(self.dat[[\"Open\"]])\n",
        "\n",
        "          gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x, y, self.window_size)\n",
        "          self.x = []\n",
        "          self.y = []\n",
        "          for i in gen:\n",
        "              self.x.extend(i[0].tolist())\n",
        "              self.y.extend(i[1].tolist())\n",
        "          self.x = np.asanyarray(self.x)\n",
        "          self.y = np.asanyarray(self.y)\n",
        "\n",
        "          self.df = self.x[-self.step_size::]\n",
        "          self.trend = self.y[-self.step_size::]\n",
        "\n",
        "    def _initialize_population(self,total=False):\n",
        "        population = []\n",
        "        for i in range(self.population_size):\n",
        "            population.append(self.model_generator(i,window_size = self.window_size*self.df.shape[-1], total=total))\n",
        "        return population\n",
        "\n",
        "    def mutate(self, individual, scale=1.0):\n",
        "      if np.random.random() < 0.01:\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W1.shape)\n",
        "        individual.W1 += np.random.normal(loc=0, scale=scale, size=individual.W1.shape) * mutation_mask\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W2.shape)\n",
        "        individual.W2 += np.random.normal(loc=0, scale=scale, size=individual.W2.shape) * mutation_mask\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W3.shape)\n",
        "        individual.W3 += np.random.normal(loc=0, scale=scale, size=individual.W3.shape) * mutation_mask\n",
        "      return individual\n",
        "    \n",
        "    def inherit_weights(self, parent, child):\n",
        "        child.W1 = parent.W1.copy()\n",
        "        child.W2 = parent.W2.copy()\n",
        "        child.W3 = parent.W3.copy()\n",
        "        return child\n",
        "    \n",
        "    def crossover(self, parent1, parent2):\n",
        "        child1 = self.model_generator((parent1.id+1)*10)\n",
        "        child1 = self.inherit_weights(parent1, child1)\n",
        "        child2 = self.model_generator((parent2.id+1)*10)\n",
        "        child2 = self.inherit_weights(parent2, child2)\n",
        "        # first W\n",
        "        n_neurons = child1.W1.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W1[:, cutoff:] = parent2.W1[:, cutoff:].copy()\n",
        "        child2.W1[:, cutoff:] = parent1.W1[:, cutoff:].copy()\n",
        "        # second W\n",
        "        n_neurons = child1.W2.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W2[:, cutoff:] = parent2.W2[:, cutoff:].copy()\n",
        "        child2.W2[:, cutoff:] = parent1.W2[:, cutoff:].copy()\n",
        "        # third W\n",
        "        n_neurons = child1.W3.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W3[:, cutoff:] = parent2.W3[:, cutoff:].copy()\n",
        "        child2.W3[:, cutoff:] = parent1.W3[:, cutoff:].copy()\n",
        "        return child1, child2\n",
        "    \n",
        "    def act(self, n1,n2,n3, state, rate=0.2,train=True):\n",
        "        logits = feed_forward(state, n1,n2,n3, rate, train)\n",
        "        return np.argmax(logits, 1)[0]\n",
        "#         return np.argmax(logits[0])\n",
        "    \n",
        "    def test(self, individual_acc, individual_min, individual_sum, i):\n",
        "        states = []\n",
        "        pip = []\n",
        "        history = []\n",
        "        h_p = []\n",
        "        provisional_pip = []\n",
        "        total_pip = 0.0\n",
        "        position = 3\n",
        "        h = np.random.randint(100,self.x.shape[0]-(self.step_size+1))\n",
        "        self.df = self.x[h:h+self.step_size]\n",
        "        self.trend = self.y[h:h+self.step_size]\n",
        "        for t in range(0, len(self.trend) - 1):\n",
        "            action = self.act(individual_acc, individual_min, individual_sum, self.df[t], train=False)\n",
        "            history.append(action)\n",
        "            states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,action,\n",
        "                                                                     position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/1000)\n",
        "#             print(len(provisional_pip))\n",
        "            h_p.append(position)\n",
        "        fitness = total_pip * self.pip_cost\n",
        "        self.pip = np.asanyarray(provisional_pip) * self.pip_cost\n",
        "        self.pip = [p if p >= -self.los_cut else -self.los_cut for p in self.pip]\n",
        "        self.total_pip = np.sum(self.pip)\n",
        "        mean_pip = self.total_pip / (t + 1)\n",
        "        trade_accuracy = np.mean(np.asanyarray(self.pip) > 0)\n",
        "        self.trade = trade_accuracy\n",
        "        mean_pip *= 96\n",
        "        prob = self.prob(history)\n",
        "        position_prob = self.prob(h_p)\n",
        "      \n",
        "        print(\"\")\n",
        "        print('action probability = ', prob)\n",
        "        print(\"buy = \", position_prob[1], \" sell = \", position_prob[-1])\n",
        "        print('trade accuracy = ', trade_accuracy)\n",
        "        print('epoch: %d, total rewards: %f, mean rewards: %f' % (i+1, float(self.total_pip), float(mean_pip)))\n",
        "    \n",
        "    def run_fit(self,i):\n",
        "      accuracy = 0\n",
        "      min_pip = 0\n",
        "      total = 0\n",
        "      for _ in range(20):\n",
        "        h = np.random.randint(self.x.shape[0]-(24+1))\n",
        "        df = self.x[h:h+24]\n",
        "        trend = self.y[h:h+24]\n",
        "        states = []\n",
        "        pip = []\n",
        "        provisional_pip = [0]\n",
        "        total_pip = 0.0\n",
        "        position = 3\n",
        "        for t in range(0, len(trend) - 1):\n",
        "            action = self.act(self.population_acc[i],self.population_min[i],self.population_sum[i], df[t])\n",
        "            states,provisional_pip,position,total_pip = self.rewards(trend[t],pip,provisional_pip,\n",
        "                                                                      action,position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/1000)\n",
        "        accuracy += np.mean(np.array(provisional_pip) > 0) * 100\n",
        "        min_pip += min(provisional_pip) * self.pip_cost\n",
        "        total += total_pip * self.pip_cost\n",
        "      return [accuracy, min_pip, total]\n",
        "    \n",
        "    def calculate_fitness(self):\n",
        "        p = Pool(os.cpu_count())\n",
        "        args = range(self.population_size)\n",
        "        fitness_list = p.map(self.run_fit, args)\n",
        "        p.close()\n",
        "        for i in range(self.population_size):\n",
        "          self.population_acc[i].fitness = fitness_list[i][0]\n",
        "          self.population_min[i].fitness = fitness_list[i][1]\n",
        "          self.population_sum[i].fitness = fitness_list[i][2]\n",
        "\n",
        "    def prob(self,history):\n",
        "        prob = np.asanyarray(history)\n",
        "        a = np.mean(prob == 0)\n",
        "        b = np.mean(prob == 1)\n",
        "        c = 1 - (a + b)\n",
        "        prob = [a,b,c]\n",
        "        return prob\n",
        "    \n",
        "    def sort(self,population):\n",
        "        fitnesses = [i.fitness for i in population]\n",
        "        fitnesses = np.array(fitnesses).flatten()\n",
        "        sort_fitness = sort_fitness = np.argsort(fitnesses,None)[::-1]\n",
        "        population = [population[int(i)] for i in sort_fitness]\n",
        "        fittest_individual = fittest_individual = population[0]\n",
        "        return fittest_individual, population\n",
        "\n",
        "    def eval(self,population):\n",
        "        next_population = [population[i] for i in range(self.n_winners)]\n",
        "        total_fitness = np.sum([np.abs(i.fitness) for i in population])\n",
        "        parent_probabilities = [np.abs(i.fitness / total_fitness) for i in population]\n",
        "        sort_probabilities = np.argsort(parent_probabilities,None).reshape(-1,1)\n",
        "        parent_probabilities = [parent_probabilities[int(i)] for i in sort_probabilities]\n",
        "        parent_probabilities = np.array(parent_probabilities).flatten()\n",
        "        parents = np.random.choice(population, size=self.n_parents, p=parent_probabilities, replace=False)\n",
        "        for i in np.arange(0, len(parents), 2):\n",
        "            child1, child2 = self.crossover(parents[i], parents[i+1])\n",
        "            next_population += [self.mutate(child1), self.mutate(child2)]\n",
        "        population = next_population\n",
        "        return population\n",
        "\n",
        "    def evolve(self, generations=20, checkpoint= 5):\n",
        "        self.population_acc = self._initialize_population()\n",
        "        self.population_min = self._initialize_population()\n",
        "        self.population_sum = self._initialize_population(total=True)\n",
        "        self.n_winners = int(self.population_size * 0.1)\n",
        "        self.n_parents = self.population_size - self.n_winners\n",
        "        for epoch in range(generations):\n",
        "            if epoch % 10 == 0:\n",
        "              self.change = True\n",
        "            self.calculate_fitness()\n",
        "            individual_acc, self.population_acc = self.sort(self.population_acc)\n",
        "            individual_min, self.population_min = self.sort(self.population_min)\n",
        "            individual_sum, self.population_sum = self.sort(self.population_sum)\n",
        "            if (epoch+1) % checkpoint == 0:\n",
        "                self.test(individual_acc,individual_min,individual_sum, epoch)\n",
        "                # save = [self.fittest_individual.W1, self.fittest_individual.W2, self.fittest_individual.W3]\n",
        "                # f = open('neuro_w.txt', 'wb')\n",
        "                # # f2 = open('neuro_train.txt', 'wb')\n",
        "                # pickle.dump(save, f)\n",
        "            self.population_acc = self.eval(self.population_acc)\n",
        "            self.population_min = self.eval(self.population_min)\n",
        "            self.population_sum = self.eval(self.population_sum)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9P8UX85cA5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_size = 100\n",
        "generations = 100\n",
        "mutation_rate = 0.1\n",
        "window_size = 30\n",
        "step_size = 24 * 20\n",
        "los_cut = 300\n",
        "restore = False\n",
        "path = \"audpred60.csv\"\n",
        "\n",
        "neural_evolve = NeuroEvolution(population_size, mutation_rate, neuralnetwork,\n",
        "                              window_size, window_size, path, step_size,restore=restore, los_cut=los_cut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GFxT5quTkq65",
        "outputId": "b765d549-6e78-4e7a-a067-ccbc47625370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fittest_nets = neural_evolve.evolve(50000,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "action probability =  [0.7870563674321504, 0.1649269311064718, 0.04801670146137782]\n",
            "buy =  0.8308977035490606  sell =  0.16910229645093944\n",
            "trade accuracy =  0.40160642570281124\n",
            "epoch: 1, total rewards: -6987.000000, mean rewards: -1400.317328\n",
            "\n",
            "action probability =  [0.34029227557411273, 0.511482254697286, 0.14822546972860118]\n",
            "buy =  0.3987473903966597  sell =  0.6012526096033404\n",
            "trade accuracy =  0.44569288389513106\n",
            "epoch: 2, total rewards: 1316.000000, mean rewards: 263.749478\n",
            "\n",
            "action probability =  [0.6263048016701461, 0.11691022964509394, 0.25678496868476]\n",
            "buy =  0.826722338204593  sell =  0.17327766179540705\n",
            "trade accuracy =  0.43119266055045874\n",
            "epoch: 3, total rewards: 7142.000000, mean rewards: 1431.382046\n",
            "\n",
            "action probability =  [0.30062630480167013, 0.1649269311064718, 0.5344467640918581]\n",
            "buy =  0.6659707724425887  sell =  0.33402922755741127\n",
            "trade accuracy =  0.4647058823529412\n",
            "epoch: 4, total rewards: -2686.000000, mean rewards: -538.321503\n",
            "\n",
            "action probability =  [0.6430062630480167, 0.020876826722338204, 0.33611691022964507]\n",
            "buy =  0.9686847599164927  sell =  0.03131524008350728\n",
            "trade accuracy =  0.3575757575757576\n",
            "epoch: 5, total rewards: 5805.000000, mean rewards: 1163.423800\n",
            "\n",
            "action probability =  [0.15866388308977036, 0.3883089770354906, 0.45302713987473897]\n",
            "buy =  0.3068893528183716  sell =  0.6931106471816284\n",
            "trade accuracy =  0.4375\n",
            "epoch: 6, total rewards: -3847.000000, mean rewards: -771.006263\n",
            "\n",
            "action probability =  [0.05010438413361169, 0.35908141962421714, 0.5908141962421711]\n",
            "buy =  0.11064718162839249  sell =  0.8893528183716075\n",
            "trade accuracy =  0.36752136752136755\n",
            "epoch: 7, total rewards: -1158.000000, mean rewards: -232.083507\n",
            "\n",
            "action probability =  [0.2254697286012526, 0.5845511482254697, 0.1899791231732777]\n",
            "buy =  0.2818371607515658  sell =  0.7181628392484343\n",
            "trade accuracy =  0.44672131147540983\n",
            "epoch: 8, total rewards: 6530.000000, mean rewards: 1308.726514\n",
            "\n",
            "action probability =  [0.31941544885177453, 0.3945720250521921, 0.28601252609603334]\n",
            "buy =  0.4405010438413361  sell =  0.5594989561586639\n",
            "trade accuracy =  0.4611872146118721\n",
            "epoch: 9, total rewards: -3482.000000, mean rewards: -697.853862\n",
            "\n",
            "action probability =  [0.5824634655532359, 0.18580375782881003, 0.231732776617954]\n",
            "buy =  0.7578288100208769  sell =  0.24217118997912312\n",
            "trade accuracy =  0.4980237154150198\n",
            "epoch: 10, total rewards: 2923.000000, mean rewards: 585.820459\n",
            "\n",
            "action probability =  [0.3883089770354906, 0.12943632567849686, 0.48225469728601256]\n",
            "buy =  0.7870563674321504  sell =  0.21294363256784965\n",
            "trade accuracy =  0.46111111111111114\n",
            "epoch: 11, total rewards: 6969.000000, mean rewards: 1396.709812\n",
            "\n",
            "action probability =  [0.5302713987473904, 0.1022964509394572, 0.36743215031315246]\n",
            "buy =  0.8183716075156576  sell =  0.18162839248434237\n",
            "trade accuracy =  0.39361702127659576\n",
            "epoch: 12, total rewards: -5325.000000, mean rewards: -1067.223382\n",
            "\n",
            "action probability =  [0.13987473903966596, 0.732776617954071, 0.12734864300626303]\n",
            "buy =  0.162839248434238  sell =  0.837160751565762\n",
            "trade accuracy =  0.3516949152542373\n",
            "epoch: 13, total rewards: -13164.000000, mean rewards: -2638.296451\n",
            "\n",
            "action probability =  [0.5135699373695198, 0.23382045929018788, 0.25260960334029225]\n",
            "buy =  0.6931106471816284  sell =  0.3068893528183716\n",
            "trade accuracy =  0.3975409836065574\n",
            "epoch: 14, total rewards: -4221.000000, mean rewards: -845.962422\n",
            "\n",
            "action probability =  [0.2818371607515658, 0.35908141962421714, 0.35908141962421714]\n",
            "buy =  0.4592901878914405  sell =  0.5407098121085595\n",
            "trade accuracy =  0.497907949790795\n",
            "epoch: 15, total rewards: 14026.000000, mean rewards: 2811.056367\n",
            "\n",
            "action probability =  [0.4551148225469729, 0.23382045929018788, 0.3110647181628392]\n",
            "buy =  0.6346555323590815  sell =  0.36534446764091855\n",
            "trade accuracy =  0.46473029045643155\n",
            "epoch: 16, total rewards: 8614.000000, mean rewards: 1726.396660\n",
            "\n",
            "action probability =  [0.5365344467640919, 0.23382045929018788, 0.2296450939457202]\n",
            "buy =  0.7160751565762005  sell =  0.28392484342379953\n",
            "trade accuracy =  0.4280155642023346\n",
            "epoch: 17, total rewards: -1804.000000, mean rewards: -361.553236\n",
            "\n",
            "action probability =  [0.24843423799582465, 0.4279749478079332, 0.32359081419624214]\n",
            "buy =  0.3695198329853862  sell =  0.6304801670146138\n",
            "trade accuracy =  0.4517543859649123\n",
            "epoch: 18, total rewards: 3299.000000, mean rewards: 661.177453\n",
            "\n",
            "action probability =  [0.40083507306889354, 0.1941544885177453, 0.40501043841336115]\n",
            "buy =  0.6242171189979123  sell =  0.3757828810020877\n",
            "trade accuracy =  0.4077669902912621\n",
            "epoch: 19, total rewards: 4121.000000, mean rewards: 825.920668\n",
            "\n",
            "action probability =  [0.05010438413361169, 0.7014613778705637, 0.24843423799582454]\n",
            "buy =  0.060542797494780795  sell =  0.9394572025052192\n",
            "trade accuracy =  0.375\n",
            "epoch: 20, total rewards: 11933.000000, mean rewards: 2391.582463\n",
            "\n",
            "action probability =  [0.018789144050104383, 0.778705636743215, 0.20250521920668063]\n",
            "buy =  0.033402922755741124  sell =  0.9665970772442589\n",
            "trade accuracy =  0.35135135135135137\n",
            "epoch: 21, total rewards: 6105.000000, mean rewards: 1223.549061\n",
            "\n",
            "action probability =  [0.7515657620041754, 0.0, 0.24843423799582465]\n",
            "buy =  1.0  sell =  0.0\n",
            "trade accuracy =  0.28888888888888886\n",
            "epoch: 22, total rewards: 12501.000000, mean rewards: 2505.419624\n",
            "\n",
            "action probability =  [0.5490605427974948, 0.07724425887265135, 0.37369519832985376]\n",
            "buy =  0.8684759916492694  sell =  0.13152400835073064\n",
            "trade accuracy =  0.38764044943820225\n",
            "epoch: 23, total rewards: 846.000000, mean rewards: 169.553236\n",
            "\n",
            "action probability =  [0.4718162839248434, 0.24634655532359082, 0.28183716075156573]\n",
            "buy =  0.6576200417536534  sell =  0.3423799582463466\n",
            "trade accuracy =  0.5122950819672131\n",
            "epoch: 24, total rewards: 19555.000000, mean rewards: 3919.164927\n",
            "\n",
            "action probability =  [0.5469728601252609, 0.35281837160751567, 0.10020876826722347]\n",
            "buy =  0.5949895615866388  sell =  0.40501043841336115\n",
            "trade accuracy =  0.4192546583850932\n",
            "epoch: 25, total rewards: 7952.000000, mean rewards: 1593.720251\n",
            "\n",
            "action probability =  [0.3674321503131524, 0.5782881002087683, 0.05427974947807934]\n",
            "buy =  0.3778705636743215  sell =  0.6221294363256785\n",
            "trade accuracy =  0.5317725752508361\n",
            "epoch: 26, total rewards: 10604.000000, mean rewards: 2125.227557\n",
            "\n",
            "action probability =  [0.5427974947807933, 0.05010438413361169, 0.40709812108559496]\n",
            "buy =  0.8935281837160751  sell =  0.10647181628392488\n",
            "trade accuracy =  0.4382716049382716\n",
            "epoch: 27, total rewards: 43791.000000, mean rewards: 8776.484342\n",
            "\n",
            "action probability =  [0.569937369519833, 0.0709812108559499, 0.35908141962421714]\n",
            "buy =  0.906054279749478  sell =  0.09394572025052195\n",
            "trade accuracy =  0.4444444444444444\n",
            "epoch: 28, total rewards: 8660.000000, mean rewards: 1735.615866\n",
            "\n",
            "action probability =  [0.4091858037578288, 0.14613778705636743, 0.44467640918580376]\n",
            "buy =  0.7766179540709812  sell =  0.22338204592901878\n",
            "trade accuracy =  0.4207650273224044\n",
            "epoch: 29, total rewards: 2272.000000, mean rewards: 455.348643\n",
            "\n",
            "action probability =  [0.4175365344467641, 0.10647181628392484, 0.47599164926931103]\n",
            "buy =  0.8058455114822547  sell =  0.1941544885177453\n",
            "trade accuracy =  0.3854748603351955\n",
            "epoch: 30, total rewards: -4150.000000, mean rewards: -831.732777\n",
            "\n",
            "action probability =  [0.3966597077244259, 0.40292275574112735, 0.20041753653444672]\n",
            "buy =  0.49478079331941544  sell =  0.5052192066805845\n",
            "trade accuracy =  0.49645390070921985\n",
            "epoch: 31, total rewards: 6767.000000, mean rewards: 1356.225470\n",
            "\n",
            "action probability =  [0.42588726513569936, 0.19206680584551147, 0.3820459290187892]\n",
            "buy =  0.6764091858037579  sell =  0.32359081419624214\n",
            "trade accuracy =  0.5093457943925234\n",
            "epoch: 32, total rewards: 11139.000000, mean rewards: 2232.450939\n",
            "\n",
            "action probability =  [0.453027139874739, 0.29436325678496866, 0.25260960334029225]\n",
            "buy =  0.6597077244258872  sell =  0.3402922755741128\n",
            "trade accuracy =  0.5604395604395604\n",
            "epoch: 33, total rewards: 18257.000000, mean rewards: 3659.022965\n",
            "\n",
            "action probability =  [0.7703549060542797, 0.08559498956158663, 0.14405010438413368]\n",
            "buy =  0.9102296450939458  sell =  0.08977035490605423\n",
            "trade accuracy =  0.42738589211618255\n",
            "epoch: 34, total rewards: -2823.000000, mean rewards: -565.778706\n",
            "\n",
            "action probability =  [0.7056367432150313, 0.24008350730688935, 0.05427974947807934]\n",
            "buy =  0.7411273486430062  sell =  0.2588726513569938\n",
            "trade accuracy =  0.46601941747572817\n",
            "epoch: 35, total rewards: 19210.000000, mean rewards: 3850.020877\n",
            "\n",
            "action probability =  [0.16701461377870563, 0.35490605427974947, 0.47807933194154484]\n",
            "buy =  0.3089770354906054  sell =  0.6910229645093946\n",
            "trade accuracy =  0.42528735632183906\n",
            "epoch: 36, total rewards: -323.000000, mean rewards: -64.734864\n",
            "\n",
            "action probability =  [0.9164926931106472, 0.05219206680584551, 0.03131524008350728]\n",
            "buy =  0.941544885177453  sell =  0.05845511482254695\n",
            "trade accuracy =  0.37158469945355194\n",
            "epoch: 37, total rewards: -7053.000000, mean rewards: -1413.544885\n",
            "\n",
            "action probability =  [0.5553235908141962, 0.15031315240083507, 0.29436325678496866]\n",
            "buy =  0.7077244258872651  sell =  0.29227557411273486\n",
            "trade accuracy =  0.5063291139240507\n",
            "epoch: 38, total rewards: 13611.000000, mean rewards: 2727.883090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK6uUyRABxi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}