{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuro evolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/neuro_evolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXpyhGyC4Cpk",
        "colab_type": "code",
        "outputId": "10cb17e6-4ecf-4688-e0e4-a16c7e53b142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQVZCJv4FBu",
        "colab_type": "code",
        "outputId": "845058ed-4748-4dd5-c1da-c1619cfaf8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ta) (0.21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.16.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->ta) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecmHJge38IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from numba import jit as njit\n",
        "from functools import lru_cache\n",
        "import time\n",
        "import random\n",
        "import ta\n",
        "from net import *\n",
        "from memory import *\n",
        "from reward import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aanxg75uPulp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class neuralnetwork:\n",
        "    def __init__(self, id_, hidden_size = 128*3, window_size = 100*2):\n",
        "        self.W1 = np.random.randn(window_size, hidden_size) / np.sqrt(window_size)\n",
        "        self.W2 = np.random.randn(hidden_size, 3) / np.sqrt(hidden_size)\n",
        "        self.fitness = 0\n",
        "        self.id = id_\n",
        "\n",
        "@njit\n",
        "def sigmoid(x):\n",
        "  x = 1 / (1 + np.exp(-x))\n",
        "  return x\n",
        "\n",
        "def swish(x):\n",
        "  x *= sigmoid(x)\n",
        "  return x\n",
        " \n",
        "def relu(X):\n",
        "    return np.maximum(X, 0)\n",
        "  \n",
        "@njit\n",
        "def softmax(X):\n",
        "    e_x = np.exp(X - np.max(X, axis=-1, keepdims=True))\n",
        "    e_x /= np.sum(e_x, axis=-1, keepdims=True)\n",
        "    return e_x\n",
        "  \n",
        "@njit\n",
        "def feed_forward(X, nets):\n",
        "    X = X.flatten().reshape(1,-1)\n",
        "    a1 = np.dot(X, nets.W1)\n",
        "    z1 = swish(a1)\n",
        "    a2 = np.dot(z1, nets.W2)\n",
        "    return softmax(a2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqWr3GfJCnzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuroEvolution:\n",
        "    def __init__(self, population_size, mutation_rate, model_generator, state_size, window_size, path, step_size, spread=10, pip_cost=1000, los_cut=100):\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.model_generator = model_generator\n",
        "        self.state_size = state_size\n",
        "        self.window_size = window_size\n",
        "        self.path = path\n",
        "        self.step_size = step_size\n",
        "        self.spread = spread / pip_cost\n",
        "        self.pip_cost = pip_cost\n",
        "        self.los_cut = los_cut\n",
        "        self.preproc()\n",
        "        self.rewards = reward3\n",
        "        \n",
        "    def preproc(self):\n",
        "          self.dat = df = pd.read_csv(self.path)\n",
        "          s = np.asanyarray(ta.stoch(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1)) - np.asanyarray(ta.stoch_signal(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1))\n",
        "          x = np.asanyarray(ta.daily_log_return(df[\"Close\"])).reshape((-1,1))\n",
        "          m = np.asanyarray(ta.macd_diff(df[\"Close\"])).reshape((-1,1))\n",
        "          x = np.concatenate([x,m], 1)\n",
        "          y = np.asanyarray(self.dat[[\"Open\"]])\n",
        "\n",
        "          gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x, y, self.window_size)\n",
        "          self.x = []\n",
        "          self.y = []\n",
        "          for i in gen:\n",
        "              self.x.extend(i[0].tolist())\n",
        "              self.y.extend(i[1].tolist())\n",
        "          self.x = np.asanyarray(self.x)\n",
        "          self.y = np.asanyarray(self.y)\n",
        "\n",
        "          self.df = self.x[-self.step_size::]\n",
        "          self.trend = self.y[-self.step_size::]\n",
        "\n",
        "    def _initialize_population(self):\n",
        "        self.population = []\n",
        "        for i in range(self.population_size):\n",
        "            self.population.append(self.model_generator(i,window_size = self.window_size*self.df.shape[-1]))\n",
        "    \n",
        "    def mutate(self, individual, scale=1.0):\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W1.shape)\n",
        "        individual.W1 += np.random.normal(loc=0, scale=scale, size=individual.W1.shape) * mutation_mask\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W2.shape)\n",
        "        individual.W2 += np.random.normal(loc=0, scale=scale, size=individual.W2.shape) * mutation_mask\n",
        "        return individual\n",
        "    \n",
        "    def inherit_weights(self, parent, child):\n",
        "        child.W1 = parent.W1.copy()\n",
        "        child.W2 = parent.W2.copy()\n",
        "        return child\n",
        "    \n",
        "    def crossover(self, parent1, parent2):\n",
        "        child1 = self.model_generator((parent1.id+1)*10)\n",
        "        child1 = self.inherit_weights(parent1, child1)\n",
        "        child2 = self.model_generator((parent2.id+1)*10)\n",
        "        child2 = self.inherit_weights(parent2, child2)\n",
        "        # first W\n",
        "        n_neurons = child1.W1.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W1[:, cutoff:] = parent2.W1[:, cutoff:].copy()\n",
        "        child2.W1[:, cutoff:] = parent1.W1[:, cutoff:].copy()\n",
        "        # second W\n",
        "        n_neurons = child1.W2.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W2[:, cutoff:] = parent2.W2[:, cutoff:].copy()\n",
        "        child2.W2[:, cutoff:] = parent1.W2[:, cutoff:].copy()\n",
        "        return child1, child2\n",
        "    \n",
        "    def act(self, p, state):\n",
        "        logits = feed_forward(state, p)\n",
        "        return np.argmax(logits, 1)[0]\n",
        "#         return np.argmax(logits[0])\n",
        "    \n",
        "    def test(self, individual, i):\n",
        "        states = []\n",
        "        pip = []\n",
        "        history = []\n",
        "        h_p = []\n",
        "        provisional_pip = []\n",
        "        total_pip = 0.0\n",
        "        position = 3\n",
        "        h = np.random.randint(self.x.shape[0]-(self.step_size+1))\n",
        "        self.df = self.x[h:h+self.step_size]\n",
        "        self.trend = self.y[h:h+self.step_size]\n",
        "        for t in range(0, len(self.trend) - 1):\n",
        "            action = self.act(individual, self.df[t])\n",
        "            history.append(action)\n",
        "            states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,action,position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/2/1000)\n",
        "#             print(len(provisional_pip))\n",
        "            h_p.append(position)\n",
        "        self.pip = np.asanyarray(provisional_pip) * self.pip_cost\n",
        "        self.pip = [p if p >= -self.los_cut else -self.los_cut for p in self.pip]\n",
        "        self.total_pip = np.sum(self.pip)\n",
        "        mean_pip = self.total_pip / (t + 1)\n",
        "        trade_accuracy = np.mean(np.asanyarray(self.pip) > 0)\n",
        "        self.trade = trade_accuracy\n",
        "        mean_pip *= 24\n",
        "        prob = self.prob(history)\n",
        "        position_prob = self.prob(h_p)\n",
        "      \n",
        "        print(\"\")\n",
        "        print('action probability = ', prob)\n",
        "        print(\"buy = \", position_prob[1], \" sell = \", position_prob[-1])\n",
        "        print('trade accuracy = ', trade_accuracy)\n",
        "        print('epoch: %d, total rewards: %f, mean rewards: %f' % (i+1, float(self.total_pip), float(mean_pip)))\n",
        "    \n",
        "    def calculate_fitness(self):\n",
        "        for i in range(self.population_size):\n",
        "          states = []\n",
        "          pip = []\n",
        "          provisional_pip = []\n",
        "          total_pip = 0.0\n",
        "          position = 3\n",
        "#           h = np.random.randint(self.x.shape[0]-(self.step_size+1))\n",
        "#           self.df = self.x[h:h+self.step_size]\n",
        "#           self.trend = self.y[h:h+self.step_size]\n",
        "          for t in range(0, len(self.trend) - 1):\n",
        "              action = self.act(self.population[i], self.df[t])\n",
        "              states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,action,position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/2/1000)\n",
        "          invest = total_pip * self.pip_cost\n",
        "          self.population[i].fitness = invest\n",
        "    \n",
        "    def prob(self,history):\n",
        "        prob = np.asanyarray(history)\n",
        "        a = np.mean(prob == 0)\n",
        "        b = np.mean(prob == 1)\n",
        "        c = 1 - (a + b)\n",
        "        prob = [a,b,c]\n",
        "        return prob\n",
        "    \n",
        "    def evolve(self, generations=20, checkpoint= 1):\n",
        "        self._initialize_population()\n",
        "        n_winners = int(self.population_size * 0.4)\n",
        "        n_parents = self.population_size - n_winners\n",
        "        for epoch in range(generations):\n",
        "            self.calculate_fitness()\n",
        "            self.fitnesses = fitnesses = [i.fitness for i in self.population]\n",
        "            self.sort_fitness = sort_fitness = np.argsort(fitnesses,None).reshape(-1,1)\n",
        "            self.population = [self.population[int(i)] for i in sort_fitness]\n",
        "            fittest_individual = self.population[0]\n",
        "            if (epoch+1) % checkpoint == 0:\n",
        "                self.test(fittest_individual, epoch)\n",
        "                save = [fittest_individual.W1, fittest_individual.W2]\n",
        "                f = open('neuro_w.txt', 'wb')\n",
        "                pickle.dump(save, f)\n",
        "            next_population = [self.population[i] for i in range(n_winners)]\n",
        "            total_fitness = np.sum([np.abs(i.fitness) for i in self.population])\n",
        "            parent_probabilities = [np.abs(i.fitness / total_fitness) for i in self.population]\n",
        "            parent_probabilities = np.array(parent_probabilities).flatten()\n",
        "            parents = np.random.choice(self.population, size=n_parents, p=parent_probabilities, replace=False)\n",
        "            for i in np.arange(0, len(parents), 2):\n",
        "                child1, child2 = self.crossover(parents[i], parents[i+1])\n",
        "                next_population += [self.mutate(child1), self.mutate(child2)]\n",
        "            self.population = next_population\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9P8UX85cA5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_size = 100\n",
        "generations = 100\n",
        "mutation_rate = 0.1\n",
        "window_size = 5\n",
        "step_size = 96\n",
        "path = \"audpred15.csv\"\n",
        "\n",
        "neural_evolve = NeuroEvolution(population_size, mutation_rate, neuralnetwork,\n",
        "                              window_size, window_size, path, step_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7qzzh4XkslF",
        "colab_type": "code",
        "outputId": "ecf3d9f2-5cd7-4162-eaf7-007168986745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fittest_nets = neural_evolve.evolve(50000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "action probability =  [0.3263157894736842, 0.37894736842105264, 0.2947368421052632]\n",
            "buy =  0.43157894736842106  sell =  0.5684210526315789\n",
            "trade accuracy =  0.38181818181818183\n",
            "epoch: 1, total rewards: 9349.000000, mean rewards: 2361.852632\n",
            "\n",
            "action probability =  [0.3157894736842105, 0.3684210526315789, 0.3157894736842106]\n",
            "buy =  0.3473684210526316  sell =  0.6526315789473685\n",
            "trade accuracy =  0.2807017543859649\n",
            "epoch: 2, total rewards: -2026.000000, mean rewards: -511.831579\n",
            "\n",
            "action probability =  [0.30526315789473685, 0.10526315789473684, 0.5894736842105264]\n",
            "buy =  0.6842105263157895  sell =  0.3157894736842105\n",
            "trade accuracy =  0.2982456140350877\n",
            "epoch: 3, total rewards: -2300.000000, mean rewards: -581.052632\n",
            "\n",
            "action probability =  [0.3894736842105263, 0.21052631578947367, 0.4]\n",
            "buy =  0.7473684210526316  sell =  0.25263157894736843\n",
            "trade accuracy =  0.3114754098360656\n",
            "epoch: 4, total rewards: 1056.000000, mean rewards: 266.778947\n",
            "\n",
            "action probability =  [0.4, 0.22105263157894736, 0.3789473684210526]\n",
            "buy =  0.7368421052631579  sell =  0.26315789473684215\n",
            "trade accuracy =  0.37681159420289856\n",
            "epoch: 5, total rewards: -1302.000000, mean rewards: -328.926316\n",
            "\n",
            "action probability =  [0.3473684210526316, 0.4105263157894737, 0.2421052631578947]\n",
            "buy =  0.4631578947368421  sell =  0.5368421052631579\n",
            "trade accuracy =  0.42\n",
            "epoch: 6, total rewards: -378.000000, mean rewards: -95.494737\n",
            "\n",
            "action probability =  [0.14736842105263157, 0.42105263157894735, 0.43157894736842106]\n",
            "buy =  0.2  sell =  0.8\n",
            "trade accuracy =  0.36065573770491804\n",
            "epoch: 7, total rewards: 75.000000, mean rewards: 18.947368\n",
            "\n",
            "action probability =  [0.4105263157894737, 0.3473684210526316, 0.2421052631578947]\n",
            "buy =  0.6210526315789474  sell =  0.3789473684210526\n",
            "trade accuracy =  0.2653061224489796\n",
            "epoch: 8, total rewards: -1014.000000, mean rewards: -256.168421\n",
            "\n",
            "action probability =  [0.021052631578947368, 0.6842105263157895, 0.2947368421052632]\n",
            "buy =  0.07368421052631578  sell =  0.9263157894736842\n",
            "trade accuracy =  0.4\n",
            "epoch: 9, total rewards: 496.000000, mean rewards: 125.305263\n",
            "\n",
            "action probability =  [0.2736842105263158, 0.4105263157894737, 0.3157894736842105]\n",
            "buy =  0.35789473684210527  sell =  0.6421052631578947\n",
            "trade accuracy =  0.4727272727272727\n",
            "epoch: 10, total rewards: 815.000000, mean rewards: 205.894737\n",
            "\n",
            "action probability =  [0.24210526315789474, 0.45263157894736844, 0.3052631578947368]\n",
            "buy =  0.4421052631578947  sell =  0.5578947368421052\n",
            "trade accuracy =  0.30158730158730157\n",
            "epoch: 11, total rewards: -1169.000000, mean rewards: -295.326316\n",
            "\n",
            "action probability =  [0.3473684210526316, 0.3157894736842105, 0.33684210526315783]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.4375\n",
            "epoch: 12, total rewards: -341.000000, mean rewards: -86.147368\n",
            "\n",
            "action probability =  [0.3684210526315789, 0.37894736842105264, 0.25263157894736843]\n",
            "buy =  0.5894736842105263  sell =  0.41052631578947374\n",
            "trade accuracy =  0.3684210526315789\n",
            "epoch: 13, total rewards: 466.000000, mean rewards: 117.726316\n",
            "\n",
            "action probability =  [0.37894736842105264, 0.15789473684210525, 0.4631578947368421]\n",
            "buy =  0.7157894736842105  sell =  0.28421052631578947\n",
            "trade accuracy =  0.27692307692307694\n",
            "epoch: 14, total rewards: -1599.000000, mean rewards: -403.957895\n",
            "\n",
            "action probability =  [0.28421052631578947, 0.30526315789473685, 0.41052631578947363]\n",
            "buy =  0.3157894736842105  sell =  0.6842105263157895\n",
            "trade accuracy =  0.2857142857142857\n",
            "epoch: 15, total rewards: -1451.000000, mean rewards: -366.568421\n",
            "\n",
            "action probability =  [0.2, 0.4421052631578947, 0.35789473684210527]\n",
            "buy =  0.30526315789473685  sell =  0.6947368421052631\n",
            "trade accuracy =  0.47540983606557374\n",
            "epoch: 16, total rewards: 703.000000, mean rewards: 177.600000\n",
            "\n",
            "action probability =  [0.3368421052631579, 0.3368421052631579, 0.3263157894736842]\n",
            "buy =  0.6421052631578947  sell =  0.35789473684210527\n",
            "trade accuracy =  0.1702127659574468\n",
            "epoch: 17, total rewards: -486.000000, mean rewards: -122.778947\n",
            "\n",
            "action probability =  [0.3473684210526316, 0.22105263157894736, 0.43157894736842106]\n",
            "buy =  0.6947368421052632  sell =  0.3052631578947368\n",
            "trade accuracy =  0.2727272727272727\n",
            "epoch: 18, total rewards: -183.000000, mean rewards: -46.231579\n",
            "\n",
            "action probability =  [0.18947368421052632, 0.35789473684210527, 0.4526315789473684]\n",
            "buy =  0.29473684210526313  sell =  0.7052631578947368\n",
            "trade accuracy =  0.375\n",
            "epoch: 19, total rewards: 1717.000000, mean rewards: 433.768421\n",
            "\n",
            "action probability =  [0.25263157894736843, 0.43157894736842106, 0.3157894736842105]\n",
            "buy =  0.5473684210526316  sell =  0.4526315789473684\n",
            "trade accuracy =  0.3770491803278688\n",
            "epoch: 20, total rewards: -1245.000000, mean rewards: -314.526316\n",
            "\n",
            "action probability =  [0.35789473684210527, 0.3157894736842105, 0.3263157894736842]\n",
            "buy =  0.43157894736842106  sell =  0.5684210526315789\n",
            "trade accuracy =  0.24489795918367346\n",
            "epoch: 21, total rewards: 195.000000, mean rewards: 49.263158\n",
            "\n",
            "action probability =  [0.4842105263157895, 0.11578947368421053, 0.4]\n",
            "buy =  0.8  sell =  0.19999999999999996\n",
            "trade accuracy =  0.5178571428571429\n",
            "epoch: 22, total rewards: 3669.000000, mean rewards: 926.905263\n",
            "\n",
            "action probability =  [0.18947368421052632, 0.24210526315789474, 0.5684210526315789]\n",
            "buy =  0.24210526315789474  sell =  0.7578947368421053\n",
            "trade accuracy =  0.4166666666666667\n",
            "epoch: 23, total rewards: -12.000000, mean rewards: -3.031579\n",
            "\n",
            "action probability =  [0.29473684210526313, 0.4105263157894737, 0.2947368421052632]\n",
            "buy =  0.42105263157894735  sell =  0.5789473684210527\n",
            "trade accuracy =  0.3442622950819672\n",
            "epoch: 24, total rewards: -450.000000, mean rewards: -113.684211\n",
            "\n",
            "action probability =  [0.18947368421052632, 0.2736842105263158, 0.5368421052631579]\n",
            "buy =  0.18947368421052632  sell =  0.8105263157894737\n",
            "trade accuracy =  0.44285714285714284\n",
            "epoch: 25, total rewards: 4771.000000, mean rewards: 1205.305263\n",
            "\n",
            "action probability =  [0.3263157894736842, 0.25263157894736843, 0.42105263157894735]\n",
            "buy =  0.6  sell =  0.4\n",
            "trade accuracy =  0.29508196721311475\n",
            "epoch: 26, total rewards: -1234.000000, mean rewards: -311.747368\n",
            "\n",
            "action probability =  [0.14736842105263157, 0.43157894736842106, 0.42105263157894735]\n",
            "buy =  0.15789473684210525  sell =  0.8421052631578947\n",
            "trade accuracy =  0.3728813559322034\n",
            "epoch: 27, total rewards: -1226.000000, mean rewards: -309.726316\n",
            "\n",
            "action probability =  [0.3684210526315789, 0.22105263157894736, 0.41052631578947374]\n",
            "buy =  0.45263157894736844  sell =  0.5473684210526315\n",
            "trade accuracy =  0.4772727272727273\n",
            "epoch: 28, total rewards: 4001.000000, mean rewards: 1010.778947\n",
            "\n",
            "action probability =  [0.22105263157894736, 0.3368421052631579, 0.4421052631578948]\n",
            "buy =  0.43157894736842106  sell =  0.5684210526315789\n",
            "trade accuracy =  0.5303030303030303\n",
            "epoch: 29, total rewards: 930.000000, mean rewards: 234.947368\n",
            "\n",
            "action probability =  [0.23157894736842105, 0.3368421052631579, 0.43157894736842106]\n",
            "buy =  0.3473684210526316  sell =  0.6526315789473685\n",
            "trade accuracy =  0.32\n",
            "epoch: 30, total rewards: -1228.000000, mean rewards: -310.231579\n",
            "\n",
            "action probability =  [0.2736842105263158, 0.3894736842105263, 0.33684210526315783]\n",
            "buy =  0.30526315789473685  sell =  0.6947368421052631\n",
            "trade accuracy =  0.17105263157894737\n",
            "epoch: 31, total rewards: -1805.000000, mean rewards: -456.000000\n",
            "\n",
            "action probability =  [0.24210526315789474, 0.3157894736842105, 0.4421052631578948]\n",
            "buy =  0.3157894736842105  sell =  0.6842105263157895\n",
            "trade accuracy =  0.5666666666666667\n",
            "epoch: 32, total rewards: 6711.000000, mean rewards: 1695.410526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx2zzjpi4lo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neural_evolve.pip"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}