{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuro evolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/neuro_evolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXpyhGyC4Cpk",
        "colab_type": "code",
        "outputId": "cead27c7-5c2c-4e07-9889-2a04bfcffd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQVZCJv4FBu",
        "colab_type": "code",
        "outputId": "988136bb-5307-498e-e261-3f22f3b4a306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.16.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.24.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ta) (0.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->ta) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecmHJge38IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from numba import jit as njit\n",
        "from functools import lru_cache\n",
        "import time\n",
        "import random\n",
        "import ta\n",
        "from net import *\n",
        "from memory import *\n",
        "from reward import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aanxg75uPulp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class neuralnetwork:\n",
        "    def __init__(self, id_, hidden_size = 128*2, window_size = 100*2, restore=False):\n",
        "        if restore:\n",
        "          f = open(\"./neuro_w.txt\",\"rb\")\n",
        "          weights = pickle.load(f)\n",
        "          self.W1 = weights[0]\n",
        "          self.W2 = weights[1]\n",
        "        else:\n",
        "          self.W1 = np.random.randn(window_size, hidden_size) / np.sqrt(window_size)\n",
        "          self.W2 = np.random.randn(hidden_size, 3) / np.sqrt(hidden_size)\n",
        "        self.fitness = 0\n",
        "        self.id = id_\n",
        "\n",
        "@njit\n",
        "def sigmoid(x):\n",
        "  x = 1 / (1 + np.exp(-x))\n",
        "  return x\n",
        "\n",
        "def swish(x):\n",
        "  x *= sigmoid(x)\n",
        "  return x\n",
        " \n",
        "def relu(X):\n",
        "    return np.maximum(X, 0)\n",
        "  \n",
        "@njit\n",
        "def softmax(X):\n",
        "    e_x = np.exp(X - np.max(X, axis=-1, keepdims=True))\n",
        "    e_x /= np.sum(e_x, axis=-1, keepdims=True)\n",
        "    return e_x\n",
        "  \n",
        "@njit\n",
        "def feed_forward(X, nets):\n",
        "    X = X.flatten().reshape(1,-1)\n",
        "    a1 = np.dot(X, nets.W1)\n",
        "    z1 = swish(a1)\n",
        "    a2 = np.dot(z1, nets.W2)\n",
        "    return softmax(a2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqWr3GfJCnzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuroEvolution:\n",
        "    def __init__(self, population_size, mutation_rate, model_generator, state_size, window_size, path, step_size, spread=10, pip_cost=1000, los_cut=20,restore=False):\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.model_generator = model_generator\n",
        "        self.state_size = state_size\n",
        "        self.window_size = window_size\n",
        "        self.path = path\n",
        "        self.step_size = step_size\n",
        "        self.spread = spread / pip_cost\n",
        "        self.pip_cost = pip_cost\n",
        "        self.los_cut = los_cut\n",
        "        self.restore = restore\n",
        "        self.preproc()\n",
        "        self.rewards = reward3\n",
        "        \n",
        "    def preproc(self):\n",
        "          self.dat = df = pd.read_csv(self.path)\n",
        "          s = np.asanyarray(ta.stoch(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1)) - np.asanyarray(ta.stoch_signal(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1))\n",
        "          x = np.asanyarray(ta.daily_log_return(df[\"Close\"])).reshape((-1,1))\n",
        "          m = np.asanyarray(ta.macd_diff(df[\"Close\"])).reshape((-1,1))\n",
        "          x = m\n",
        "#           x = np.concatenate([x,m], 1)\n",
        "          y = np.asanyarray(self.dat[[\"Open\"]])\n",
        "\n",
        "          gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x, y, self.window_size)\n",
        "          self.x = []\n",
        "          self.y = []\n",
        "          for i in gen:\n",
        "              self.x.extend(i[0].tolist())\n",
        "              self.y.extend(i[1].tolist())\n",
        "          self.x = np.asanyarray(self.x)\n",
        "          self.y = np.asanyarray(self.y)\n",
        "\n",
        "          self.df = self.x[-self.step_size::]\n",
        "          self.trend = self.y[-self.step_size::]\n",
        "\n",
        "    def _initialize_population(self):\n",
        "        self.population = []\n",
        "        for i in range(self.population_size):\n",
        "            self.population.append(self.model_generator(i,window_size = self.window_size*self.df.shape[-1], restore=self.restore))\n",
        "    \n",
        "    def mutate(self, individual, scale=1.0):\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W1.shape)\n",
        "        individual.W1 += np.random.normal(loc=0, scale=scale, size=individual.W1.shape) * mutation_mask\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W2.shape)\n",
        "        individual.W2 += np.random.normal(loc=0, scale=scale, size=individual.W2.shape) * mutation_mask\n",
        "        return individual\n",
        "    \n",
        "    def inherit_weights(self, parent, child):\n",
        "        child.W1 = parent.W1.copy()\n",
        "        child.W2 = parent.W2.copy()\n",
        "        return child\n",
        "    \n",
        "    def crossover(self, parent1, parent2):\n",
        "        child1 = self.model_generator((parent1.id+1)*10)\n",
        "        child1 = self.inherit_weights(parent1, child1)\n",
        "        child2 = self.model_generator((parent2.id+1)*10)\n",
        "        child2 = self.inherit_weights(parent2, child2)\n",
        "        # first W\n",
        "        n_neurons = child1.W1.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W1[:, cutoff:] = parent2.W1[:, cutoff:].copy()\n",
        "        child2.W1[:, cutoff:] = parent1.W1[:, cutoff:].copy()\n",
        "        # second W\n",
        "        n_neurons = child1.W2.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W2[:, cutoff:] = parent2.W2[:, cutoff:].copy()\n",
        "        child2.W2[:, cutoff:] = parent1.W2[:, cutoff:].copy()\n",
        "        return child1, child2\n",
        "    \n",
        "    def act(self, p, state):\n",
        "        logits = feed_forward(state, p)\n",
        "        return np.argmax(logits, 1)[0]\n",
        "#         return np.argmax(logits[0])\n",
        "    \n",
        "    def test(self, individual, i):\n",
        "        states = []\n",
        "        pip = []\n",
        "        history = []\n",
        "        h_p = []\n",
        "        provisional_pip = []\n",
        "        total_pip = 0.0\n",
        "        position = 3\n",
        "        h = np.random.randint(100,self.x.shape[0]-(self.step_size*20))\n",
        "        self.df = self.x[h:h+self.step_size*20]\n",
        "        self.trend = self.y[h:h+self.step_size*20]\n",
        "        for t in range(0, len(self.trend) - 1):\n",
        "            action = self.act(individual, self.df[t])\n",
        "            history.append(action)\n",
        "            states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,action,\n",
        "                                                                     position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/1000)\n",
        "#             print(len(provisional_pip))\n",
        "            h_p.append(position)\n",
        "        self.pip = np.asanyarray(provisional_pip) * self.pip_cost\n",
        "        self.pip = [p if p >= -self.los_cut else -self.los_cut for p in self.pip]\n",
        "        self.total_pip = np.sum(self.pip)\n",
        "        mean_pip = self.total_pip / (t + 1)\n",
        "        trade_accuracy = np.mean(np.asanyarray(self.pip) > 0)\n",
        "        self.trade = trade_accuracy\n",
        "        mean_pip *= 24\n",
        "        prob = self.prob(history)\n",
        "        position_prob = self.prob(h_p)\n",
        "      \n",
        "        print(\"\")\n",
        "        print('action probability = ', prob)\n",
        "        print(\"buy = \", position_prob[1], \" sell = \", position_prob[-1])\n",
        "        print('trade accuracy = ', trade_accuracy)\n",
        "        print('epoch: %d, total rewards: %f, mean rewards: %f' % (i+1, float(self.total_pip), float(mean_pip)))\n",
        "    \n",
        "    def calculate_fitness(self):\n",
        "        change = True\n",
        "        for i in range(self.population_size):\n",
        "          states = []\n",
        "          pip = []\n",
        "          provisional_pip = []\n",
        "          total_pip = 0.0\n",
        "          position = 3\n",
        "          if change:\n",
        "            change = False\n",
        "            h = np.random.randint(self.x.shape[0]-(self.step_size+1))\n",
        "            self.df = self.x[h:h+self.step_size]\n",
        "            self.trend = self.y[h:h+self.step_size]\n",
        "          for t in range(0, len(self.trend) - 1):\n",
        "              action = self.act(self.population[i], self.df[t])\n",
        "              states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,\n",
        "                                                                       action,position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/1000)\n",
        "          invest = total_pip * self.pip_cost\n",
        "          trade_accuracy = np.mean(np.asanyarray(provisional_pip) > 0) * 100\n",
        "          self.population[i].fitness = trade_accuracy\n",
        "    \n",
        "    def prob(self,history):\n",
        "        prob = np.asanyarray(history)\n",
        "        a = np.mean(prob == 0)\n",
        "        b = np.mean(prob == 1)\n",
        "        c = 1 - (a + b)\n",
        "        prob = [a,b,c]\n",
        "        return prob\n",
        "    \n",
        "    def evolve(self, generations=20, checkpoint= 5):\n",
        "        self._initialize_population()\n",
        "        n_winners = int(self.population_size * 0.6)\n",
        "        n_parents = self.population_size - n_winners\n",
        "        for epoch in range(generations):\n",
        "            self.calculate_fitness()\n",
        "            self.fitnesses = fitnesses = [i.fitness for i in self.population]\n",
        "            fitnesses = np.array(neural_evolve.fitnesses).flatten()\n",
        "            self.sort_fitness = sort_fitness = np.argsort(neural_evolve.fitnesses,None)[::-1]\n",
        "            self.population = [self.population[int(i)] for i in sort_fitness]\n",
        "            fittest_individual = self.population[0]\n",
        "            if (epoch+1) % checkpoint == 0:\n",
        "                self.test(fittest_individual, epoch)\n",
        "                save = [fittest_individual.W1, fittest_individual.W2]\n",
        "                f = open('neuro_w.txt', 'wb')\n",
        "                pickle.dump(save, f)\n",
        "                \n",
        "            next_population = [self.population[i] for i in range(n_winners)]\n",
        "            total_fitness = np.sum([np.abs(i.fitness) for i in self.population])\n",
        "            parent_probabilities = [np.abs(i.fitness / total_fitness) for i in self.population]\n",
        "            sort_probabilities = np.argsort(parent_probabilities,None).reshape(-1,1)\n",
        "            parent_probabilities = [parent_probabilities[int(i)] for i in sort_probabilities]\n",
        "            parent_probabilities = np.array(parent_probabilities).flatten()\n",
        "            parents = np.random.choice(self.population, size=n_parents, p=parent_probabilities, replace=False)\n",
        "            for i in np.arange(0, len(parents), 2):\n",
        "                child1, child2 = self.crossover(parents[i], parents[i+1])\n",
        "                next_population += [self.mutate(child1), self.mutate(child2)]\n",
        "            self.population = next_population\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9P8UX85cA5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_size = 100\n",
        "generations = 100\n",
        "mutation_rate = 0.1\n",
        "window_size = 30\n",
        "step_size = 96\n",
        "los_cut = 600\n",
        "restore = False\n",
        "path = \"audpred15.csv\"\n",
        "\n",
        "neural_evolve = NeuroEvolution(population_size, mutation_rate, neuralnetwork,\n",
        "                              window_size, window_size, path, step_size,restore=restore, los_cut=los_cut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7qzzh4XkslF",
        "colab_type": "code",
        "outputId": "0f196209-81ab-45f5-c312-4bf656bd3935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fittest_nets = neural_evolve.evolve(50000,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "action probability =  [0.3871808233454924, 0.4179260031266285, 0.19489317352787916]\n",
            "buy =  0.47889525794684734  sell =  0.5211047420531527\n",
            "trade accuracy =  0.39156626506024095\n",
            "epoch: 1, total rewards: -16762.000000, mean rewards: -209.634184\n",
            "\n",
            "action probability =  [0.38822303282959875, 0.4174048983845753, 0.1943720687858259]\n",
            "buy =  0.4768108389786347  sell =  0.5231891610213653\n",
            "trade accuracy =  0.3945578231292517\n",
            "epoch: 2, total rewards: -12639.000000, mean rewards: -158.069828\n",
            "\n",
            "action probability =  [0.37206878582595104, 0.3611255862428348, 0.2668056279312141]\n",
            "buy =  0.45648775403856173  sell =  0.5435122459614383\n",
            "trade accuracy =  0.4124293785310734\n",
            "epoch: 3, total rewards: -21492.000000, mean rewards: -268.789995\n",
            "\n",
            "action probability =  [0.3845752996352267, 0.4158415841584158, 0.1995831162063575]\n",
            "buy =  0.4815007816571131  sell =  0.5184992183428869\n",
            "trade accuracy =  0.39759036144578314\n",
            "epoch: 4, total rewards: -16809.000000, mean rewards: -210.221991\n",
            "\n",
            "action probability =  [0.33611255862428346, 0.2928608650338718, 0.37102657634184477]\n",
            "buy =  0.5763418447107869  sell =  0.42365815528921313\n",
            "trade accuracy =  0.541371158392435\n",
            "epoch: 5, total rewards: 9613.000000, mean rewards: 120.225117\n",
            "\n",
            "action probability =  [0.3689421573736321, 0.19541427826993227, 0.4356435643564356]\n",
            "buy =  0.7014069828035435  sell =  0.2985930171964565\n",
            "trade accuracy =  0.4628099173553719\n",
            "epoch: 6, total rewards: -2560.000000, mean rewards: -32.016675\n",
            "\n",
            "action probability =  [0.34288692027097445, 0.3725898905680042, 0.2845231891610214]\n",
            "buy =  0.41271495570609695  sell =  0.587285044293903\n",
            "trade accuracy =  0.45588235294117646\n",
            "epoch: 7, total rewards: -10401.000000, mean rewards: -130.080250\n",
            "\n",
            "action probability =  [0.2136529442417926, 0.3579989577905159, 0.42834809796769147]\n",
            "buy =  0.2678478374153205  sell =  0.7321521625846795\n",
            "trade accuracy =  0.35735735735735735\n",
            "epoch: 8, total rewards: -14295.000000, mean rewards: -178.780615\n",
            "\n",
            "action probability =  [0.38613861386138615, 0.2245961438249088, 0.3892652423137051]\n",
            "buy =  0.4825429911412194  sell =  0.5174570088587807\n",
            "trade accuracy =  0.34048257372654156\n",
            "epoch: 9, total rewards: -25224.000000, mean rewards: -315.464304\n",
            "\n",
            "action probability =  [0.36477331943720687, 0.22720166753517457, 0.4080250130276186]\n",
            "buy =  0.4054194893173528  sell =  0.5945805106826472\n",
            "trade accuracy =  0.5736842105263158\n",
            "epoch: 10, total rewards: 3258.000000, mean rewards: 40.746222\n",
            "\n",
            "action probability =  [0.3751954142782699, 0.3986451276706618, 0.2261594580510683]\n",
            "buy =  0.41219385096404376  sell =  0.5878061490359563\n",
            "trade accuracy =  0.4977578475336323\n",
            "epoch: 11, total rewards: 19855.000000, mean rewards: 248.316832\n",
            "\n",
            "action probability =  [0.31943720687858257, 0.3256904637832204, 0.354872329338197]\n",
            "buy =  0.37363210005211045  sell =  0.6263678999478896\n",
            "trade accuracy =  0.48578199052132703\n",
            "epoch: 12, total rewards: -2710.000000, mean rewards: -33.892652\n",
            "\n",
            "action probability =  [0.34809796769150597, 0.3559145388223033, 0.2959874934861908]\n",
            "buy =  0.4226159458051068  sell =  0.5773840541948931\n",
            "trade accuracy =  0.5135135135135135\n",
            "epoch: 13, total rewards: 6964.000000, mean rewards: 87.095362\n",
            "\n",
            "action probability =  [0.43147472642001045, 0.4132360604481501, 0.15528921313183952]\n",
            "buy =  0.5039082855653987  sell =  0.4960917144346013\n",
            "trade accuracy =  0.3956639566395664\n",
            "epoch: 14, total rewards: -6137.000000, mean rewards: -76.752475\n",
            "\n",
            "action probability =  [0.3069306930693069, 0.3069306930693069, 0.38613861386138615]\n",
            "buy =  0.39082855653986454  sell =  0.6091714434601354\n",
            "trade accuracy =  0.5563725490196079\n",
            "epoch: 15, total rewards: 5783.000000, mean rewards: 72.325169\n",
            "\n",
            "action probability =  [0.24700364773319436, 0.33194372068785827, 0.42105263157894735]\n",
            "buy =  0.40906722251172484  sell =  0.5909327774882751\n",
            "trade accuracy =  0.504424778761062\n",
            "epoch: 16, total rewards: 306.000000, mean rewards: 3.826993\n",
            "\n",
            "action probability =  [0.2303282959874935, 0.3501823866597186, 0.4194893173527878]\n",
            "buy =  0.4632621156852527  sell =  0.5367378843147472\n",
            "trade accuracy =  0.523121387283237\n",
            "epoch: 17, total rewards: -2252.000000, mean rewards: -28.164669\n",
            "\n",
            "action probability =  [0.4017717561229807, 0.24700364773319436, 0.35122459614382495]\n",
            "buy =  0.43772798332464824  sell =  0.5622720166753518\n",
            "trade accuracy =  0.44493392070484583\n",
            "epoch: 18, total rewards: 401.000000, mean rewards: 5.015112\n",
            "\n",
            "action probability =  [0.242313705054716, 0.3809275664408546, 0.3767587285044294]\n",
            "buy =  0.5127670661803022  sell =  0.4872329338196978\n",
            "trade accuracy =  0.3525641025641026\n",
            "epoch: 19, total rewards: -13534.000000, mean rewards: -169.263158\n",
            "\n",
            "action probability =  [0.3444502344971339, 0.3064095883272538, 0.3491401771756123]\n",
            "buy =  0.48827514330380406  sell =  0.5117248566961959\n",
            "trade accuracy =  0.5207253886010362\n",
            "epoch: 20, total rewards: 5825.000000, mean rewards: 72.850443\n",
            "\n",
            "action probability =  [0.2016675351745701, 0.4445023449713392, 0.35383011985409074]\n",
            "buy =  0.30328295987493487  sell =  0.6967170401250651\n",
            "trade accuracy =  0.5333333333333333\n",
            "epoch: 21, total rewards: 27715.000000, mean rewards: 346.618030\n",
            "\n",
            "action probability =  [0.47628973423658155, 0.3402813965607087, 0.18342886920270973]\n",
            "buy =  0.5737363210005211  sell =  0.4262636789994789\n",
            "trade accuracy =  0.4677871148459384\n",
            "epoch: 22, total rewards: -3807.000000, mean rewards: -47.612298\n",
            "\n",
            "action probability =  [0.3402813965607087, 0.29807191245440334, 0.3616466909848879]\n",
            "buy =  0.5914538822303282  sell =  0.40854611776967176\n",
            "trade accuracy =  0.5155440414507773\n",
            "epoch: 23, total rewards: -3673.000000, mean rewards: -45.936425\n",
            "\n",
            "action probability =  [0.31891610213652943, 0.3163105784262637, 0.3647733194372069]\n",
            "buy =  0.3757165190203231  sell =  0.6242834809796769\n",
            "trade accuracy =  0.5098039215686274\n",
            "epoch: 24, total rewards: 7793.000000, mean rewards: 97.463262\n",
            "\n",
            "action probability =  [0.4351224596143825, 0.17926003126628454, 0.385617509119333]\n",
            "buy =  0.7019280875455967  sell =  0.29807191245440334\n",
            "trade accuracy =  0.44711538461538464\n",
            "epoch: 25, total rewards: -6229.000000, mean rewards: -77.903075\n",
            "\n",
            "action probability =  [0.3069306930693069, 0.35070349140177176, 0.3423658155289213]\n",
            "buy =  0.41010943199583116  sell =  0.5898905680041688\n",
            "trade accuracy =  0.445\n",
            "epoch: 26, total rewards: 4521.000000, mean rewards: 56.541949\n",
            "\n",
            "action probability =  [0.3350703491401772, 0.2761855132881709, 0.3887441375716518]\n",
            "buy =  0.4611776967170401  sell =  0.5388223032829599\n",
            "trade accuracy =  0.47101449275362317\n",
            "epoch: 27, total rewards: 5508.000000, mean rewards: 68.885878\n",
            "\n",
            "action probability =  [0.47107868681605003, 0.20427305888483585, 0.32464825429911415]\n",
            "buy =  0.6545075560187598  sell =  0.34549244398124024\n",
            "trade accuracy =  0.4328767123287671\n",
            "epoch: 28, total rewards: 1888.000000, mean rewards: 23.612298\n",
            "\n",
            "action probability =  [0.33871808233454925, 0.3470557582073997, 0.3142261594580511]\n",
            "buy =  0.583637311099531  sell =  0.416362688900469\n",
            "trade accuracy =  0.36147757255936674\n",
            "epoch: 29, total rewards: -21424.000000, mean rewards: -267.939552\n",
            "\n",
            "action probability =  [0.42365815528921313, 0.33142261594580513, 0.24491922876498173]\n",
            "buy =  0.5351745700885878  sell =  0.4648254299114122\n",
            "trade accuracy =  0.4534005037783375\n",
            "epoch: 30, total rewards: -14932.000000, mean rewards: -186.747264\n",
            "\n",
            "action probability =  [0.32412714955706096, 0.3256904637832204, 0.3501823866597187]\n",
            "buy =  0.662324127149557  sell =  0.337675872850443\n",
            "trade accuracy =  0.38190954773869346\n",
            "epoch: 31, total rewards: -24274.000000, mean rewards: -303.583116\n",
            "\n",
            "action probability =  [0.22511724856696197, 0.4507556018759771, 0.324127149557061]\n",
            "buy =  0.28869202709744657  sell =  0.7113079729025534\n",
            "trade accuracy =  0.46633416458852867\n",
            "epoch: 32, total rewards: 14858.000000, mean rewards: 185.821782\n",
            "\n",
            "action probability =  [0.33611255862428346, 0.3491401771756123, 0.31474726420010424]\n",
            "buy =  0.3918707660239708  sell =  0.6081292339760291\n",
            "trade accuracy =  0.44476744186046513\n",
            "epoch: 33, total rewards: -1216.000000, mean rewards: -15.207921\n",
            "\n",
            "action probability =  [0.2589890568004169, 0.4038561750911933, 0.33715476810838974]\n",
            "buy =  0.4304325169359041  sell =  0.5695674830640959\n",
            "trade accuracy =  0.42592592592592593\n",
            "epoch: 34, total rewards: -10113.000000, mean rewards: -126.478374\n",
            "\n",
            "action probability =  [0.13705054715997916, 0.4517978113600834, 0.41115164147993744]\n",
            "buy =  0.2569046378322043  sell =  0.7430953621677957\n",
            "trade accuracy =  0.5401929260450161\n",
            "epoch: 35, total rewards: 2505.000000, mean rewards: 31.328817\n",
            "\n",
            "action probability =  [0.3126628452318916, 0.29598749348619074, 0.3913496612819176]\n",
            "buy =  0.6878582595101616  sell =  0.31214174048983845\n",
            "trade accuracy =  0.5212264150943396\n",
            "epoch: 36, total rewards: 18836.000000, mean rewards: 235.572694\n",
            "\n",
            "action probability =  [0.3423658155289213, 0.33559145388223033, 0.32204273058884836]\n",
            "buy =  0.6201146430432517  sell =  0.3798853569567483\n",
            "trade accuracy =  0.3967136150234742\n",
            "epoch: 37, total rewards: -19974.000000, mean rewards: -249.805107\n",
            "\n",
            "action probability =  [0.24752475247524752, 0.46221990620114645, 0.290255341323606]\n",
            "buy =  0.4179260031266285  sell =  0.5820739968733715\n",
            "trade accuracy =  0.42857142857142855\n",
            "epoch: 38, total rewards: -6434.000000, mean rewards: -80.466910\n",
            "\n",
            "action probability =  [0.21677957269411152, 0.4111516414799375, 0.37206878582595104]\n",
            "buy =  0.3402813965607087  sell =  0.6597186034392912\n",
            "trade accuracy =  0.3933933933933934\n",
            "epoch: 39, total rewards: -15849.000000, mean rewards: -198.215737\n",
            "\n",
            "action probability =  [0.30484627410109433, 0.3152683689421574, 0.3798853569567483]\n",
            "buy =  0.6367899947889526  sell =  0.3632100052110474\n",
            "trade accuracy =  0.47129909365558914\n",
            "epoch: 40, total rewards: 995.000000, mean rewards: 12.443981\n",
            "\n",
            "action probability =  [0.3236060448150078, 0.30536737884314746, 0.37102657634184477]\n",
            "buy =  0.631578947368421  sell =  0.368421052631579\n",
            "trade accuracy =  0.4594594594594595\n",
            "epoch: 41, total rewards: -4007.000000, mean rewards: -50.113601\n",
            "\n",
            "action probability =  [0.31735278791036997, 0.28817092235539343, 0.39447628973423665]\n",
            "buy =  0.3611255862428348  sell =  0.6388744137571651\n",
            "trade accuracy =  0.38954869358669836\n",
            "epoch: 42, total rewards: -14323.000000, mean rewards: -179.130797\n",
            "\n",
            "action probability =  [0.3559145388223033, 0.4283480979676915, 0.21573736321000525]\n",
            "buy =  0.4934861907243356  sell =  0.5065138092756645\n",
            "trade accuracy =  0.46588235294117647\n",
            "epoch: 43, total rewards: -5023.000000, mean rewards: -62.820219\n",
            "\n",
            "action probability =  [0.27670661803022406, 0.3699843668577384, 0.3533090151120375]\n",
            "buy =  0.5815528921313184  sell =  0.41844710786868156\n",
            "trade accuracy =  0.4828571428571429\n",
            "epoch: 44, total rewards: -7753.000000, mean rewards: -96.963002\n",
            "\n",
            "action probability =  [0.4632621156852527, 0.11412193850964043, 0.42261594580510686]\n",
            "buy =  0.6988014590932777  sell =  0.30119854090672227\n",
            "trade accuracy =  0.4498567335243553\n",
            "epoch: 45, total rewards: -12011.000000, mean rewards: -150.215737\n",
            "\n",
            "action probability =  [0.36216779572694113, 0.22824387701928087, 0.40958832725377803]\n",
            "buy =  0.6414799374674309  sell =  0.3585200625325691\n",
            "trade accuracy =  0.5\n",
            "epoch: 46, total rewards: 13676.000000, mean rewards: 171.039083\n",
            "\n",
            "action probability =  [0.3236060448150078, 0.3845752996352267, 0.2918186555497655]\n",
            "buy =  0.3892652423137051  sell =  0.6107347576862949\n",
            "trade accuracy =  0.46335697399527187\n",
            "epoch: 47, total rewards: -1294.000000, mean rewards: -16.183429\n",
            "\n",
            "action probability =  [0.3064095883272538, 0.3043251693590412, 0.3892652423137051]\n",
            "buy =  0.3460135487232934  sell =  0.6539864512767066\n",
            "trade accuracy =  0.5238095238095238\n",
            "epoch: 48, total rewards: 9774.000000, mean rewards: 122.238666\n",
            "\n",
            "action probability =  [0.11099531005732152, 0.416362688900469, 0.47264200104220944]\n",
            "buy =  0.3585200625325691  sell =  0.6414799374674309\n",
            "trade accuracy =  0.47191011235955055\n",
            "epoch: 49, total rewards: -7859.000000, mean rewards: -98.288692\n",
            "\n",
            "action probability =  [0.27722772277227725, 0.3225638353309015, 0.40020844189682125]\n",
            "buy =  0.4731631057842626  sell =  0.5268368942157373\n",
            "trade accuracy =  0.37822349570200575\n",
            "epoch: 50, total rewards: -13569.000000, mean rewards: -169.700886\n",
            "\n",
            "action probability =  [0.3632100052110474, 0.3064095883272538, 0.33038040646169886]\n",
            "buy =  0.5544554455445545  sell =  0.4455445544554455\n",
            "trade accuracy =  0.4325153374233129\n",
            "epoch: 51, total rewards: -3594.000000, mean rewards: -44.948411\n",
            "\n",
            "action probability =  [0.3064095883272538, 0.42157373632100054, 0.2720166753517457]\n",
            "buy =  0.3470557582073997  sell =  0.6529442417926004\n",
            "trade accuracy =  0.4897959183673469\n",
            "epoch: 52, total rewards: 180.000000, mean rewards: 2.251172\n",
            "\n",
            "action probability =  [0.22094841063053675, 0.43981240229286084, 0.3392391870766024]\n",
            "buy =  0.47837415320479415  sell =  0.5216258467952058\n",
            "trade accuracy =  0.4508670520231214\n",
            "epoch: 53, total rewards: -9878.000000, mean rewards: -123.539343\n",
            "\n",
            "action probability =  [0.3678999478895258, 0.25273579989577905, 0.37936425221469516]\n",
            "buy =  0.5653986451276707  sell =  0.4346013548723293\n",
            "trade accuracy =  0.42788461538461536\n",
            "epoch: 54, total rewards: 25613.000000, mean rewards: 320.329338\n",
            "\n",
            "action probability =  [0.31943720687858257, 0.3465346534653465, 0.3340281396560709]\n",
            "buy =  0.3757165190203231  sell =  0.6242834809796769\n",
            "trade accuracy =  0.4725274725274725\n",
            "epoch: 55, total rewards: 6236.000000, mean rewards: 77.990620\n",
            "\n",
            "action probability =  [0.1354872329338197, 0.39291297550807713, 0.47159979155810317]\n",
            "buy =  0.3397602918186555  sell =  0.6602397081813445\n",
            "trade accuracy =  0.3536977491961415\n",
            "epoch: 56, total rewards: -7840.000000, mean rewards: -98.051068\n",
            "\n",
            "action probability =  [0.40020844189682125, 0.2678478374153205, 0.33194372068785827]\n",
            "buy =  0.46951537258989057  sell =  0.5304846274101094\n",
            "trade accuracy =  0.45\n",
            "epoch: 57, total rewards: -5939.000000, mean rewards: -74.276186\n",
            "\n",
            "action probability =  [0.3225638353309015, 0.2985930171964565, 0.37884314747264203]\n",
            "buy =  0.4491922876498176  sell =  0.5508077123501824\n",
            "trade accuracy =  0.4520123839009288\n",
            "epoch: 58, total rewards: 16517.000000, mean rewards: 206.570089\n",
            "\n",
            "action probability =  [0.3324648254299114, 0.3376758728504429, 0.3298593017196456]\n",
            "buy =  0.6029181865554977  sell =  0.39708181344450233\n",
            "trade accuracy =  0.4606741573033708\n",
            "epoch: 59, total rewards: -5781.000000, mean rewards: -72.300156\n",
            "\n",
            "action probability =  [0.3449713392391871, 0.40906722251172484, 0.245961438249088]\n",
            "buy =  0.3658155289213132  sell =  0.6341844710786868\n",
            "trade accuracy =  0.4507042253521127\n",
            "epoch: 60, total rewards: -4756.000000, mean rewards: -59.480980\n",
            "\n",
            "action probability =  [0.33402813965607087, 0.4043772798332465, 0.26159458051068263]\n",
            "buy =  0.4507556018759771  sell =  0.5492443981240229\n",
            "trade accuracy =  0.5064935064935064\n",
            "epoch: 61, total rewards: 28663.000000, mean rewards: 358.474205\n",
            "\n",
            "action probability =  [0.23293381969775925, 0.43772798332464824, 0.3293381969775925]\n",
            "buy =  0.42886920270974466  sell =  0.5711307972902553\n",
            "trade accuracy =  0.5114942528735632\n",
            "epoch: 62, total rewards: -1725.000000, mean rewards: -21.573736\n",
            "\n",
            "action probability =  [0.31005732152162585, 0.31474726420010424, 0.37519541427826986]\n",
            "buy =  0.4517978113600834  sell =  0.5482021886399167\n",
            "trade accuracy =  0.3577075098814229\n",
            "epoch: 63, total rewards: -18225.000000, mean rewards: -227.931214\n",
            "\n",
            "action probability =  [0.3282959874934862, 0.2975508077123502, 0.3741532047941636]\n",
            "buy =  0.5961438249088067  sell =  0.4038561750911933\n",
            "trade accuracy =  0.45153061224489793\n",
            "epoch: 64, total rewards: 3812.000000, mean rewards: 47.674831\n",
            "\n",
            "action probability =  [0.31214174048983845, 0.3350703491401772, 0.35278791036998436]\n",
            "buy =  0.6117769671704012  sell =  0.3882230328295988\n",
            "trade accuracy =  0.39944903581267216\n",
            "epoch: 65, total rewards: -14917.000000, mean rewards: -186.559666\n",
            "\n",
            "action probability =  [0.2897342365815529, 0.2985930171964565, 0.4116727462219907]\n",
            "buy =  0.416362688900469  sell =  0.583637311099531\n",
            "trade accuracy =  0.4423076923076923\n",
            "epoch: 66, total rewards: 13204.000000, mean rewards: 165.136008\n",
            "\n",
            "action probability =  [0.22772277227722773, 0.4137571651902032, 0.3585200625325691]\n",
            "buy =  0.46899426784783743  sell =  0.5310057321521626\n",
            "trade accuracy =  0.5131578947368421\n",
            "epoch: 67, total rewards: -1481.000000, mean rewards: -18.522147\n",
            "\n",
            "action probability =  [0.2532569046378322, 0.42105263157894735, 0.32569046378322053]\n",
            "buy =  0.3986451276706618  sell =  0.6013548723293383\n",
            "trade accuracy =  0.4300254452926209\n",
            "epoch: 68, total rewards: -9448.000000, mean rewards: -118.161542\n",
            "\n",
            "action probability =  [0.42782699322563833, 0.35956227201667534, 0.21261073475768633]\n",
            "buy =  0.5586242834809797  sell =  0.4413757165190203\n",
            "trade accuracy =  0.5668789808917197\n",
            "epoch: 69, total rewards: 42123.000000, mean rewards: 526.811881\n",
            "\n",
            "action probability =  [0.334549244398124, 0.43564356435643564, 0.22980719124544036]\n",
            "buy =  0.4887962480458572  sell =  0.5112037519541428\n",
            "trade accuracy =  0.518796992481203\n",
            "epoch: 70, total rewards: 244.000000, mean rewards: 3.051589\n",
            "\n",
            "action probability =  [0.3491401771756123, 0.39603960396039606, 0.25482021886399164]\n",
            "buy =  0.4106305367378843  sell =  0.5893694632621157\n",
            "trade accuracy =  0.5733695652173914\n",
            "epoch: 71, total rewards: 8106.000000, mean rewards: 101.377801\n",
            "\n",
            "action probability =  [0.1959353830119854, 0.36216779572694113, 0.44189682126107344]\n",
            "buy =  0.2522146951537259  sell =  0.7477853048462741\n",
            "trade accuracy =  0.43686868686868685\n",
            "epoch: 72, total rewards: -8757.000000, mean rewards: -109.519541\n",
            "\n",
            "action probability =  [0.2699322563835331, 0.3069306930693069, 0.42313705054716]\n",
            "buy =  0.31943720687858257  sell =  0.6805627931214174\n",
            "trade accuracy =  0.43967828418230565\n",
            "epoch: 73, total rewards: -5433.000000, mean rewards: -67.947890\n",
            "\n",
            "action probability =  [0.2376237623762376, 0.40906722251172484, 0.3533090151120375]\n",
            "buy =  0.3564356435643564  sell =  0.6435643564356436\n",
            "trade accuracy =  0.45365853658536587\n",
            "epoch: 74, total rewards: -4829.000000, mean rewards: -60.393955\n",
            "\n",
            "action probability =  [0.20948410630536737, 0.42209484106305367, 0.368421052631579]\n",
            "buy =  0.4283480979676915  sell =  0.5716519020323085\n",
            "trade accuracy =  0.4765258215962441\n",
            "epoch: 75, total rewards: 3907.000000, mean rewards: 48.862949\n",
            "\n",
            "action probability =  [0.3887441375716519, 0.22980719124544033, 0.3814486711829078]\n",
            "buy =  0.5716519020323085  sell =  0.42834809796769147\n",
            "trade accuracy =  0.4689119170984456\n",
            "epoch: 76, total rewards: 2995.000000, mean rewards: 37.457009\n",
            "\n",
            "action probability =  [0.3256904637832204, 0.38822303282959875, 0.2860865033871809]\n",
            "buy =  0.5106826472120897  sell =  0.48931735278791033\n",
            "trade accuracy =  0.45374449339207046\n",
            "epoch: 77, total rewards: 3124.000000, mean rewards: 39.070349\n",
            "\n",
            "action probability =  [0.25482021886399164, 0.41479937467430955, 0.33038040646169886]\n",
            "buy =  0.5617509119332986  sell =  0.4382490880667014\n",
            "trade accuracy =  0.5\n",
            "epoch: 78, total rewards: 5609.000000, mean rewards: 70.149036\n",
            "\n",
            "action probability =  [0.10838978634705576, 0.45231891610213654, 0.43929129755080765]\n",
            "buy =  0.28348097967691505  sell =  0.7165190203230849\n",
            "trade accuracy =  0.4406779661016949\n",
            "epoch: 79, total rewards: 4792.000000, mean rewards: 59.931214\n",
            "\n",
            "action probability =  [0.39708181344450233, 0.2376237623762376, 0.36529442417926006]\n",
            "buy =  0.6618030224075039  sell =  0.3381969775924961\n",
            "trade accuracy =  0.32285714285714284\n",
            "epoch: 80, total rewards: -27419.000000, mean rewards: -342.916102\n",
            "\n",
            "action probability =  [0.37154768108389785, 0.2610734757686295, 0.3673788431474727]\n",
            "buy =  0.5789473684210527  sell =  0.42105263157894735\n",
            "trade accuracy =  0.4408866995073892\n",
            "epoch: 81, total rewards: -6770.000000, mean rewards: -84.669098\n",
            "\n",
            "action probability =  [0.08285565398645128, 0.47107868681605003, 0.44606565919749874]\n",
            "buy =  0.3126628452318916  sell =  0.6873371547681084\n",
            "trade accuracy =  0.5078864353312302\n",
            "epoch: 82, total rewards: 18476.000000, mean rewards: 231.070349\n",
            "\n",
            "action probability =  [0.43355914538822304, 0.41688379364252215, 0.1495570609692548]\n",
            "buy =  0.5059927045336112  sell =  0.4940072954663888\n",
            "trade accuracy =  0.45409429280397023\n",
            "epoch: 83, total rewards: -17882.000000, mean rewards: -223.641480\n",
            "\n",
            "action probability =  [0.16935904116727463, 0.4512767066180302, 0.37936425221469516]\n",
            "buy =  0.33402813965607087  sell =  0.6659718603439291\n",
            "trade accuracy =  0.4987405541561713\n",
            "epoch: 84, total rewards: -7128.000000, mean rewards: -89.146430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO884_K7OHzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit = np.array(neural_evolve.fitnesses).flatten()\n",
        "sort_fitness = np.argsort(neural_evolve.fitnesses,None)[::-1]\n",
        "print(sort_fitness)\n",
        "a = [neural_evolve.population[int(i)] for i in sort_fitness]\n",
        "# print(fit)\n",
        "[a.fitness for a in a]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RTJ5Ouzu54s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[i.fitness for i in neural_evolve.population]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}