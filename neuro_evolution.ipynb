{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuro evolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/neuro_evolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXpyhGyC4Cpk",
        "colab_type": "code",
        "outputId": "f401a891-30e3-442c-982b-36943c3553d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQVZCJv4FBu",
        "colab_type": "code",
        "outputId": "b1dfdbc8-f49c-4112-d6e9-459a88a85181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.24.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ta) (0.21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.16.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->ta) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecmHJge38IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from numba import jit as njit\n",
        "from functools import lru_cache\n",
        "import time\n",
        "import random\n",
        "import ta\n",
        "from net import *\n",
        "from memory import *\n",
        "from reward import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aanxg75uPulp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class neuralnetwork:\n",
        "    def __init__(self, id_, hidden_size = 128*2, window_size = 100*2, restore=False):\n",
        "        if restore:\n",
        "          f = open(\"./neuro_w.txt\",\"rb\")\n",
        "          weights = pickle.load(f)\n",
        "          self.W1 = weights[0]\n",
        "          self.W2 = weights[1]\n",
        "        else:\n",
        "          self.W1 = np.random.randn(window_size, hidden_size) / np.sqrt(window_size)\n",
        "          self.W2 = np.random.randn(hidden_size, 3) / np.sqrt(hidden_size)\n",
        "        self.fitness = 0\n",
        "        self.id = id_\n",
        "\n",
        "@njit\n",
        "def sigmoid(x):\n",
        "  x = 1 / (1 + np.exp(-x))\n",
        "  return x\n",
        "\n",
        "def swish(x):\n",
        "  x *= sigmoid(x)\n",
        "  return x\n",
        " \n",
        "def relu(X):\n",
        "    return np.maximum(X, 0)\n",
        "  \n",
        "@njit\n",
        "def softmax(X):\n",
        "    e_x = np.exp(X - np.max(X, axis=-1, keepdims=True))\n",
        "    e_x /= np.sum(e_x, axis=-1, keepdims=True)\n",
        "    return e_x\n",
        "  \n",
        "@njit\n",
        "def feed_forward(X, nets):\n",
        "    X = X.flatten().reshape(1,-1)\n",
        "    a1 = np.dot(X, nets.W1)\n",
        "    z1 = swish(a1)\n",
        "    a2 = np.dot(z1, nets.W2)\n",
        "    return softmax(a2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqWr3GfJCnzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuroEvolution:\n",
        "    def __init__(self, population_size, mutation_rate, model_generator, state_size, window_size, path, step_size, spread=10, pip_cost=1000, los_cut=20,restore=False):\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.model_generator = model_generator\n",
        "        self.state_size = state_size\n",
        "        self.window_size = window_size\n",
        "        self.path = path\n",
        "        self.step_size = step_size\n",
        "        self.spread = spread / pip_cost\n",
        "        self.pip_cost = pip_cost\n",
        "        self.los_cut = los_cut\n",
        "        self.restore = restore\n",
        "        self.preproc()\n",
        "        self.rewards = reward3\n",
        "        \n",
        "    def preproc(self):\n",
        "          self.dat = df = pd.read_csv(self.path)\n",
        "          s = np.asanyarray(ta.stoch(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1)) - np.asanyarray(ta.stoch_signal(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1))\n",
        "          x = np.asanyarray(ta.daily_log_return(df[\"Close\"])).reshape((-1,1))\n",
        "          m = np.asanyarray(ta.macd_diff(df[\"Close\"])).reshape((-1,1))\n",
        "          x = m\n",
        "#           x = np.concatenate([x,m], 1)\n",
        "          y = np.asanyarray(self.dat[[\"Open\"]])\n",
        "\n",
        "          gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x, y, self.window_size)\n",
        "          self.x = []\n",
        "          self.y = []\n",
        "          for i in gen:\n",
        "              self.x.extend(i[0].tolist())\n",
        "              self.y.extend(i[1].tolist())\n",
        "          self.x = np.asanyarray(self.x)\n",
        "          self.y = np.asanyarray(self.y)\n",
        "\n",
        "          self.df = self.x[-self.step_size::]\n",
        "          self.trend = self.y[-self.step_size::]\n",
        "\n",
        "    def _initialize_population(self):\n",
        "        self.population = []\n",
        "        for i in range(self.population_size):\n",
        "            self.population.append(self.model_generator(i,window_size = self.window_size*self.df.shape[-1], restore=self.restore))\n",
        "    \n",
        "    def mutate(self, individual, scale=1.0):\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W1.shape)\n",
        "        individual.W1 += np.random.normal(loc=0, scale=scale, size=individual.W1.shape) * mutation_mask\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W2.shape)\n",
        "        individual.W2 += np.random.normal(loc=0, scale=scale, size=individual.W2.shape) * mutation_mask\n",
        "        return individual\n",
        "    \n",
        "    def inherit_weights(self, parent, child):\n",
        "        child.W1 = parent.W1.copy()\n",
        "        child.W2 = parent.W2.copy()\n",
        "        return child\n",
        "    \n",
        "    def crossover(self, parent1, parent2):\n",
        "        child1 = self.model_generator((parent1.id+1)*10)\n",
        "        child1 = self.inherit_weights(parent1, child1)\n",
        "        child2 = self.model_generator((parent2.id+1)*10)\n",
        "        child2 = self.inherit_weights(parent2, child2)\n",
        "        # first W\n",
        "        n_neurons = child1.W1.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W1[:, cutoff:] = parent2.W1[:, cutoff:].copy()\n",
        "        child2.W1[:, cutoff:] = parent1.W1[:, cutoff:].copy()\n",
        "        # second W\n",
        "        n_neurons = child1.W2.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W2[:, cutoff:] = parent2.W2[:, cutoff:].copy()\n",
        "        child2.W2[:, cutoff:] = parent1.W2[:, cutoff:].copy()\n",
        "        return child1, child2\n",
        "    \n",
        "    def act(self, p, state):\n",
        "        logits = feed_forward(state, p)\n",
        "        return np.argmax(logits, 1)[0]\n",
        "#         return np.argmax(logits[0])\n",
        "    \n",
        "    def test(self, individual, i):\n",
        "        states = []\n",
        "        pip = []\n",
        "        history = []\n",
        "        h_p = []\n",
        "        provisional_pip = []\n",
        "        total_pip = 0.0\n",
        "        position = 3\n",
        "        h = self.h\n",
        "#         h = np.random.randint(100,self.x.shape[0]-(self.step_size*20))\n",
        "#         self.df = self.x[h+self.step_size:h+self.step_size*2]\n",
        "#         self.trend = self.y[h+self.step_size:h+self.step_size*2]\n",
        "        for t in range(0, len(self.trend) - 1):\n",
        "            action = self.act(individual, self.df[t])\n",
        "            history.append(action)\n",
        "            states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,action,\n",
        "                                                                     position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/1000)\n",
        "#             print(len(provisional_pip))\n",
        "            h_p.append(position)\n",
        "        self.pip = np.asanyarray(provisional_pip) * self.pip_cost\n",
        "        self.pip = [p if p >= -self.los_cut else -self.los_cut for p in self.pip]\n",
        "        self.total_pip = np.sum(self.pip)\n",
        "        mean_pip = self.total_pip / (t + 1)\n",
        "        trade_accuracy = np.mean(np.asanyarray(self.pip) > 0)\n",
        "        self.trade = trade_accuracy\n",
        "        mean_pip *= 24\n",
        "        prob = self.prob(history)\n",
        "        position_prob = self.prob(h_p)\n",
        "      \n",
        "        print(\"\")\n",
        "        print('action probability = ', prob)\n",
        "        print(\"buy = \", position_prob[1], \" sell = \", position_prob[-1])\n",
        "        print('trade accuracy = ', trade_accuracy)\n",
        "        print('epoch: %d, total rewards: %f, mean rewards: %f' % (i+1, float(self.total_pip), float(mean_pip)))\n",
        "    \n",
        "    def calculate_fitness(self):\n",
        "        change = True\n",
        "        for i in range(self.population_size):\n",
        "          states = []\n",
        "          pip = []\n",
        "          provisional_pip = []\n",
        "          total_pip = 0.0\n",
        "          position = 3\n",
        "          if change:\n",
        "            change = False\n",
        "            self.h = h = np.random.randint(self.x.shape[0]-(self.step_size+1))\n",
        "            self.df = self.x[h:h+self.step_size]\n",
        "            self.trend = self.y[h:h+self.step_size]\n",
        "          for t in range(0, len(self.trend) - 1):\n",
        "              action = self.act(self.population[i], self.df[t])\n",
        "              states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,\n",
        "                                                                       action,position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/1000)\n",
        "          invest = total_pip * self.pip_cost\n",
        "          trade_accuracy = np.mean(np.asanyarray(provisional_pip) > 0) * 100\n",
        "          self.population[i].fitness = trade_accuracy\n",
        "    \n",
        "    def prob(self,history):\n",
        "        prob = np.asanyarray(history)\n",
        "        a = np.mean(prob == 0)\n",
        "        b = np.mean(prob == 1)\n",
        "        c = 1 - (a + b)\n",
        "        prob = [a,b,c]\n",
        "        return prob\n",
        "    \n",
        "    def evolve(self, generations=20, checkpoint= 5):\n",
        "        self._initialize_population()\n",
        "        n_winners = int(self.population_size * 0.6)\n",
        "        n_parents = self.population_size - n_winners\n",
        "        for epoch in range(generations):\n",
        "            self.calculate_fitness()\n",
        "            self.fitnesses = fitnesses = [i.fitness for i in self.population]\n",
        "            fitnesses = np.array(neural_evolve.fitnesses).flatten()\n",
        "            self.sort_fitness = sort_fitness = np.argsort(neural_evolve.fitnesses,None)[::-1]\n",
        "            self.population = [self.population[int(i)] for i in sort_fitness]\n",
        "            fittest_individual = self.population[0]\n",
        "            if (epoch+1) % checkpoint == 0:\n",
        "                self.test(fittest_individual, epoch)\n",
        "                save = [fittest_individual.W1, fittest_individual.W2]\n",
        "                f = open('neuro_w.txt', 'wb')\n",
        "                pickle.dump(save, f)\n",
        "            \n",
        "            next_population = [self.population[i] for i in range(n_winners)]\n",
        "            total_fitness = np.sum([np.abs(i.fitness) for i in self.population])\n",
        "            parent_probabilities = [np.abs(i.fitness / total_fitness) for i in self.population]\n",
        "            sort_probabilities = np.argsort(parent_probabilities,None).reshape(-1,1)\n",
        "            parent_probabilities = [parent_probabilities[int(i)] for i in sort_probabilities]\n",
        "            parent_probabilities = np.array(parent_probabilities).flatten()\n",
        "            parent_probabilities = np.nan_to_num(parent_probabilities)\n",
        "            parents = np.random.choice(self.population, size=n_parents, p=parent_probabilities, replace=False)\n",
        "            for i in np.arange(0, len(parents), 2):\n",
        "                child1, child2 = self.crossover(parents[i], parents[i+1])\n",
        "                next_population += [self.mutate(child1), self.mutate(child2)]\n",
        "            self.population = next_population\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9P8UX85cA5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_size = 100\n",
        "generations = 100\n",
        "mutation_rate = 0.1\n",
        "window_size = 30\n",
        "step_size = 96\n",
        "los_cut = 300\n",
        "restore = False\n",
        "path = \"audpred15.csv\"\n",
        "\n",
        "neural_evolve = NeuroEvolution(population_size, mutation_rate, neuralnetwork,\n",
        "                              window_size, window_size, path, step_size,restore=restore, los_cut=los_cut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7qzzh4XkslF",
        "colab_type": "code",
        "outputId": "74f00daf-07eb-48cd-da97-5bed243159e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fittest_nets = neural_evolve.evolve(50000,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "action probability =  [0.3368421052631579, 0.42105263157894735, 0.24210526315789482]\n",
            "buy =  0.5789473684210527  sell =  0.42105263157894735\n",
            "trade accuracy =  0.7096774193548387\n",
            "epoch: 1, total rewards: 2470.000000, mean rewards: 624.000000\n",
            "\n",
            "action probability =  [0.15789473684210525, 0.4631578947368421, 0.3789473684210527]\n",
            "buy =  0.16842105263157894  sell =  0.8315789473684211\n",
            "trade accuracy =  0.8235294117647058\n",
            "epoch: 2, total rewards: 1944.000000, mean rewards: 491.115789\n",
            "\n",
            "action probability =  [0.16842105263157894, 0.30526315789473685, 0.5263157894736842]\n",
            "buy =  0.16842105263157894  sell =  0.8315789473684211\n",
            "trade accuracy =  0.875\n",
            "epoch: 3, total rewards: 4194.000000, mean rewards: 1059.536842\n",
            "\n",
            "action probability =  [0.031578947368421054, 0.5263157894736842, 0.4421052631578948]\n",
            "buy =  0.031578947368421054  sell =  0.968421052631579\n",
            "trade accuracy =  0.9411764705882353\n",
            "epoch: 4, total rewards: 2282.000000, mean rewards: 576.505263\n",
            "\n",
            "action probability =  [0.23157894736842105, 0.35789473684210527, 0.41052631578947363]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.64\n",
            "epoch: 5, total rewards: 1142.000000, mean rewards: 288.505263\n",
            "\n",
            "action probability =  [0.15789473684210525, 0.5263157894736842, 0.3157894736842106]\n",
            "buy =  0.35789473684210527  sell =  0.6421052631578947\n",
            "trade accuracy =  0.6333333333333333\n",
            "epoch: 6, total rewards: 9539.000000, mean rewards: 2409.852632\n",
            "\n",
            "action probability =  [0.3157894736842105, 0.30526315789473685, 0.3789473684210527]\n",
            "buy =  0.5368421052631579  sell =  0.4631578947368421\n",
            "trade accuracy =  0.75\n",
            "epoch: 7, total rewards: 4636.000000, mean rewards: 1171.200000\n",
            "\n",
            "action probability =  [0.3368421052631579, 0.22105263157894736, 0.4421052631578948]\n",
            "buy =  0.7473684210526316  sell =  0.25263157894736843\n",
            "trade accuracy =  0.8461538461538461\n",
            "epoch: 8, total rewards: 3125.000000, mean rewards: 789.473684\n",
            "\n",
            "action probability =  [0.14736842105263157, 0.29473684210526313, 0.5578947368421053]\n",
            "buy =  0.2631578947368421  sell =  0.736842105263158\n",
            "trade accuracy =  0.8\n",
            "epoch: 9, total rewards: 11402.000000, mean rewards: 2880.505263\n",
            "\n",
            "action probability =  [0.45263157894736844, 0.3684210526315789, 0.17894736842105263]\n",
            "buy =  0.45263157894736844  sell =  0.5473684210526315\n",
            "trade accuracy =  0.7419354838709677\n",
            "epoch: 10, total rewards: 5773.000000, mean rewards: 1458.442105\n",
            "\n",
            "action probability =  [0.5263157894736842, 0.28421052631578947, 0.18947368421052635]\n",
            "buy =  0.6210526315789474  sell =  0.3789473684210526\n",
            "trade accuracy =  0.75\n",
            "epoch: 11, total rewards: 4418.000000, mean rewards: 1116.126316\n",
            "\n",
            "action probability =  [0.28421052631578947, 0.5052631578947369, 0.21052631578947367]\n",
            "buy =  0.45263157894736844  sell =  0.5473684210526315\n",
            "trade accuracy =  0.8095238095238095\n",
            "epoch: 12, total rewards: 3748.000000, mean rewards: 946.863158\n",
            "\n",
            "action probability =  [0.2631578947368421, 0.29473684210526313, 0.4421052631578948]\n",
            "buy =  0.2631578947368421  sell =  0.736842105263158\n",
            "trade accuracy =  0.8125\n",
            "epoch: 13, total rewards: 989.000000, mean rewards: 249.852632\n",
            "\n",
            "action probability =  [0.3368421052631579, 0.3368421052631579, 0.3263157894736842]\n",
            "buy =  0.6631578947368421  sell =  0.33684210526315794\n",
            "trade accuracy =  0.8695652173913043\n",
            "epoch: 14, total rewards: 2429.000000, mean rewards: 613.642105\n",
            "\n",
            "action probability =  [0.3368421052631579, 0.42105263157894735, 0.24210526315789482]\n",
            "buy =  0.3368421052631579  sell =  0.6631578947368422\n",
            "trade accuracy =  0.7368421052631579\n",
            "epoch: 15, total rewards: 3166.000000, mean rewards: 799.831579\n",
            "\n",
            "action probability =  [0.5578947368421052, 0.09473684210526316, 0.34736842105263166]\n",
            "buy =  0.631578947368421  sell =  0.368421052631579\n",
            "trade accuracy =  0.8125\n",
            "epoch: 16, total rewards: 1416.000000, mean rewards: 357.726316\n",
            "\n",
            "action probability =  [0.25263157894736843, 0.15789473684210525, 0.5894736842105264]\n",
            "buy =  0.7263157894736842  sell =  0.27368421052631575\n",
            "trade accuracy =  0.7647058823529411\n",
            "epoch: 17, total rewards: 735.000000, mean rewards: 185.684211\n",
            "\n",
            "action probability =  [0.28421052631578947, 0.35789473684210527, 0.35789473684210527]\n",
            "buy =  0.5368421052631579  sell =  0.4631578947368421\n",
            "trade accuracy =  0.76\n",
            "epoch: 18, total rewards: 2136.000000, mean rewards: 539.621053\n",
            "\n",
            "action probability =  [0.3684210526315789, 0.2, 0.43157894736842106]\n",
            "buy =  0.7473684210526316  sell =  0.25263157894736843\n",
            "trade accuracy =  0.6363636363636364\n",
            "epoch: 19, total rewards: 400.000000, mean rewards: 101.052632\n",
            "\n",
            "action probability =  [0.1368421052631579, 0.35789473684210527, 0.5052631578947369]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.8275862068965517\n",
            "epoch: 20, total rewards: 6424.000000, mean rewards: 1622.905263\n",
            "\n",
            "action probability =  [0.2736842105263158, 0.3684210526315789, 0.35789473684210527]\n",
            "buy =  0.5894736842105263  sell =  0.41052631578947374\n",
            "trade accuracy =  0.8\n",
            "epoch: 21, total rewards: 2637.000000, mean rewards: 666.189474\n",
            "\n",
            "action probability =  [0.24210526315789474, 0.28421052631578947, 0.4736842105263158]\n",
            "buy =  0.24210526315789474  sell =  0.7578947368421053\n",
            "trade accuracy =  0.9285714285714286\n",
            "epoch: 22, total rewards: 2100.000000, mean rewards: 530.526316\n",
            "\n",
            "action probability =  [0.3263157894736842, 0.3894736842105263, 0.28421052631578947]\n",
            "buy =  0.3263157894736842  sell =  0.6736842105263158\n",
            "trade accuracy =  0.7941176470588235\n",
            "epoch: 23, total rewards: 2964.000000, mean rewards: 748.800000\n",
            "\n",
            "action probability =  [0.42105263157894735, 0.24210526315789474, 0.33684210526315794]\n",
            "buy =  0.42105263157894735  sell =  0.5789473684210527\n",
            "trade accuracy =  0.8\n",
            "epoch: 24, total rewards: 2092.000000, mean rewards: 528.505263\n",
            "\n",
            "action probability =  [0.16842105263157894, 0.3473684210526316, 0.4842105263157894]\n",
            "buy =  0.25263157894736843  sell =  0.7473684210526316\n",
            "trade accuracy =  0.7647058823529411\n",
            "epoch: 25, total rewards: 2544.000000, mean rewards: 642.694737\n",
            "\n",
            "action probability =  [0.23157894736842105, 0.24210526315789474, 0.5263157894736842]\n",
            "buy =  0.3368421052631579  sell =  0.6631578947368422\n",
            "trade accuracy =  0.7894736842105263\n",
            "epoch: 26, total rewards: 2489.000000, mean rewards: 628.800000\n",
            "\n",
            "action probability =  [0.3473684210526316, 0.3263157894736842, 0.3263157894736841]\n",
            "buy =  0.5157894736842106  sell =  0.4842105263157894\n",
            "trade accuracy =  0.6190476190476191\n",
            "epoch: 27, total rewards: 942.000000, mean rewards: 237.978947\n",
            "\n",
            "action probability =  [0.29473684210526313, 0.28421052631578947, 0.42105263157894735]\n",
            "buy =  0.3263157894736842  sell =  0.6736842105263158\n",
            "trade accuracy =  0.8333333333333334\n",
            "epoch: 28, total rewards: 3257.000000, mean rewards: 822.821053\n",
            "\n",
            "action probability =  [0.28421052631578947, 0.35789473684210527, 0.35789473684210527]\n",
            "buy =  0.29473684210526313  sell =  0.7052631578947368\n",
            "trade accuracy =  0.7777777777777778\n",
            "epoch: 29, total rewards: 3116.000000, mean rewards: 787.200000\n",
            "\n",
            "action probability =  [0.4, 0.3368421052631579, 0.26315789473684204]\n",
            "buy =  0.42105263157894735  sell =  0.5789473684210527\n",
            "trade accuracy =  0.8064516129032258\n",
            "epoch: 30, total rewards: 4695.000000, mean rewards: 1186.105263\n",
            "\n",
            "action probability =  [0.23157894736842105, 0.3473684210526316, 0.42105263157894735]\n",
            "buy =  0.4631578947368421  sell =  0.5368421052631579\n",
            "trade accuracy =  0.8\n",
            "epoch: 31, total rewards: 4169.000000, mean rewards: 1053.221053\n",
            "\n",
            "action probability =  [0.25263157894736843, 0.11578947368421053, 0.631578947368421]\n",
            "buy =  0.8842105263157894  sell =  0.11578947368421055\n",
            "trade accuracy =  0.8181818181818182\n",
            "epoch: 32, total rewards: 1480.000000, mean rewards: 373.894737\n",
            "\n",
            "action probability =  [0.28421052631578947, 0.3263157894736842, 0.3894736842105263]\n",
            "buy =  0.3473684210526316  sell =  0.6526315789473685\n",
            "trade accuracy =  0.6190476190476191\n",
            "epoch: 33, total rewards: 437.000000, mean rewards: 110.400000\n",
            "\n",
            "action probability =  [0.18947368421052632, 0.2736842105263158, 0.5368421052631579]\n",
            "buy =  0.2631578947368421  sell =  0.736842105263158\n",
            "trade accuracy =  0.6956521739130435\n",
            "epoch: 34, total rewards: 2682.000000, mean rewards: 677.557895\n",
            "\n",
            "action probability =  [0.24210526315789474, 0.4, 0.35789473684210527]\n",
            "buy =  0.3684210526315789  sell =  0.631578947368421\n",
            "trade accuracy =  0.9\n",
            "epoch: 35, total rewards: 2789.000000, mean rewards: 704.589474\n",
            "\n",
            "action probability =  [0.4421052631578947, 0.4, 0.1578947368421053]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.8888888888888888\n",
            "epoch: 36, total rewards: 3771.000000, mean rewards: 952.673684\n",
            "\n",
            "action probability =  [0.3473684210526316, 0.21052631578947367, 0.4421052631578948]\n",
            "buy =  0.4631578947368421  sell =  0.5368421052631579\n",
            "trade accuracy =  0.85\n",
            "epoch: 37, total rewards: 1259.000000, mean rewards: 318.063158\n",
            "\n",
            "action probability =  [0.3894736842105263, 0.2736842105263158, 0.33684210526315783]\n",
            "buy =  0.45263157894736844  sell =  0.5473684210526315\n",
            "trade accuracy =  0.9166666666666666\n",
            "epoch: 38, total rewards: 4987.000000, mean rewards: 1259.873684\n",
            "\n",
            "action probability =  [0.29473684210526313, 0.3368421052631579, 0.368421052631579]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.72\n",
            "epoch: 39, total rewards: 5416.000000, mean rewards: 1368.252632\n",
            "\n",
            "action probability =  [0.25263157894736843, 0.4631578947368421, 0.28421052631578947]\n",
            "buy =  0.28421052631578947  sell =  0.7157894736842105\n",
            "trade accuracy =  0.7647058823529411\n",
            "epoch: 40, total rewards: 743.000000, mean rewards: 187.705263\n",
            "\n",
            "action probability =  [0.42105263157894735, 0.3157894736842105, 0.26315789473684215]\n",
            "buy =  0.5368421052631579  sell =  0.4631578947368421\n",
            "trade accuracy =  0.7741935483870968\n",
            "epoch: 41, total rewards: 3283.000000, mean rewards: 829.389474\n",
            "\n",
            "action probability =  [0.22105263157894736, 0.5473684210526316, 0.231578947368421]\n",
            "buy =  0.22105263157894736  sell =  0.7789473684210526\n",
            "trade accuracy =  0.6923076923076923\n",
            "epoch: 42, total rewards: 1128.000000, mean rewards: 284.968421\n",
            "\n",
            "action probability =  [0.3684210526315789, 0.5894736842105263, 0.04210526315789487]\n",
            "buy =  0.4105263157894737  sell =  0.5894736842105264\n",
            "trade accuracy =  0.8\n",
            "epoch: 43, total rewards: 6566.000000, mean rewards: 1658.778947\n",
            "\n",
            "action probability =  [0.10526315789473684, 0.4, 0.49473684210526314]\n",
            "buy =  0.2736842105263158  sell =  0.7263157894736842\n",
            "trade accuracy =  0.8333333333333334\n",
            "epoch: 44, total rewards: 3359.000000, mean rewards: 848.589474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO884_K7OHzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit = np.array(neural_evolve.fitnesses).flatten()\n",
        "sort_fitness = np.argsort(neural_evolve.fitnesses,None)[::-1]\n",
        "print(sort_fitness)\n",
        "a = [neural_evolve.population[int(i)] for i in sort_fitness]\n",
        "# print(fit)\n",
        "[a.fitness for a in a]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RTJ5Ouzu54s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[i.fitness for i in neural_evolve.population]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}