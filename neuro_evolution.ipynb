{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuro evolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/neuro_evolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXpyhGyC4Cpk",
        "colab_type": "code",
        "outputId": "fd255125-3e54-4d17-d5f9-7018c0222983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQVZCJv4FBu",
        "colab_type": "code",
        "outputId": "367b1262-1d7b-4c69-e9c7-66446ecfac1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.16.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ta) (0.21.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.5.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->ta) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecmHJge38IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from numba import jit as njit\n",
        "from functools import lru_cache\n",
        "import time\n",
        "import random\n",
        "import ta\n",
        "from net import *\n",
        "from memory import *\n",
        "from reward import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aanxg75uPulp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class neuralnetwork:\n",
        "    def __init__(self, id_, hidden_size = 128):\n",
        "        self.W1 = np.random.randn(window_size, hidden_size) / np.sqrt(window_size)\n",
        "        self.W2 = np.random.randn(hidden_size, 3) / np.sqrt(hidden_size)\n",
        "        self.fitness = 0\n",
        "        self.id = id_\n",
        "\n",
        "@njit\n",
        "def sigmoid(x):\n",
        "  x = 1 / (1 + np.exp(-x))\n",
        "  return x\n",
        "\n",
        "def swish(x):\n",
        "  x *= sigmoid(x)\n",
        "  return x\n",
        " \n",
        "@njit\n",
        "def softmax(X):\n",
        "    e_x = np.exp(X - np.max(X, axis=-1, keepdims=True))\n",
        "    e_x /= np.sum(e_x, axis=-1, keepdims=True)\n",
        "    return e_x\n",
        "  \n",
        "@njit\n",
        "def feed_forward(X, nets):\n",
        "    X = X.flatten().reshape(1,-1)\n",
        "    a1 = np.dot(X, nets.W1)\n",
        "    z1 = swish(a1)\n",
        "    a2 = np.dot(z1, nets.W2)\n",
        "    return softmax(a2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqWr3GfJCnzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuroEvolution:\n",
        "    def __init__(self, population_size, mutation_rate, model_generator, state_size, window_size, path, step_size, spread=10, pip_cost=1000, los_cut=100):\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.model_generator = model_generator\n",
        "        self.state_size = state_size\n",
        "        self.window_size = window_size\n",
        "        self.path = path\n",
        "        self.step_size = step_size\n",
        "        self.spread = spread / pip_cost\n",
        "        self.pip_cost = pip_cost\n",
        "        self.los_cut = los_cut\n",
        "        self.preproc()\n",
        "        self.rewards = reward3\n",
        "        \n",
        "    def preproc(self):\n",
        "          self.dat = df = pd.read_csv(self.path)\n",
        "#           x = np.asanyarray(ta.stoch(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1)) - np.asanyarray(ta.stoch_signal(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1))\n",
        "          x = np.asanyarray(ta.daily_return(df[\"Close\"])).reshape((-1,1))\n",
        "          y = np.asanyarray(self.dat[[\"Open\"]])\n",
        "\n",
        "          gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x, y, self.window_size)\n",
        "          self.x = []\n",
        "          self.y = []\n",
        "          for i in gen:\n",
        "              self.x.extend(i[0].tolist())\n",
        "              self.y.extend(i[1].tolist())\n",
        "          self.x = np.asanyarray(self.x)\n",
        "          self.y = np.asanyarray(self.y)\n",
        "\n",
        "          self.df = self.x[-self.step_size::]\n",
        "          self.trend = self.y[-self.step_size::]\n",
        "\n",
        "    def _initialize_population(self):\n",
        "        self.population = []\n",
        "        for i in range(self.population_size):\n",
        "            self.population.append(self.model_generator(i))\n",
        "    \n",
        "    def mutate(self, individual, scale=1.0):\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W1.shape)\n",
        "        individual.W1 += np.random.normal(loc=0, scale=scale, size=individual.W1.shape) * mutation_mask\n",
        "        mutation_mask = np.random.binomial(1, p=self.mutation_rate, size=individual.W2.shape)\n",
        "        individual.W2 += np.random.normal(loc=0, scale=scale, size=individual.W2.shape) * mutation_mask\n",
        "        return individual\n",
        "    \n",
        "    def inherit_weights(self, parent, child):\n",
        "        child.W1 = parent.W1.copy()\n",
        "        child.W2 = parent.W2.copy()\n",
        "        return child\n",
        "    \n",
        "    def crossover(self, parent1, parent2):\n",
        "        child1 = self.model_generator((parent1.id+1)*10)\n",
        "        child1 = self.inherit_weights(parent1, child1)\n",
        "        child2 = self.model_generator((parent2.id+1)*10)\n",
        "        child2 = self.inherit_weights(parent2, child2)\n",
        "        # first W\n",
        "        n_neurons = child1.W1.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W1[:, cutoff:] = parent2.W1[:, cutoff:].copy()\n",
        "        child2.W1[:, cutoff:] = parent1.W1[:, cutoff:].copy()\n",
        "        # second W\n",
        "        n_neurons = child1.W2.shape[1]\n",
        "        cutoff = np.random.randint(0, n_neurons)\n",
        "        child1.W2[:, cutoff:] = parent2.W2[:, cutoff:].copy()\n",
        "        child2.W2[:, cutoff:] = parent1.W2[:, cutoff:].copy()\n",
        "        return child1, child2\n",
        "    \n",
        "    def act(self, p, state):\n",
        "        logits = feed_forward(state, p)\n",
        "        return np.argmax(logits, 1)[0]\n",
        "#         return np.argmax(logits[0])\n",
        "    \n",
        "    def test(self, individual, i):\n",
        "        states = []\n",
        "        pip = []\n",
        "        history = []\n",
        "        h_p = []\n",
        "        provisional_pip = []\n",
        "        total_pip = 0.0\n",
        "        position = 3\n",
        "        h = np.random.randint(self.x.shape[0]-(self.step_size+1))\n",
        "        self.df = self.x[h:h+self.step_size]\n",
        "        self.trend = self.y[h:h+self.step_size]\n",
        "        for t in range(0, len(self.trend) - 1):\n",
        "            action = self.act(individual, self.df[t])\n",
        "            history.append(action)\n",
        "            states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,action,position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/2/1000)\n",
        "#             print(len(provisional_pip))\n",
        "            h_p.append(position)\n",
        "        self.pip = np.asanyarray(provisional_pip) * self.pip_cost\n",
        "        self.pip = [p if p >= -self.los_cut else -self.los_cut for p in self.pip]\n",
        "        self.total_pip = np.sum(self.pip)\n",
        "        mean_pip = self.total_pip / (t + 1)\n",
        "        trade_accuracy = np.mean(np.asanyarray(self.pip) > 0)\n",
        "        self.trade = trade_accuracy\n",
        "        mean_pip *= 24\n",
        "        prob = self.prob(history)\n",
        "        position_prob = self.prob(h_p)\n",
        "      \n",
        "        print(\"\")\n",
        "        print('action probability = ', prob)\n",
        "        print(\"buy = \", position_prob[1], \" sell = \", position_prob[-1])\n",
        "        print('trade accuracy = ', trade_accuracy)\n",
        "        print('epoch: %d, total rewards: %f, mean rewards: %f' % (i+1, float(self.total_pip), float(mean_pip)))\n",
        "    \n",
        "    def calculate_fitness(self):\n",
        "        for i in range(self.population_size):\n",
        "          states = []\n",
        "          pip = []\n",
        "          provisional_pip = []\n",
        "          total_pip = 0.0\n",
        "          position = 3\n",
        "#           h = np.random.randint(self.x.shape[0]-(self.step_size+1))\n",
        "#           self.df = self.x[h:h+self.step_size]\n",
        "#           self.trend = self.y[h:h+self.step_size]\n",
        "          for t in range(0, len(self.trend) - 1):\n",
        "              action = self.act(self.population[i], self.df[t])\n",
        "              states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,action,position,states,self.pip_cost,self.spread,total_pip,lc=self.los_cut/2/1000)\n",
        "          invest = total_pip * self.pip_cost\n",
        "          self.population[i].fitness = invest\n",
        "    \n",
        "    def prob(self,history):\n",
        "        prob = np.asanyarray(history)\n",
        "        a = np.mean(prob == 0)\n",
        "        b = np.mean(prob == 1)\n",
        "        c = 1 - (a + b)\n",
        "        prob = [a,b,c]\n",
        "        return prob\n",
        "    \n",
        "    def evolve(self, generations=20, checkpoint= 1):\n",
        "        self._initialize_population()\n",
        "        n_winners = int(self.population_size * 0.4)\n",
        "        n_parents = self.population_size - n_winners\n",
        "        for epoch in range(generations):\n",
        "            self.calculate_fitness()\n",
        "            self.fitnesses = fitnesses = [i.fitness for i in self.population]\n",
        "            self.sort_fitness = sort_fitness = np.argsort(fitnesses,None).reshape(-1,1)\n",
        "            self.population = [self.population[int(i)] for i in sort_fitness]\n",
        "            fittest_individual = self.population[0]\n",
        "            if (epoch+1) % checkpoint == 0:\n",
        "                self.test(fittest_individual, epoch)\n",
        "                save = [fittest_individual.W1, fittest_individual.W2]\n",
        "                f = open('neuro_w.txt', 'wb')\n",
        "                pickle.dump(save, f)\n",
        "            next_population = [self.population[i] for i in range(n_winners)]\n",
        "            total_fitness = np.sum([np.abs(i.fitness) for i in self.population])\n",
        "            parent_probabilities = [np.abs(i.fitness / total_fitness) for i in self.population]\n",
        "            parent_probabilities = np.array(parent_probabilities).flatten()\n",
        "            parents = np.random.choice(self.population, size=n_parents, p=parent_probabilities, replace=False)\n",
        "            for i in np.arange(0, len(parents), 2):\n",
        "                child1, child2 = self.crossover(parents[i], parents[i+1])\n",
        "                next_population += [self.mutate(child1), self.mutate(child2)]\n",
        "            self.population = next_population\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9P8UX85cA5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_size = 1000\n",
        "generations = 100\n",
        "mutation_rate = 0.1\n",
        "window_size = 30\n",
        "step_size = 96\n",
        "path = \"audpred15.csv\"\n",
        "\n",
        "neural_evolve = NeuroEvolution(population_size, mutation_rate, neuralnetwork,\n",
        "                              window_size, window_size, path, step_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7qzzh4XkslF",
        "colab_type": "code",
        "outputId": "f9a474a7-66d3-4fb6-cdd9-4537bdc197f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fittest_nets = neural_evolve.evolve(50000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "action probability =  [0.3473684210526316, 0.2736842105263158, 0.3789473684210526]\n",
            "buy =  0.6105263157894737  sell =  0.3894736842105263\n",
            "trade accuracy =  0.36363636363636365\n",
            "epoch: 1, total rewards: 484.000000, mean rewards: 122.273684\n",
            "\n",
            "action probability =  [0.18947368421052632, 0.35789473684210527, 0.4526315789473684]\n",
            "buy =  0.28421052631578947  sell =  0.7157894736842105\n",
            "trade accuracy =  0.5070422535211268\n",
            "epoch: 2, total rewards: 2904.000000, mean rewards: 733.642105\n",
            "\n",
            "action probability =  [0.3368421052631579, 0.22105263157894736, 0.4421052631578948]\n",
            "buy =  0.6210526315789474  sell =  0.3789473684210526\n",
            "trade accuracy =  0.5294117647058824\n",
            "epoch: 3, total rewards: 2038.000000, mean rewards: 514.863158\n",
            "\n",
            "action probability =  [0.30526315789473685, 0.2736842105263158, 0.42105263157894735]\n",
            "buy =  0.5263157894736842  sell =  0.4736842105263158\n",
            "trade accuracy =  0.417910447761194\n",
            "epoch: 4, total rewards: -396.000000, mean rewards: -100.042105\n",
            "\n",
            "action probability =  [0.3684210526315789, 0.2631578947368421, 0.368421052631579]\n",
            "buy =  0.49473684210526314  sell =  0.5052631578947369\n",
            "trade accuracy =  0.2923076923076923\n",
            "epoch: 5, total rewards: -1270.000000, mean rewards: -320.842105\n",
            "\n",
            "action probability =  [0.2631578947368421, 0.42105263157894735, 0.3157894736842106]\n",
            "buy =  0.3894736842105263  sell =  0.6105263157894737\n",
            "trade accuracy =  0.2878787878787879\n",
            "epoch: 6, total rewards: -1238.000000, mean rewards: -312.757895\n",
            "\n",
            "action probability =  [0.3157894736842105, 0.21052631578947367, 0.4736842105263158]\n",
            "buy =  0.5578947368421052  sell =  0.4421052631578948\n",
            "trade accuracy =  0.36486486486486486\n",
            "epoch: 7, total rewards: 8489.000000, mean rewards: 2144.589474\n",
            "\n",
            "action probability =  [0.21052631578947367, 0.2736842105263158, 0.5157894736842106]\n",
            "buy =  0.4105263157894737  sell =  0.5894736842105264\n",
            "trade accuracy =  0.40540540540540543\n",
            "epoch: 8, total rewards: 1104.000000, mean rewards: 278.905263\n",
            "\n",
            "action probability =  [0.29473684210526313, 0.4, 0.3052631578947369]\n",
            "buy =  0.37894736842105264  sell =  0.6210526315789473\n",
            "trade accuracy =  0.4067796610169492\n",
            "epoch: 9, total rewards: -3.000000, mean rewards: -0.757895\n",
            "\n",
            "action probability =  [0.2, 0.25263157894736843, 0.5473684210526315]\n",
            "buy =  0.4421052631578947  sell =  0.5578947368421052\n",
            "trade accuracy =  0.3055555555555556\n",
            "epoch: 10, total rewards: -57.000000, mean rewards: -14.400000\n",
            "\n",
            "action probability =  [0.28421052631578947, 0.30526315789473685, 0.41052631578947363]\n",
            "buy =  0.4631578947368421  sell =  0.5368421052631579\n",
            "trade accuracy =  0.24285714285714285\n",
            "epoch: 11, total rewards: -1220.000000, mean rewards: -308.210526\n",
            "\n",
            "action probability =  [0.45263157894736844, 0.24210526315789474, 0.3052631578947368]\n",
            "buy =  0.6736842105263158  sell =  0.3263157894736842\n",
            "trade accuracy =  0.40425531914893614\n",
            "epoch: 12, total rewards: -71.000000, mean rewards: -17.936842\n",
            "\n",
            "action probability =  [0.30526315789473685, 0.3263157894736842, 0.368421052631579]\n",
            "buy =  0.5157894736842106  sell =  0.4842105263157894\n",
            "trade accuracy =  0.3472222222222222\n",
            "epoch: 13, total rewards: -1314.000000, mean rewards: -331.957895\n",
            "\n",
            "action probability =  [0.2631578947368421, 0.37894736842105264, 0.35789473684210527]\n",
            "buy =  0.3473684210526316  sell =  0.6526315789473685\n",
            "trade accuracy =  0.3103448275862069\n",
            "epoch: 14, total rewards: -1005.000000, mean rewards: -253.894737\n",
            "\n",
            "action probability =  [0.35789473684210527, 0.37894736842105264, 0.26315789473684204]\n",
            "buy =  0.5052631578947369  sell =  0.49473684210526314\n",
            "trade accuracy =  0.3709677419354839\n",
            "epoch: 15, total rewards: -1024.000000, mean rewards: -258.694737\n",
            "\n",
            "action probability =  [0.2736842105263158, 0.22105263157894736, 0.5052631578947369]\n",
            "buy =  0.5894736842105263  sell =  0.41052631578947374\n",
            "trade accuracy =  0.36507936507936506\n",
            "epoch: 16, total rewards: -960.000000, mean rewards: -242.526316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx2zzjpi4lo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neural_evolve.pip"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}