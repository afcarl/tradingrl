{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xluJbvKFSQsW",
        "outputId": "8fba5576-8c53-41e3-8625-1bcd69f2f461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive\n",
        "%load_ext Cython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "asRYJu49SQsJ",
        "outputId": "15678c87-9e50-4f1d-ac62-d3b4fc6381d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.6/dist-packages (0.4.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.17.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ta) (0.21.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (0.14.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ta) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ta) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ArBkEJtSQrw",
        "outputId": "75eba3a7-c1be-4083-d677-e396f90d69d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from numba import jit as njit\n",
        "from functools import lru_cache\n",
        "from multiprocessing import Pool\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import ta\n",
        "from net import *\n",
        "from memory import *\n",
        "from reward import *\n",
        "import traceback\n",
        "from IPython.display import clear_output\n",
        "from collections import deque"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yuYMpdBjSQrF",
        "colab": {}
      },
      "source": [
        "def swish(x):\n",
        "    x *= tf.nn.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def net(x,layer):\n",
        "  for i in layer:\n",
        "    x = i(x)\n",
        "  return x\n",
        "\n",
        "def actor(x,action):\n",
        "  with tf.variable_scope(\"actor\", reuse=False):\n",
        "    inputs = x\n",
        "    with tf.variable_scope(\"main\", reuse=False):\n",
        "      x1 = tf.keras.layers.Conv1D(128,8,1,padding=\"causal\",activation=swish)(x)\n",
        "      x2 = tf.keras.layers.Conv1D(128,4,1,padding=\"causal\",activation=swish)(x)\n",
        "      x3 = tf.keras.layers.Conv1D(128,2,1,padding=\"causal\",activation=swish)(x)\n",
        "      x = tf.keras.layers.Concatenate()([x1,x2,x3])\n",
        "      x = tf.keras.layers.Conv1D(128,3,1,padding=\"valid\",activation=swish)(x)\n",
        "      f = tf.keras.layers.Flatten()(x)\n",
        "    with tf.variable_scope(\"sub\", reuse=False):\n",
        "      x = tf.keras.layers.Flatten()(inputs)\n",
        "      shape = int(x.shape[-1])\n",
        "      a = tf.keras.layers.Dense(shape,tf.nn.softmax)(f)\n",
        "      mul = tf.keras.layers.Multiply()([x,a])\n",
        "      out = tf.keras.layers.Dense(128,swish)(mul)\n",
        "      out = tf.keras.layers.Dense(2,tf.tanh)(out)\n",
        "    with tf.variable_scope(\"main2\", reuse=False):\n",
        "      # x = tf.keras.layers.Dense(128,tf.nn.relu)(f)\n",
        "      x1 = tf.keras.layers.Concatenate()([out,f])\n",
        "      x2 = tf.keras.layers.Concatenate()([action,f])\n",
        "      layer = [tf.keras.layers.Dense(128,tf.nn.relu),tf.keras.layers.Dense(2)]\n",
        "      x1 = net(x1,layer)\n",
        "      x2 = net(x2,layer)\n",
        "      X = tf.keras.layers.Maximum()([x1[:,0],x1[:,1]])\n",
        "  return X,x1,x2,out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnaWdzaJY8tS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self,path,window_siz):\n",
        "      self.path = path\n",
        "      self.window_size = window_size\n",
        "      self.STEP_SIZE = 20 * 6\n",
        "      self.preproc()\n",
        "      self.state_size = (None,self.window_size,self.df.shape[-1])\n",
        "      print(self.state_size)\n",
        "      self.memory = Memory(5000)\n",
        "      self.rewards = reward3\n",
        "      self.noise = 0.5\n",
        "      self.noise_min = 0.1\n",
        "      self.sess = tf.Session()\n",
        "\n",
        "      with tf.variable_scope(\"input\"):\n",
        "        self.state = tf.placeholder(tf.float32, self.state_size)\n",
        "        self.new_state = tf.placeholder(tf.float32, self.state_size)\n",
        "        self.action = tf.placeholder(tf.float32,(None,2))\n",
        "        self.reward = tf.placeholder(tf.float32,(None,2))\n",
        "\n",
        "      with tf.variable_scope(\"model\", reuse=False):\n",
        "        self.policy,self.q_pi,self.q,self.out = actor(self.state,self.action)\n",
        "      \n",
        "      with tf.variable_scope(\"target\", reuse=False):\n",
        "        _,self.target_q_pi,_,_ = actor(self.new_state,self.action)\n",
        "\n",
        "      with tf.variable_scope(\"loss\"):\n",
        "        self.loss = loss = (0.5 * tf.reduce_mean((self.reward - self.q) ** 2))\n",
        "        self.ploss = policy_loss = -tf.reduce_mean(self.policy)\n",
        "        self.absolute_errors = tf.abs(self.reward - self.q)\n",
        "\n",
        "      self.policy_sub_opt = tf.train.AdamOptimizer(1e-3).minimize(policy_loss, var_list=get_vars('model/actor/sub'))\n",
        "      self.policy_main_opt = tf.train.AdamOptimizer(1e-3).minimize(loss, var_list=get_vars('model/actor/main')+get_vars('model/actor/main2'))\n",
        "\n",
        "      self.target_update = tf.group([tf.assign(v_targ, 0.001*v_targ + (1-0.001)*v_main)\n",
        "                                for v_main, v_targ in zip(get_vars('model'), get_vars('target'))])\n",
        "\n",
        "      target_init = tf.group([tf.assign(v_targ, v_main)\n",
        "                              for v_main, v_targ in zip(get_vars('model'), get_vars('target'))])\n",
        "\n",
        "      self.sess.run(tf.global_variables_initializer())\n",
        "      # self.sess.run(target_init)\n",
        "    def preproc(self):\n",
        "        self.dat = df = pd.read_csv(self.path)\n",
        "        s = np.asanyarray(ta.stoch(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1)) - np.asanyarray(ta.stoch_signal(df[\"High\"],df[\"Low\"],df[\"Close\"],14)).reshape((-1, 1))\n",
        "        x = np.asanyarray(ta.daily_return(df[\"Close\"])).reshape((-1,1))\n",
        "        m = np.asanyarray(ta.macd_diff(df[\"Close\"])).reshape((-1,1))\n",
        "        cross1 = np.asanyarray(ta.ema(self.dat[\"Close\"],12)).reshape((-1, 1)) - np.asanyarray(ta.ema(self.dat[\"Close\"],5)).reshape((-1, 1))\n",
        "        trend = np.asanyarray(df[[\"Close\"]]) - np.asanyarray(ta.ema(self.dat[\"Close\"],50)).reshape((-1, 1))\n",
        "        # x = s\n",
        "        x = np.concatenate([s,x,cross1,trend,m], 1)\n",
        "        y = np.asanyarray(self.dat[[\"Open\"]])\n",
        "\n",
        "        gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x, y, self.window_size)\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        for i in gen:\n",
        "            self.x.extend(i[0].tolist())\n",
        "            self.y.extend(i[1].tolist())\n",
        "        self.x = np.asanyarray(self.x)[100:] #.reshape((-1, self.window_size, x.shape[-1]))\n",
        "        self.y = np.asanyarray(self.y)[100:]\n",
        "\n",
        "        self.df = self.x[-self.STEP_SIZE:]\n",
        "        self.trend = self.y[-self.STEP_SIZE:]\n",
        "\n",
        "    def _construct_memories_and_train(self,i, replay=None):\n",
        "      try:\n",
        "          tree_idx, replay = self.memory.sample(128)\n",
        "      except:\n",
        "          self.memory = Memory(5000)\n",
        "\n",
        "      states = np.array([a[0][0] for a in replay])\n",
        "      new_states = np.array([a[0][3] for a in replay])\n",
        "      actions = np.array([a[0][1] for a in replay]).reshape((-1, 2))\n",
        "      rewards = np.array([a[0][2] for a in replay]).reshape((-1, 1))\n",
        "      done = np.array([a[0][-1] for a in replay]).reshape((-1, 1))\n",
        "\n",
        "      # target_q = self.sess.run(self.target_q, feed_dict={self.new_state:new_states}).reshape((-1,1))\n",
        "      q = self.sess.run(self.q,feed_dict={self.state:states,self.action:actions})\n",
        "      new_q = self.sess.run(self.q_pi,feed_dict={self.state:new_states})\n",
        "      new_target_q = self.sess.run(self.target_q_pi, feed_dict={self.new_state:new_states})\n",
        "\n",
        "      for I in range(128):\n",
        "        q[I,np.argmax(actions[I])] = rewards[I] + done[I] * 0.99 * new_target_q[I,np.argmax(new_q[I])]\n",
        "      # print(q)\n",
        "\n",
        "      step_ops = [self.absolute_errors,self.policy_main_opt]\n",
        "      for _ in range(1):\n",
        "        absolute_errors,_ = self.sess.run(step_ops, feed_dict={self.state: states, self.new_state: new_states, self.reward: q,self.action:actions})\n",
        "      if i > 10:\n",
        "        if (i+1) % 2 == 0:\n",
        "              loss,_ = self.sess.run([self.loss,self.policy_sub_opt], feed_dict={self.state: states,self.reward: q,self.action:actions})\n",
        "              # print(loss)\n",
        "          # print([rewards,loss])\n",
        "      # self.sess.run(self.target_update)\n",
        "      ae = []\n",
        "      for i in absolute_errors:\n",
        "        ae.append(np.mean(i))\n",
        "      ae = np.array(ae)\n",
        "      self.memory.batch_update(tree_idx, ae)\n",
        "\n",
        "    def _select_action(self, state, i):\n",
        "        # self.policy_out\n",
        "        prediction,q = self.sess.run([self.out,self.q_pi], feed_dict={self.state: [state]})\n",
        "        prediction,q = prediction[0],q[0]\n",
        "        q = np.abs(q) / np.sum(q)\n",
        "\n",
        "        if self.noise > self.noise_min:\n",
        "          self.noise *= 0.9999\n",
        "        noise = 0. if (i + 1) % 5 == 0 else self.noise\n",
        "        # print(prediction)\n",
        "        prediction += (noise * np.random.randn(2))\n",
        "        prediction = np.clip(prediction, -1, 1)\n",
        "        q += prediction\n",
        "        # prediction = q\n",
        "        action = np.argmax(q)\n",
        "        self.pred = prediction\n",
        "\n",
        "        return action\n",
        "\n",
        "    def prob(self,history):\n",
        "        prob = np.asanyarray(history)\n",
        "        a = np.mean(prob == 0)\n",
        "        b = np.mean(prob == 1)\n",
        "        c = 1 - (a + b)\n",
        "        prob = [a,b,c]\n",
        "        return prob\n",
        "\n",
        "    def discount_rewards(self, r, running_add):\n",
        "        running_add = running_add * 0.99 + r\n",
        "        return running_add\n",
        "        \n",
        "    def nstep(self,r):\n",
        "        running_add = 0.0\n",
        "        for t in range(len(r)):\n",
        "            running_add += 0.99 * r[t]\n",
        "\n",
        "        return running_add\n",
        "\n",
        "    def run(self, spread=10, pip_cost=1000, los_cut=600, day_pip=20, n=10,step=100):\n",
        "        spread = spread / pip_cost\n",
        "        self.rand = np.random.RandomState()\n",
        "        lc = los_cut / pip_cost\n",
        "        h = self.rand.randint(self.x.shape[0]-(self.STEP_SIZE+1))\n",
        "        self.df = self.x[h:h+self.STEP_SIZE]\n",
        "        self.trend = self.y[h:h+self.STEP_SIZE]\n",
        "        for i in range(100000):\n",
        "            # if i % 1000 == 0:\n",
        "            #   h = self.rand.randint(self.x.shape[0]-(self.STEP_SIZE+1))\n",
        "            #   self.df = self.x[h:h+self.STEP_SIZE]\n",
        "            #   self.trend = self.y[h:h+self.STEP_SIZE]\n",
        "            done = 1.0\n",
        "            position = 3\n",
        "            pip = []\n",
        "            provisional_pip = []\n",
        "            running_add = 0.0\n",
        "            total_pip = 0.0\n",
        "            old_reword = 0.0\n",
        "            states = []\n",
        "            h_a = []\n",
        "            h_r = []\n",
        "            h_p = []\n",
        "            old = np.asanyarray(0)\n",
        "            self.history = []\n",
        "            for t in  range(0, len(self.trend)-1):\n",
        "                action = self._select_action(self.df[t],i)\n",
        "                h_a.append(self.pred)\n",
        "                self.history.append(action)\n",
        "                \n",
        "                states,provisional_pip,position,total_pip = self.rewards(self.trend[t],pip,provisional_pip,\n",
        "                                    action,position,states,pip_cost,spread,total_pip,lc=min([lc/2,100/pip_cost]))\n",
        "                h_p.append(position)\n",
        "                reward =  (total_pip - old_reword) * 100\n",
        "                old_reword = total_pip\n",
        "                h_r.append(reward)\n",
        "\n",
        "                # running_add = self.discount_rewards(reward,running_add)\n",
        "                # r_d = int(running_add * (pip_cost / 100)) * 100\n",
        "                # # r_d = int(np.mean(np.array(provisional_pip) > 0)*100) if len(provisional_pip) != 0 else 0.\n",
        "                # if t == len(self.trend)-5:\n",
        "                #     done = 0.\n",
        "                # exp = self.df[t], h_a[t], r_d, self.df[t+1], done\n",
        "                # self.memory.store(exp)\n",
        "            for t in range(0, len(self.trend)-1):\n",
        "                tau = t - n + 1\n",
        "                if tau >= 0:\n",
        "                    rewards = self.nstep(h_r[tau+1:tau+n])\n",
        "                    exp = self.df[tau], h_a[tau], int(rewards), self.df[tau+n], done\n",
        "                    self.memory.store(exp)\n",
        "\n",
        "            try:\n",
        "              self._construct_memories_and_train(i)\n",
        "            except:\n",
        "              traceback.print_exc()\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "              clear_output()\n",
        "\n",
        "            if (i + 1) % 5 == 0:\n",
        "                # loss = np.mean(ae)\n",
        "                self.pip = np.asanyarray(provisional_pip) * pip_cost\n",
        "                self.pip = [p if p >= -los_cut else -los_cut for p in self.pip]\n",
        "                self.total_pip = np.sum(self.pip)\n",
        "                mean_pip = self.total_pip / (t + 1)\n",
        "                trade_accuracy = np.mean(np.asanyarray(self.pip) > 0)\n",
        "                self.trade = trade_accuracy\n",
        "                mean_pip *= day_pip\n",
        "                prob = self.prob(self.history)\n",
        "                position_prob = self.prob(h_p)\n",
        "\n",
        "                # print(\"loss =\", loss)\n",
        "                # print(\"\")\n",
        "                print('action probability = ', prob)\n",
        "                print(\"buy = \", position_prob[1], \" sell = \", position_prob[-1])\n",
        "                print('trade accuracy = ', trade_accuracy)\n",
        "                print('epoch: %d, total rewards: %f, mean rewards: %f' % (i + 1, float(self.total_pip), float(mean_pip)))\n",
        "                print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFioYWzBenRt",
        "colab_type": "code",
        "outputId": "997ab313-1ec3-451e-c418-5e3fd478627f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "window_size = 30\n",
        "path = \"audpred1440.csv\"\n",
        "agent = Agent(path,window_size)\n",
        "\n",
        "agent.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "action probability =  [0.4369747899159664, 0.5630252100840336, 0.0]\n",
            "buy =  0.4369747899159664  sell =  0.5630252100840336\n",
            "trade accuracy =  0.6206896551724138\n",
            "epoch: 2005, total rewards: 329710.000000, mean rewards: 55413.445378\n",
            "\n",
            "action probability =  [0.42016806722689076, 0.5798319327731093, 0.0]\n",
            "buy =  0.42016806722689076  sell =  0.5798319327731092\n",
            "trade accuracy =  0.5726495726495726\n",
            "epoch: 2010, total rewards: 311980.000000, mean rewards: 52433.613445\n",
            "\n",
            "action probability =  [0.4369747899159664, 0.5630252100840336, 0.0]\n",
            "buy =  0.4369747899159664  sell =  0.5630252100840336\n",
            "trade accuracy =  0.5689655172413793\n",
            "epoch: 2015, total rewards: 280010.000000, mean rewards: 47060.504202\n",
            "\n",
            "action probability =  [0.46218487394957986, 0.5378151260504201, 0.0]\n",
            "buy =  0.46218487394957986  sell =  0.5378151260504201\n",
            "trade accuracy =  0.5652173913043478\n",
            "epoch: 2020, total rewards: 262180.000000, mean rewards: 44063.865546\n",
            "\n",
            "action probability =  [0.5294117647058824, 0.47058823529411764, 0.0]\n",
            "buy =  0.5294117647058824  sell =  0.47058823529411764\n",
            "trade accuracy =  0.5517241379310345\n",
            "epoch: 2025, total rewards: 258800.000000, mean rewards: 43495.798319\n",
            "\n",
            "action probability =  [0.680672268907563, 0.31932773109243695, 0.0]\n",
            "buy =  0.680672268907563  sell =  0.31932773109243695\n",
            "trade accuracy =  0.5614035087719298\n",
            "epoch: 2030, total rewards: 224000.000000, mean rewards: 37647.058824\n",
            "\n",
            "action probability =  [0.6722689075630253, 0.3277310924369748, 0.0]\n",
            "buy =  0.6722689075630253  sell =  0.32773109243697474\n",
            "trade accuracy =  0.5565217391304348\n",
            "epoch: 2035, total rewards: 218100.000000, mean rewards: 36655.462185\n",
            "\n",
            "action probability =  [0.7226890756302521, 0.2773109243697479, 0.0]\n",
            "buy =  0.7226890756302521  sell =  0.2773109243697479\n",
            "trade accuracy =  0.5175438596491229\n",
            "epoch: 2040, total rewards: 208510.000000, mean rewards: 35043.697479\n",
            "\n",
            "action probability =  [0.7899159663865546, 0.21008403361344538, 0.0]\n",
            "buy =  0.7899159663865546  sell =  0.2100840336134454\n",
            "trade accuracy =  0.5304347826086957\n",
            "epoch: 2045, total rewards: 185990.000000, mean rewards: 31258.823529\n",
            "\n",
            "action probability =  [0.7310924369747899, 0.2689075630252101, 0.0]\n",
            "buy =  0.7310924369747899  sell =  0.26890756302521013\n",
            "trade accuracy =  0.5565217391304348\n",
            "epoch: 2050, total rewards: 182060.000000, mean rewards: 30598.319328\n",
            "\n",
            "action probability =  [0.5462184873949579, 0.453781512605042, 0.0]\n",
            "buy =  0.5462184873949579  sell =  0.45378151260504207\n",
            "trade accuracy =  0.5508474576271186\n",
            "epoch: 2055, total rewards: 218580.000000, mean rewards: 36736.134454\n",
            "\n",
            "action probability =  [0.44537815126050423, 0.5546218487394958, 0.0]\n",
            "buy =  0.44537815126050423  sell =  0.5546218487394958\n",
            "trade accuracy =  0.6271186440677966\n",
            "epoch: 2060, total rewards: 289580.000000, mean rewards: 48668.907563\n",
            "\n",
            "action probability =  [0.40336134453781514, 0.5966386554621849, 0.0]\n",
            "buy =  0.40336134453781514  sell =  0.5966386554621849\n",
            "trade accuracy =  0.6610169491525424\n",
            "epoch: 2065, total rewards: 324610.000000, mean rewards: 54556.302521\n",
            "\n",
            "action probability =  [0.3865546218487395, 0.6134453781512605, 0.0]\n",
            "buy =  0.3865546218487395  sell =  0.6134453781512605\n",
            "trade accuracy =  0.6949152542372882\n",
            "epoch: 2070, total rewards: 373080.000000, mean rewards: 62702.521008\n",
            "\n",
            "action probability =  [0.3865546218487395, 0.6134453781512605, 0.0]\n",
            "buy =  0.3865546218487395  sell =  0.6134453781512605\n",
            "trade accuracy =  0.7288135593220338\n",
            "epoch: 2075, total rewards: 411030.000000, mean rewards: 69080.672269\n",
            "\n",
            "action probability =  [0.3697478991596639, 0.6302521008403361, 0.0]\n",
            "buy =  0.3697478991596639  sell =  0.6302521008403361\n",
            "trade accuracy =  0.7542372881355932\n",
            "epoch: 2080, total rewards: 431150.000000, mean rewards: 72462.184874\n",
            "\n",
            "action probability =  [0.35294117647058826, 0.6470588235294118, 0.0]\n",
            "buy =  0.35294117647058826  sell =  0.6470588235294117\n",
            "trade accuracy =  0.7008547008547008\n",
            "epoch: 2085, total rewards: 364530.000000, mean rewards: 61265.546218\n",
            "\n",
            "action probability =  [0.3865546218487395, 0.6134453781512605, 0.0]\n",
            "buy =  0.3865546218487395  sell =  0.6134453781512605\n",
            "trade accuracy =  0.6724137931034483\n",
            "epoch: 2090, total rewards: 353380.000000, mean rewards: 59391.596639\n",
            "\n",
            "action probability =  [0.42016806722689076, 0.5798319327731093, 0.0]\n",
            "buy =  0.42016806722689076  sell =  0.5798319327731092\n",
            "trade accuracy =  0.6810344827586207\n",
            "epoch: 2095, total rewards: 361090.000000, mean rewards: 60687.394958\n",
            "\n",
            "action probability =  [0.680672268907563, 0.31932773109243695, 0.0]\n",
            "buy =  0.680672268907563  sell =  0.31932773109243695\n",
            "trade accuracy =  0.6548672566371682\n",
            "epoch: 2100, total rewards: 249250.000000, mean rewards: 41890.756303\n",
            "\n",
            "action probability =  [0.8739495798319328, 0.12605042016806722, 0.0]\n",
            "buy =  0.8739495798319328  sell =  0.12605042016806722\n",
            "trade accuracy =  0.47368421052631576\n",
            "epoch: 2105, total rewards: 188610.000000, mean rewards: 31699.159664\n",
            "\n",
            "action probability =  [0.9159663865546218, 0.08403361344537816, 0.0]\n",
            "buy =  0.9159663865546218  sell =  0.08403361344537819\n",
            "trade accuracy =  0.4473684210526316\n",
            "epoch: 2110, total rewards: 174070.000000, mean rewards: 29255.462185\n",
            "\n",
            "action probability =  [0.9327731092436975, 0.06722689075630252, 0.0]\n",
            "buy =  0.9327731092436975  sell =  0.0672268907563025\n",
            "trade accuracy =  0.4298245614035088\n",
            "epoch: 2115, total rewards: 170800.000000, mean rewards: 28705.882353\n",
            "\n",
            "action probability =  [0.9159663865546218, 0.08403361344537816, 0.0]\n",
            "buy =  0.9159663865546218  sell =  0.08403361344537819\n",
            "trade accuracy =  0.5\n",
            "epoch: 2120, total rewards: 207920.000000, mean rewards: 34944.537815\n",
            "\n",
            "action probability =  [0.8319327731092437, 0.16806722689075632, 0.0]\n",
            "buy =  0.8319327731092437  sell =  0.16806722689075626\n",
            "trade accuracy =  0.543859649122807\n",
            "epoch: 2125, total rewards: 222200.000000, mean rewards: 37344.537815\n",
            "\n",
            "action probability =  [0.6302521008403361, 0.3697478991596639, 0.0]\n",
            "buy =  0.6302521008403361  sell =  0.3697478991596639\n",
            "trade accuracy =  0.5982905982905983\n",
            "epoch: 2130, total rewards: 241100.000000, mean rewards: 40521.008403\n",
            "\n",
            "action probability =  [0.4117647058823529, 0.5882352941176471, 0.0]\n",
            "buy =  0.4117647058823529  sell =  0.5882352941176471\n",
            "trade accuracy =  0.7094017094017094\n",
            "epoch: 2135, total rewards: 306400.000000, mean rewards: 51495.798319\n",
            "\n",
            "action probability =  [0.3025210084033613, 0.6974789915966386, 0.0]\n",
            "buy =  0.3025210084033613  sell =  0.6974789915966386\n",
            "trade accuracy =  0.7288135593220338\n",
            "epoch: 2140, total rewards: 402100.000000, mean rewards: 67579.831933\n",
            "\n",
            "action probability =  [0.226890756302521, 0.773109243697479, 0.0]\n",
            "buy =  0.226890756302521  sell =  0.773109243697479\n",
            "trade accuracy =  0.7008547008547008\n",
            "epoch: 2145, total rewards: 583770.000000, mean rewards: 98112.605042\n",
            "\n",
            "action probability =  [0.2184873949579832, 0.7815126050420168, 0.0]\n",
            "buy =  0.2184873949579832  sell =  0.7815126050420168\n",
            "trade accuracy =  0.6610169491525424\n",
            "epoch: 2150, total rewards: 481270.000000, mean rewards: 80885.714286\n",
            "\n",
            "action probability =  [0.29411764705882354, 0.7058823529411765, 0.0]\n",
            "buy =  0.29411764705882354  sell =  0.7058823529411764\n",
            "trade accuracy =  0.6949152542372882\n",
            "epoch: 2155, total rewards: 409530.000000, mean rewards: 68828.571429\n",
            "\n",
            "action probability =  [0.4957983193277311, 0.5042016806722689, 0.0]\n",
            "buy =  0.4957983193277311  sell =  0.5042016806722689\n",
            "trade accuracy =  0.7288135593220338\n",
            "epoch: 2160, total rewards: 328430.000000, mean rewards: 55198.319328\n",
            "\n",
            "action probability =  [0.7226890756302521, 0.2773109243697479, 0.0]\n",
            "buy =  0.7226890756302521  sell =  0.2773109243697479\n",
            "trade accuracy =  0.6173913043478261\n",
            "epoch: 2165, total rewards: 254190.000000, mean rewards: 42721.008403\n",
            "\n",
            "action probability =  [0.7983193277310925, 0.20168067226890757, 0.0]\n",
            "buy =  0.7983193277310925  sell =  0.2016806722689075\n",
            "trade accuracy =  0.6434782608695652\n",
            "epoch: 2170, total rewards: 327650.000000, mean rewards: 55067.226891\n",
            "\n",
            "action probability =  [0.8739495798319328, 0.12605042016806722, 0.0]\n",
            "buy =  0.8739495798319328  sell =  0.12605042016806722\n",
            "trade accuracy =  0.6140350877192983\n",
            "epoch: 2175, total rewards: 310930.000000, mean rewards: 52257.142857\n",
            "\n",
            "action probability =  [0.7563025210084033, 0.24369747899159663, 0.0]\n",
            "buy =  0.7563025210084033  sell =  0.24369747899159666\n",
            "trade accuracy =  0.6491228070175439\n",
            "epoch: 2180, total rewards: 366200.000000, mean rewards: 61546.218487\n",
            "\n",
            "action probability =  [0.5966386554621849, 0.40336134453781514, 0.0]\n",
            "buy =  0.5966386554621849  sell =  0.40336134453781514\n",
            "trade accuracy =  0.6982758620689655\n",
            "epoch: 2185, total rewards: 298040.000000, mean rewards: 50090.756303\n",
            "\n",
            "action probability =  [0.5378151260504201, 0.46218487394957986, 0.0]\n",
            "buy =  0.5378151260504201  sell =  0.46218487394957986\n",
            "trade accuracy =  0.7304347826086957\n",
            "epoch: 2190, total rewards: 308140.000000, mean rewards: 51788.235294\n",
            "\n",
            "action probability =  [0.40336134453781514, 0.5966386554621849, 0.0]\n",
            "buy =  0.40336134453781514  sell =  0.5966386554621849\n",
            "trade accuracy =  0.6239316239316239\n",
            "epoch: 2195, total rewards: 191190.000000, mean rewards: 32132.773109\n",
            "\n",
            "action probability =  [0.3949579831932773, 0.6050420168067226, 0.0]\n",
            "buy =  0.3949579831932773  sell =  0.6050420168067228\n",
            "trade accuracy =  0.652542372881356\n",
            "epoch: 2200, total rewards: 212060.000000, mean rewards: 35640.336134\n",
            "\n",
            "action probability =  [0.42857142857142855, 0.5714285714285714, 0.0]\n",
            "buy =  0.42857142857142855  sell =  0.5714285714285714\n",
            "trade accuracy =  0.6610169491525424\n",
            "epoch: 2205, total rewards: 209410.000000, mean rewards: 35194.957983\n",
            "\n",
            "action probability =  [0.5714285714285714, 0.42857142857142855, 0.0]\n",
            "buy =  0.5714285714285714  sell =  0.4285714285714286\n",
            "trade accuracy =  0.6666666666666666\n",
            "epoch: 2210, total rewards: 263460.000000, mean rewards: 44278.991597\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.6864406779661016\n",
            "epoch: 2215, total rewards: 275320.000000, mean rewards: 46272.268908\n",
            "\n",
            "action probability =  [0.3865546218487395, 0.6134453781512605, 0.0]\n",
            "buy =  0.3865546218487395  sell =  0.6134453781512605\n",
            "trade accuracy =  0.6581196581196581\n",
            "epoch: 2220, total rewards: 192320.000000, mean rewards: 32322.689076\n",
            "\n",
            "action probability =  [0.453781512605042, 0.5462184873949579, 0.0]\n",
            "buy =  0.453781512605042  sell =  0.546218487394958\n",
            "trade accuracy =  0.6403508771929824\n",
            "epoch: 2225, total rewards: 158710.000000, mean rewards: 26673.949580\n",
            "\n",
            "action probability =  [0.5378151260504201, 0.46218487394957986, 0.0]\n",
            "buy =  0.5378151260504201  sell =  0.46218487394957986\n",
            "trade accuracy =  0.7719298245614035\n",
            "epoch: 2230, total rewards: 211250.000000, mean rewards: 35504.201681\n",
            "\n",
            "action probability =  [0.6134453781512605, 0.3865546218487395, 0.0]\n",
            "buy =  0.6134453781512605  sell =  0.38655462184873945\n",
            "trade accuracy =  0.672566371681416\n",
            "epoch: 2235, total rewards: 169250.000000, mean rewards: 28445.378151\n",
            "\n",
            "action probability =  [0.6470588235294118, 0.35294117647058826, 0.0]\n",
            "buy =  0.6470588235294118  sell =  0.3529411764705882\n",
            "trade accuracy =  0.7079646017699115\n",
            "epoch: 2240, total rewards: 189960.000000, mean rewards: 31926.050420\n",
            "\n",
            "action probability =  [0.5882352941176471, 0.4117647058823529, 0.0]\n",
            "buy =  0.5882352941176471  sell =  0.4117647058823529\n",
            "trade accuracy =  0.6581196581196581\n",
            "epoch: 2245, total rewards: 176180.000000, mean rewards: 29610.084034\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.6495726495726496\n",
            "epoch: 2250, total rewards: 194270.000000, mean rewards: 32650.420168\n",
            "\n",
            "action probability =  [0.46218487394957986, 0.5378151260504201, 0.0]\n",
            "buy =  0.46218487394957986  sell =  0.5378151260504201\n",
            "trade accuracy =  0.6752136752136753\n",
            "epoch: 2255, total rewards: 183220.000000, mean rewards: 30793.277311\n",
            "\n",
            "action probability =  [0.453781512605042, 0.5462184873949579, 0.0]\n",
            "buy =  0.453781512605042  sell =  0.546218487394958\n",
            "trade accuracy =  0.6666666666666666\n",
            "epoch: 2260, total rewards: 183730.000000, mean rewards: 30878.991597\n",
            "\n",
            "action probability =  [0.4789915966386555, 0.5210084033613446, 0.0]\n",
            "buy =  0.4789915966386555  sell =  0.5210084033613445\n",
            "trade accuracy =  0.6581196581196581\n",
            "epoch: 2265, total rewards: 189480.000000, mean rewards: 31845.378151\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.6752136752136753\n",
            "epoch: 2270, total rewards: 193420.000000, mean rewards: 32507.563025\n",
            "\n",
            "action probability =  [0.5882352941176471, 0.4117647058823529, 0.0]\n",
            "buy =  0.5882352941176471  sell =  0.4117647058823529\n",
            "trade accuracy =  0.6666666666666666\n",
            "epoch: 2275, total rewards: 207270.000000, mean rewards: 34835.294118\n",
            "\n",
            "action probability =  [0.6218487394957983, 0.37815126050420167, 0.0]\n",
            "buy =  0.6218487394957983  sell =  0.37815126050420167\n",
            "trade accuracy =  0.6785714285714286\n",
            "epoch: 2280, total rewards: 272470.000000, mean rewards: 45793.277311\n",
            "\n",
            "action probability =  [0.6134453781512605, 0.3865546218487395, 0.0]\n",
            "buy =  0.6134453781512605  sell =  0.38655462184873945\n",
            "trade accuracy =  0.6752136752136753\n",
            "epoch: 2285, total rewards: 281200.000000, mean rewards: 47260.504202\n",
            "\n",
            "action probability =  [0.5630252100840336, 0.4369747899159664, 0.0]\n",
            "buy =  0.5630252100840336  sell =  0.4369747899159664\n",
            "trade accuracy =  0.6637931034482759\n",
            "epoch: 2290, total rewards: 209440.000000, mean rewards: 35200.000000\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.6752136752136753\n",
            "epoch: 2295, total rewards: 221960.000000, mean rewards: 37304.201681\n",
            "\n",
            "action probability =  [0.5462184873949579, 0.453781512605042, 0.0]\n",
            "buy =  0.5462184873949579  sell =  0.45378151260504207\n",
            "trade accuracy =  0.6923076923076923\n",
            "epoch: 2300, total rewards: 217720.000000, mean rewards: 36591.596639\n",
            "\n",
            "action probability =  [0.5630252100840336, 0.4369747899159664, 0.0]\n",
            "buy =  0.5630252100840336  sell =  0.4369747899159664\n",
            "trade accuracy =  0.7008547008547008\n",
            "epoch: 2305, total rewards: 218830.000000, mean rewards: 36778.151261\n",
            "\n",
            "action probability =  [0.6638655462184874, 0.33613445378151263, 0.0]\n",
            "buy =  0.6638655462184874  sell =  0.33613445378151263\n",
            "trade accuracy =  0.6239316239316239\n",
            "epoch: 2310, total rewards: 184110.000000, mean rewards: 30942.857143\n",
            "\n",
            "action probability =  [0.6890756302521008, 0.31092436974789917, 0.0]\n",
            "buy =  0.6890756302521008  sell =  0.31092436974789917\n",
            "trade accuracy =  0.5299145299145299\n",
            "epoch: 2315, total rewards: 146130.000000, mean rewards: 24559.663866\n",
            "\n",
            "action probability =  [0.5882352941176471, 0.4117647058823529, 0.0]\n",
            "buy =  0.5882352941176471  sell =  0.4117647058823529\n",
            "trade accuracy =  0.717948717948718\n",
            "epoch: 2320, total rewards: 209900.000000, mean rewards: 35277.310924\n",
            "\n",
            "action probability =  [0.44537815126050423, 0.5546218487394958, 0.0]\n",
            "buy =  0.44537815126050423  sell =  0.5546218487394958\n",
            "trade accuracy =  0.6694915254237288\n",
            "epoch: 2325, total rewards: 194990.000000, mean rewards: 32771.428571\n",
            "\n",
            "action probability =  [0.3697478991596639, 0.6302521008403361, 0.0]\n",
            "buy =  0.3697478991596639  sell =  0.6302521008403361\n",
            "trade accuracy =  0.7094017094017094\n",
            "epoch: 2330, total rewards: 255550.000000, mean rewards: 42949.579832\n",
            "\n",
            "action probability =  [0.3865546218487395, 0.6134453781512605, 0.0]\n",
            "buy =  0.3865546218487395  sell =  0.6134453781512605\n",
            "trade accuracy =  0.6923076923076923\n",
            "epoch: 2335, total rewards: 236820.000000, mean rewards: 39801.680672\n",
            "\n",
            "action probability =  [0.48739495798319327, 0.5126050420168067, 0.0]\n",
            "buy =  0.48739495798319327  sell =  0.5126050420168067\n",
            "trade accuracy =  0.7241379310344828\n",
            "epoch: 2340, total rewards: 256690.000000, mean rewards: 43141.176471\n",
            "\n",
            "action probability =  [0.44537815126050423, 0.5546218487394958, 0.0]\n",
            "buy =  0.44537815126050423  sell =  0.5546218487394958\n",
            "trade accuracy =  0.7264957264957265\n",
            "epoch: 2345, total rewards: 247470.000000, mean rewards: 41591.596639\n",
            "\n",
            "action probability =  [0.31932773109243695, 0.680672268907563, 0.0]\n",
            "buy =  0.31932773109243695  sell =  0.680672268907563\n",
            "trade accuracy =  0.6271186440677966\n",
            "epoch: 2350, total rewards: 235440.000000, mean rewards: 39569.747899\n",
            "\n",
            "action probability =  [0.35294117647058826, 0.6470588235294118, 0.0]\n",
            "buy =  0.35294117647058826  sell =  0.6470588235294117\n",
            "trade accuracy =  0.6440677966101694\n",
            "epoch: 2355, total rewards: 230770.000000, mean rewards: 38784.873950\n",
            "\n",
            "action probability =  [0.453781512605042, 0.5462184873949579, 0.0]\n",
            "buy =  0.453781512605042  sell =  0.546218487394958\n",
            "trade accuracy =  0.6949152542372882\n",
            "epoch: 2360, total rewards: 226880.000000, mean rewards: 38131.092437\n",
            "\n",
            "action probability =  [0.6302521008403361, 0.3697478991596639, 0.0]\n",
            "buy =  0.6302521008403361  sell =  0.3697478991596639\n",
            "trade accuracy =  0.5299145299145299\n",
            "epoch: 2365, total rewards: 153270.000000, mean rewards: 25759.663866\n",
            "\n",
            "action probability =  [0.8319327731092437, 0.16806722689075632, 0.0]\n",
            "buy =  0.8319327731092437  sell =  0.16806722689075626\n",
            "trade accuracy =  0.4396551724137931\n",
            "epoch: 2370, total rewards: 85180.000000, mean rewards: 14315.966387\n",
            "\n",
            "action probability =  [0.8571428571428571, 0.14285714285714285, 0.0]\n",
            "buy =  0.8571428571428571  sell =  0.1428571428571429\n",
            "trade accuracy =  0.3879310344827586\n",
            "epoch: 2375, total rewards: 69270.000000, mean rewards: 11642.016807\n",
            "\n",
            "action probability =  [0.7899159663865546, 0.21008403361344538, 0.0]\n",
            "buy =  0.7899159663865546  sell =  0.2100840336134454\n",
            "trade accuracy =  0.5405405405405406\n",
            "epoch: 2380, total rewards: 158410.000000, mean rewards: 26623.529412\n",
            "\n",
            "action probability =  [0.773109243697479, 0.226890756302521, 0.0]\n",
            "buy =  0.773109243697479  sell =  0.22689075630252098\n",
            "trade accuracy =  0.6140350877192983\n",
            "epoch: 2385, total rewards: 244250.000000, mean rewards: 41050.420168\n",
            "\n",
            "action probability =  [0.7058823529411765, 0.29411764705882354, 0.0]\n",
            "buy =  0.7058823529411765  sell =  0.2941176470588235\n",
            "trade accuracy =  0.6434782608695652\n",
            "epoch: 2390, total rewards: 195840.000000, mean rewards: 32914.285714\n",
            "\n",
            "action probability =  [0.6050420168067226, 0.3949579831932773, 0.0]\n",
            "buy =  0.6050420168067226  sell =  0.39495798319327735\n",
            "trade accuracy =  0.6956521739130435\n",
            "epoch: 2395, total rewards: 198690.000000, mean rewards: 33393.277311\n",
            "\n",
            "action probability =  [0.5798319327731093, 0.42016806722689076, 0.0]\n",
            "buy =  0.5798319327731093  sell =  0.4201680672268907\n",
            "trade accuracy =  0.7043478260869566\n",
            "epoch: 2400, total rewards: 196830.000000, mean rewards: 33080.672269\n",
            "\n",
            "action probability =  [0.6218487394957983, 0.37815126050420167, 0.0]\n",
            "buy =  0.6218487394957983  sell =  0.37815126050420167\n",
            "trade accuracy =  0.7017543859649122\n",
            "epoch: 2405, total rewards: 257620.000000, mean rewards: 43297.478992\n",
            "\n",
            "action probability =  [0.5630252100840336, 0.4369747899159664, 0.0]\n",
            "buy =  0.5630252100840336  sell =  0.4369747899159664\n",
            "trade accuracy =  0.672566371681416\n",
            "epoch: 2410, total rewards: 234770.000000, mean rewards: 39457.142857\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.6283185840707964\n",
            "epoch: 2415, total rewards: 168740.000000, mean rewards: 28359.663866\n",
            "\n",
            "action probability =  [0.5966386554621849, 0.40336134453781514, 0.0]\n",
            "buy =  0.5966386554621849  sell =  0.40336134453781514\n",
            "trade accuracy =  0.6460176991150443\n",
            "epoch: 2420, total rewards: 199690.000000, mean rewards: 33561.344538\n",
            "\n",
            "action probability =  [0.5882352941176471, 0.4117647058823529, 0.0]\n",
            "buy =  0.5882352941176471  sell =  0.4117647058823529\n",
            "trade accuracy =  0.6991150442477876\n",
            "epoch: 2425, total rewards: 213750.000000, mean rewards: 35924.369748\n",
            "\n",
            "action probability =  [0.6134453781512605, 0.3865546218487395, 0.0]\n",
            "buy =  0.6134453781512605  sell =  0.38655462184873945\n",
            "trade accuracy =  0.6896551724137931\n",
            "epoch: 2430, total rewards: 205950.000000, mean rewards: 34613.445378\n",
            "\n",
            "action probability =  [0.6890756302521008, 0.31092436974789917, 0.0]\n",
            "buy =  0.6890756302521008  sell =  0.31092436974789917\n",
            "trade accuracy =  0.646551724137931\n",
            "epoch: 2435, total rewards: 234270.000000, mean rewards: 39373.109244\n",
            "\n",
            "action probability =  [0.7058823529411765, 0.29411764705882354, 0.0]\n",
            "buy =  0.7058823529411765  sell =  0.2941176470588235\n",
            "trade accuracy =  0.6206896551724138\n",
            "epoch: 2440, total rewards: 226580.000000, mean rewards: 38080.672269\n",
            "\n",
            "action probability =  [0.6890756302521008, 0.31092436974789917, 0.0]\n",
            "buy =  0.6890756302521008  sell =  0.31092436974789917\n",
            "trade accuracy =  0.603448275862069\n",
            "epoch: 2445, total rewards: 216140.000000, mean rewards: 36326.050420\n",
            "\n",
            "action probability =  [0.5966386554621849, 0.40336134453781514, 0.0]\n",
            "buy =  0.5966386554621849  sell =  0.40336134453781514\n",
            "trade accuracy =  0.6581196581196581\n",
            "epoch: 2450, total rewards: 240730.000000, mean rewards: 40458.823529\n",
            "\n",
            "action probability =  [0.6470588235294118, 0.35294117647058826, 0.0]\n",
            "buy =  0.6470588235294118  sell =  0.3529411764705882\n",
            "trade accuracy =  0.6120689655172413\n",
            "epoch: 2455, total rewards: 213180.000000, mean rewards: 35828.571429\n",
            "\n",
            "action probability =  [0.6386554621848739, 0.36134453781512604, 0.0]\n",
            "buy =  0.6386554621848739  sell =  0.3613445378151261\n",
            "trade accuracy =  0.6956521739130435\n",
            "epoch: 2460, total rewards: 238980.000000, mean rewards: 40164.705882\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.6864406779661016\n",
            "epoch: 2465, total rewards: 249950.000000, mean rewards: 42008.403361\n",
            "\n",
            "action probability =  [0.453781512605042, 0.5462184873949579, 0.0]\n",
            "buy =  0.453781512605042  sell =  0.546218487394958\n",
            "trade accuracy =  0.7033898305084746\n",
            "epoch: 2470, total rewards: 270030.000000, mean rewards: 45383.193277\n",
            "\n",
            "action probability =  [0.42016806722689076, 0.5798319327731093, 0.0]\n",
            "buy =  0.42016806722689076  sell =  0.5798319327731092\n",
            "trade accuracy =  0.6779661016949152\n",
            "epoch: 2475, total rewards: 260160.000000, mean rewards: 43724.369748\n",
            "\n",
            "action probability =  [0.36134453781512604, 0.6386554621848739, 0.0]\n",
            "buy =  0.36134453781512604  sell =  0.6386554621848739\n",
            "trade accuracy =  0.711864406779661\n",
            "epoch: 2480, total rewards: 308990.000000, mean rewards: 51931.092437\n",
            "\n",
            "action probability =  [0.31092436974789917, 0.6890756302521008, 0.0]\n",
            "buy =  0.31092436974789917  sell =  0.6890756302521008\n",
            "trade accuracy =  0.6610169491525424\n",
            "epoch: 2485, total rewards: 291660.000000, mean rewards: 49018.487395\n",
            "\n",
            "action probability =  [0.31932773109243695, 0.680672268907563, 0.0]\n",
            "buy =  0.31932773109243695  sell =  0.680672268907563\n",
            "trade accuracy =  0.6779661016949152\n",
            "epoch: 2490, total rewards: 302340.000000, mean rewards: 50813.445378\n",
            "\n",
            "action probability =  [0.4957983193277311, 0.5042016806722689, 0.0]\n",
            "buy =  0.4957983193277311  sell =  0.5042016806722689\n",
            "trade accuracy =  0.6239316239316239\n",
            "epoch: 2495, total rewards: 243630.000000, mean rewards: 40946.218487\n",
            "\n",
            "action probability =  [0.6554621848739496, 0.3445378151260504, 0.0]\n",
            "buy =  0.6554621848739496  sell =  0.3445378151260504\n",
            "trade accuracy =  0.6454545454545455\n",
            "epoch: 2500, total rewards: 236830.000000, mean rewards: 39803.361345\n",
            "\n",
            "action probability =  [0.7394957983193278, 0.2605042016806723, 0.0]\n",
            "buy =  0.7394957983193278  sell =  0.26050420168067223\n",
            "trade accuracy =  0.6017699115044248\n",
            "epoch: 2505, total rewards: 222750.000000, mean rewards: 37436.974790\n",
            "\n",
            "action probability =  [0.7647058823529411, 0.23529411764705882, 0.0]\n",
            "buy =  0.7647058823529411  sell =  0.23529411764705888\n",
            "trade accuracy =  0.48214285714285715\n",
            "epoch: 2510, total rewards: 172260.000000, mean rewards: 28951.260504\n",
            "\n",
            "action probability =  [0.8571428571428571, 0.14285714285714285, 0.0]\n",
            "buy =  0.8571428571428571  sell =  0.1428571428571429\n",
            "trade accuracy =  0.43478260869565216\n",
            "epoch: 2515, total rewards: 120100.000000, mean rewards: 20184.873950\n",
            "\n",
            "action probability =  [0.8319327731092437, 0.16806722689075632, 0.0]\n",
            "buy =  0.8319327731092437  sell =  0.16806722689075626\n",
            "trade accuracy =  0.46017699115044247\n",
            "epoch: 2520, total rewards: 127380.000000, mean rewards: 21408.403361\n",
            "\n",
            "action probability =  [0.6302521008403361, 0.3697478991596639, 0.0]\n",
            "buy =  0.6302521008403361  sell =  0.3697478991596639\n",
            "trade accuracy =  0.7610619469026548\n",
            "epoch: 2525, total rewards: 277490.000000, mean rewards: 46636.974790\n",
            "\n",
            "action probability =  [0.5042016806722689, 0.4957983193277311, 0.0]\n",
            "buy =  0.5042016806722689  sell =  0.4957983193277311\n",
            "trade accuracy =  0.7264957264957265\n",
            "epoch: 2530, total rewards: 282810.000000, mean rewards: 47531.092437\n",
            "\n",
            "action probability =  [0.3949579831932773, 0.6050420168067226, 0.0]\n",
            "buy =  0.3949579831932773  sell =  0.6050420168067228\n",
            "trade accuracy =  0.6694915254237288\n",
            "epoch: 2535, total rewards: 246320.000000, mean rewards: 41398.319328\n",
            "\n",
            "action probability =  [0.4369747899159664, 0.5630252100840336, 0.0]\n",
            "buy =  0.4369747899159664  sell =  0.5630252100840336\n",
            "trade accuracy =  0.6779661016949152\n",
            "epoch: 2540, total rewards: 264390.000000, mean rewards: 44435.294118\n",
            "\n",
            "action probability =  [0.33613445378151263, 0.6638655462184874, 0.0]\n",
            "buy =  0.33613445378151263  sell =  0.6638655462184874\n",
            "trade accuracy =  0.6896551724137931\n",
            "epoch: 2545, total rewards: 256900.000000, mean rewards: 43176.470588\n",
            "\n",
            "action probability =  [0.3025210084033613, 0.6974789915966386, 0.0]\n",
            "buy =  0.3025210084033613  sell =  0.6974789915966386\n",
            "trade accuracy =  0.75\n",
            "epoch: 2550, total rewards: 341380.000000, mean rewards: 57374.789916\n",
            "\n",
            "action probability =  [0.2857142857142857, 0.7142857142857143, 0.0]\n",
            "buy =  0.2857142857142857  sell =  0.7142857142857143\n",
            "trade accuracy =  0.7844827586206896\n",
            "epoch: 2555, total rewards: 556860.000000, mean rewards: 93589.915966\n",
            "\n",
            "action probability =  [0.3025210084033613, 0.6974789915966386, 0.0]\n",
            "buy =  0.3025210084033613  sell =  0.6974789915966386\n",
            "trade accuracy =  0.7327586206896551\n",
            "epoch: 2560, total rewards: 351400.000000, mean rewards: 59058.823529\n",
            "\n",
            "action probability =  [0.5714285714285714, 0.42857142857142855, 0.0]\n",
            "buy =  0.5714285714285714  sell =  0.4285714285714286\n",
            "trade accuracy =  0.6982758620689655\n",
            "epoch: 2565, total rewards: 269510.000000, mean rewards: 45295.798319\n",
            "\n",
            "action probability =  [0.6638655462184874, 0.33613445378151263, 0.0]\n",
            "buy =  0.6638655462184874  sell =  0.33613445378151263\n",
            "trade accuracy =  0.6896551724137931\n",
            "epoch: 2570, total rewards: 310760.000000, mean rewards: 52228.571429\n",
            "\n",
            "action probability =  [0.7647058823529411, 0.23529411764705882, 0.0]\n",
            "buy =  0.7647058823529411  sell =  0.23529411764705888\n",
            "trade accuracy =  0.6260869565217392\n",
            "epoch: 2575, total rewards: 282560.000000, mean rewards: 47489.075630\n",
            "\n",
            "action probability =  [0.8067226890756303, 0.19327731092436976, 0.0]\n",
            "buy =  0.8067226890756303  sell =  0.19327731092436973\n",
            "trade accuracy =  0.6428571428571429\n",
            "epoch: 2580, total rewards: 278240.000000, mean rewards: 46763.025210\n",
            "\n",
            "action probability =  [0.8235294117647058, 0.17647058823529413, 0.0]\n",
            "buy =  0.8235294117647058  sell =  0.17647058823529416\n",
            "trade accuracy =  0.6548672566371682\n",
            "epoch: 2585, total rewards: 237140.000000, mean rewards: 39855.462185\n",
            "\n",
            "action probability =  [0.8739495798319328, 0.12605042016806722, 0.0]\n",
            "buy =  0.8739495798319328  sell =  0.12605042016806722\n",
            "trade accuracy =  0.5652173913043478\n",
            "epoch: 2590, total rewards: 200880.000000, mean rewards: 33761.344538\n",
            "\n",
            "action probability =  [0.8151260504201681, 0.18487394957983194, 0.0]\n",
            "buy =  0.8151260504201681  sell =  0.18487394957983194\n",
            "trade accuracy =  0.6521739130434783\n",
            "epoch: 2595, total rewards: 230860.000000, mean rewards: 38800.000000\n",
            "\n",
            "action probability =  [0.8067226890756303, 0.19327731092436976, 0.0]\n",
            "buy =  0.8067226890756303  sell =  0.19327731092436973\n",
            "trade accuracy =  0.5982142857142857\n",
            "epoch: 2600, total rewards: 238420.000000, mean rewards: 40070.588235\n",
            "\n",
            "action probability =  [0.6890756302521008, 0.31092436974789917, 0.0]\n",
            "buy =  0.6890756302521008  sell =  0.31092436974789917\n",
            "trade accuracy =  0.6491228070175439\n",
            "epoch: 2605, total rewards: 260120.000000, mean rewards: 43717.647059\n",
            "\n",
            "action probability =  [0.48739495798319327, 0.5126050420168067, 0.0]\n",
            "buy =  0.48739495798319327  sell =  0.5126050420168067\n",
            "trade accuracy =  0.6837606837606838\n",
            "epoch: 2610, total rewards: 301740.000000, mean rewards: 50712.605042\n",
            "\n",
            "action probability =  [0.3445378151260504, 0.6554621848739496, 0.0]\n",
            "buy =  0.3445378151260504  sell =  0.6554621848739496\n",
            "trade accuracy =  0.6982758620689655\n",
            "epoch: 2615, total rewards: 299930.000000, mean rewards: 50408.403361\n",
            "\n",
            "action probability =  [0.3025210084033613, 0.6974789915966386, 0.0]\n",
            "buy =  0.3025210084033613  sell =  0.6974789915966386\n",
            "trade accuracy =  0.6837606837606838\n",
            "epoch: 2620, total rewards: 305310.000000, mean rewards: 51312.605042\n",
            "\n",
            "action probability =  [0.31092436974789917, 0.6890756302521008, 0.0]\n",
            "buy =  0.31092436974789917  sell =  0.6890756302521008\n",
            "trade accuracy =  0.7777777777777778\n",
            "epoch: 2625, total rewards: 561090.000000, mean rewards: 94300.840336\n",
            "\n",
            "action probability =  [0.31932773109243695, 0.680672268907563, 0.0]\n",
            "buy =  0.31932773109243695  sell =  0.680672268907563\n",
            "trade accuracy =  0.7777777777777778\n",
            "epoch: 2630, total rewards: 560060.000000, mean rewards: 94127.731092\n",
            "\n",
            "action probability =  [0.2773109243697479, 0.7226890756302521, 0.0]\n",
            "buy =  0.2773109243697479  sell =  0.7226890756302521\n",
            "trade accuracy =  0.6581196581196581\n",
            "epoch: 2635, total rewards: 235400.000000, mean rewards: 39563.025210\n",
            "\n",
            "action probability =  [0.3025210084033613, 0.6974789915966386, 0.0]\n",
            "buy =  0.3025210084033613  sell =  0.6974789915966386\n",
            "trade accuracy =  0.5641025641025641\n",
            "epoch: 2640, total rewards: 194780.000000, mean rewards: 32736.134454\n",
            "\n",
            "action probability =  [0.35294117647058826, 0.6470588235294118, 0.0]\n",
            "buy =  0.35294117647058826  sell =  0.6470588235294117\n",
            "trade accuracy =  0.5932203389830508\n",
            "epoch: 2645, total rewards: 221330.000000, mean rewards: 37198.319328\n",
            "\n",
            "action probability =  [0.5546218487394958, 0.44537815126050423, 0.0]\n",
            "buy =  0.5546218487394958  sell =  0.4453781512605042\n",
            "trade accuracy =  0.6521739130434783\n",
            "epoch: 2650, total rewards: 213940.000000, mean rewards: 35956.302521\n",
            "\n",
            "action probability =  [0.6134453781512605, 0.3865546218487395, 0.0]\n",
            "buy =  0.6134453781512605  sell =  0.38655462184873945\n",
            "trade accuracy =  0.6694915254237288\n",
            "epoch: 2655, total rewards: 244370.000000, mean rewards: 41070.588235\n",
            "\n",
            "action probability =  [0.7142857142857143, 0.2857142857142857, 0.0]\n",
            "buy =  0.7142857142857143  sell =  0.2857142857142857\n",
            "trade accuracy =  0.6440677966101694\n",
            "epoch: 2660, total rewards: 229230.000000, mean rewards: 38526.050420\n",
            "\n",
            "action probability =  [0.8235294117647058, 0.17647058823529413, 0.0]\n",
            "buy =  0.8235294117647058  sell =  0.17647058823529416\n",
            "trade accuracy =  0.5726495726495726\n",
            "epoch: 2665, total rewards: 270490.000000, mean rewards: 45460.504202\n",
            "\n",
            "action probability =  [0.8319327731092437, 0.16806722689075632, 0.0]\n",
            "buy =  0.8319327731092437  sell =  0.16806722689075626\n",
            "trade accuracy =  0.5384615384615384\n",
            "epoch: 2670, total rewards: 233290.000000, mean rewards: 39208.403361\n",
            "\n",
            "action probability =  [0.6218487394957983, 0.37815126050420167, 0.0]\n",
            "buy =  0.6218487394957983  sell =  0.37815126050420167\n",
            "trade accuracy =  0.7350427350427351\n",
            "epoch: 2675, total rewards: 303900.000000, mean rewards: 51075.630252\n",
            "\n",
            "action probability =  [0.6302521008403361, 0.3697478991596639, 0.0]\n",
            "buy =  0.6302521008403361  sell =  0.3697478991596639\n",
            "trade accuracy =  0.7288135593220338\n",
            "epoch: 2680, total rewards: 274640.000000, mean rewards: 46157.983193\n",
            "\n",
            "action probability =  [0.7394957983193278, 0.2605042016806723, 0.0]\n",
            "buy =  0.7394957983193278  sell =  0.26050420168067223\n",
            "trade accuracy =  0.6810344827586207\n",
            "epoch: 2685, total rewards: 213830.000000, mean rewards: 35937.815126\n",
            "\n",
            "action probability =  [0.7983193277310925, 0.20168067226890757, 0.0]\n",
            "buy =  0.7983193277310925  sell =  0.2016806722689075\n",
            "trade accuracy =  0.6410256410256411\n",
            "epoch: 2690, total rewards: 295060.000000, mean rewards: 49589.915966\n",
            "\n",
            "action probability =  [0.7226890756302521, 0.2773109243697479, 0.0]\n",
            "buy =  0.7226890756302521  sell =  0.2773109243697479\n",
            "trade accuracy =  0.7008547008547008\n",
            "epoch: 2695, total rewards: 263370.000000, mean rewards: 44263.865546\n",
            "\n",
            "action probability =  [0.6218487394957983, 0.37815126050420167, 0.0]\n",
            "buy =  0.6218487394957983  sell =  0.37815126050420167\n",
            "trade accuracy =  0.7435897435897436\n",
            "epoch: 2700, total rewards: 272020.000000, mean rewards: 45717.647059\n",
            "\n",
            "action probability =  [0.5546218487394958, 0.44537815126050423, 0.0]\n",
            "buy =  0.5546218487394958  sell =  0.4453781512605042\n",
            "trade accuracy =  0.7068965517241379\n",
            "epoch: 2705, total rewards: 314810.000000, mean rewards: 52909.243697\n",
            "\n",
            "action probability =  [0.6050420168067226, 0.3949579831932773, 0.0]\n",
            "buy =  0.6050420168067226  sell =  0.39495798319327735\n",
            "trade accuracy =  0.6956521739130435\n",
            "epoch: 2710, total rewards: 306190.000000, mean rewards: 51460.504202\n",
            "\n",
            "action probability =  [0.6974789915966386, 0.3025210084033613, 0.0]\n",
            "buy =  0.6974789915966386  sell =  0.3025210084033614\n",
            "trade accuracy =  0.6666666666666666\n",
            "epoch: 2715, total rewards: 346520.000000, mean rewards: 58238.655462\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.6581196581196581\n",
            "epoch: 2720, total rewards: 299520.000000, mean rewards: 50339.495798\n",
            "\n",
            "action probability =  [0.4789915966386555, 0.5210084033613446, 0.0]\n",
            "buy =  0.4789915966386555  sell =  0.5210084033613445\n",
            "trade accuracy =  0.6153846153846154\n",
            "epoch: 2725, total rewards: 232650.000000, mean rewards: 39100.840336\n",
            "\n",
            "action probability =  [0.6218487394957983, 0.37815126050420167, 0.0]\n",
            "buy =  0.6218487394957983  sell =  0.37815126050420167\n",
            "trade accuracy =  0.6782608695652174\n",
            "epoch: 2730, total rewards: 353520.000000, mean rewards: 59415.126050\n",
            "\n",
            "action probability =  [0.6218487394957983, 0.37815126050420167, 0.0]\n",
            "buy =  0.6218487394957983  sell =  0.37815126050420167\n",
            "trade accuracy =  0.6982758620689655\n",
            "epoch: 2735, total rewards: 377910.000000, mean rewards: 63514.285714\n",
            "\n",
            "action probability =  [0.680672268907563, 0.31932773109243695, 0.0]\n",
            "buy =  0.680672268907563  sell =  0.31932773109243695\n",
            "trade accuracy =  0.7217391304347827\n",
            "epoch: 2740, total rewards: 383500.000000, mean rewards: 64453.781513\n",
            "\n",
            "action probability =  [0.680672268907563, 0.31932773109243695, 0.0]\n",
            "buy =  0.680672268907563  sell =  0.31932773109243695\n",
            "trade accuracy =  0.7631578947368421\n",
            "epoch: 2745, total rewards: 402220.000000, mean rewards: 67600.000000\n",
            "\n",
            "action probability =  [0.42016806722689076, 0.5798319327731093, 0.0]\n",
            "buy =  0.42016806722689076  sell =  0.5798319327731092\n",
            "trade accuracy =  0.7288135593220338\n",
            "epoch: 2750, total rewards: 294110.000000, mean rewards: 49430.252101\n",
            "\n",
            "action probability =  [0.44537815126050423, 0.5546218487394958, 0.0]\n",
            "buy =  0.44537815126050423  sell =  0.5546218487394958\n",
            "trade accuracy =  0.7711864406779662\n",
            "epoch: 2755, total rewards: 358250.000000, mean rewards: 60210.084034\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.8135593220338984\n",
            "epoch: 2760, total rewards: 355800.000000, mean rewards: 59798.319328\n",
            "\n",
            "action probability =  [0.48739495798319327, 0.5126050420168067, 0.0]\n",
            "buy =  0.48739495798319327  sell =  0.5126050420168067\n",
            "trade accuracy =  0.847457627118644\n",
            "epoch: 2765, total rewards: 411300.000000, mean rewards: 69126.050420\n",
            "\n",
            "action probability =  [0.5210084033613446, 0.4789915966386555, 0.0]\n",
            "buy =  0.5210084033613446  sell =  0.4789915966386554\n",
            "trade accuracy =  0.811965811965812\n",
            "epoch: 2770, total rewards: 375090.000000, mean rewards: 63040.336134\n",
            "\n",
            "action probability =  [0.6218487394957983, 0.37815126050420167, 0.0]\n",
            "buy =  0.6218487394957983  sell =  0.37815126050420167\n",
            "trade accuracy =  0.7606837606837606\n",
            "epoch: 2775, total rewards: 302580.000000, mean rewards: 50853.781513\n",
            "\n",
            "action probability =  [0.5294117647058824, 0.47058823529411764, 0.0]\n",
            "buy =  0.5294117647058824  sell =  0.47058823529411764\n",
            "trade accuracy =  0.8559322033898306\n",
            "epoch: 2780, total rewards: 400540.000000, mean rewards: 67317.647059\n",
            "\n",
            "action probability =  [0.6134453781512605, 0.3865546218487395, 0.0]\n",
            "buy =  0.6134453781512605  sell =  0.38655462184873945\n",
            "trade accuracy =  0.7094017094017094\n",
            "epoch: 2785, total rewards: 282660.000000, mean rewards: 47505.882353\n",
            "\n",
            "action probability =  [0.7394957983193278, 0.2605042016806723, 0.0]\n",
            "buy =  0.7394957983193278  sell =  0.26050420168067223\n",
            "trade accuracy =  0.5739130434782609\n",
            "epoch: 2790, total rewards: 244810.000000, mean rewards: 41144.537815\n",
            "\n",
            "action probability =  [0.6974789915966386, 0.3025210084033613, 0.0]\n",
            "buy =  0.6974789915966386  sell =  0.3025210084033614\n",
            "trade accuracy =  0.6173913043478261\n",
            "epoch: 2795, total rewards: 259460.000000, mean rewards: 43606.722689\n",
            "\n",
            "action probability =  [0.6638655462184874, 0.33613445378151263, 0.0]\n",
            "buy =  0.6638655462184874  sell =  0.33613445378151263\n",
            "trade accuracy =  0.7739130434782608\n",
            "epoch: 2800, total rewards: 317220.000000, mean rewards: 53314.285714\n",
            "\n",
            "action probability =  [0.7647058823529411, 0.23529411764705882, 0.0]\n",
            "buy =  0.7647058823529411  sell =  0.23529411764705888\n",
            "trade accuracy =  0.6608695652173913\n",
            "epoch: 2805, total rewards: 257560.000000, mean rewards: 43287.394958\n",
            "\n",
            "action probability =  [0.8319327731092437, 0.16806722689075632, 0.0]\n",
            "buy =  0.8319327731092437  sell =  0.16806722689075626\n",
            "trade accuracy =  0.4956521739130435\n",
            "epoch: 2810, total rewards: 208750.000000, mean rewards: 35084.033613\n",
            "\n",
            "action probability =  [0.7899159663865546, 0.21008403361344538, 0.0]\n",
            "buy =  0.7899159663865546  sell =  0.2100840336134454\n",
            "trade accuracy =  0.6086956521739131\n",
            "epoch: 2815, total rewards: 244340.000000, mean rewards: 41065.546218\n",
            "\n",
            "action probability =  [0.6470588235294118, 0.35294117647058826, 0.0]\n",
            "buy =  0.6470588235294118  sell =  0.3529411764705882\n",
            "trade accuracy =  0.75\n",
            "epoch: 2820, total rewards: 310610.000000, mean rewards: 52203.361345\n",
            "\n",
            "action probability =  [0.5294117647058824, 0.47058823529411764, 0.0]\n",
            "buy =  0.5294117647058824  sell =  0.47058823529411764\n",
            "trade accuracy =  0.75\n",
            "epoch: 2825, total rewards: 325950.000000, mean rewards: 54781.512605\n",
            "\n",
            "action probability =  [0.453781512605042, 0.5462184873949579, 0.0]\n",
            "buy =  0.453781512605042  sell =  0.546218487394958\n",
            "trade accuracy =  0.8290598290598291\n",
            "epoch: 2830, total rewards: 405490.000000, mean rewards: 68149.579832\n",
            "\n",
            "action probability =  [0.42857142857142855, 0.5714285714285714, 0.0]\n",
            "buy =  0.42857142857142855  sell =  0.5714285714285714\n",
            "trade accuracy =  0.811965811965812\n",
            "epoch: 2835, total rewards: 351500.000000, mean rewards: 59075.630252\n",
            "\n",
            "action probability =  [0.42857142857142855, 0.5714285714285714, 0.0]\n",
            "buy =  0.42857142857142855  sell =  0.5714285714285714\n",
            "trade accuracy =  0.811965811965812\n",
            "epoch: 2840, total rewards: 351500.000000, mean rewards: 59075.630252\n",
            "\n",
            "action probability =  [0.4789915966386555, 0.5210084033613446, 0.0]\n",
            "buy =  0.4789915966386555  sell =  0.5210084033613445\n",
            "trade accuracy =  0.7863247863247863\n",
            "epoch: 2845, total rewards: 366140.000000, mean rewards: 61536.134454\n",
            "\n",
            "action probability =  [0.5966386554621849, 0.40336134453781514, 0.0]\n",
            "buy =  0.5966386554621849  sell =  0.40336134453781514\n",
            "trade accuracy =  0.646551724137931\n",
            "epoch: 2850, total rewards: 290690.000000, mean rewards: 48855.462185\n",
            "\n",
            "action probability =  [0.6554621848739496, 0.3445378151260504, 0.0]\n",
            "buy =  0.6554621848739496  sell =  0.3445378151260504\n",
            "trade accuracy =  0.6551724137931034\n",
            "epoch: 2855, total rewards: 290980.000000, mean rewards: 48904.201681\n",
            "\n",
            "action probability =  [0.7226890756302521, 0.2773109243697479, 0.0]\n",
            "buy =  0.7226890756302521  sell =  0.2773109243697479\n",
            "trade accuracy =  0.6608695652173913\n",
            "epoch: 2860, total rewards: 284580.000000, mean rewards: 47828.571429\n",
            "\n",
            "action probability =  [0.6386554621848739, 0.36134453781512604, 0.0]\n",
            "buy =  0.6386554621848739  sell =  0.3613445378151261\n",
            "trade accuracy =  0.7043478260869566\n",
            "epoch: 2865, total rewards: 308280.000000, mean rewards: 51811.764706\n",
            "\n",
            "action probability =  [0.6386554621848739, 0.36134453781512604, 0.0]\n",
            "buy =  0.6386554621848739  sell =  0.3613445378151261\n",
            "trade accuracy =  0.7304347826086957\n",
            "epoch: 2870, total rewards: 325140.000000, mean rewards: 54645.378151\n",
            "\n",
            "action probability =  [0.7142857142857143, 0.2857142857142857, 0.0]\n",
            "buy =  0.7142857142857143  sell =  0.2857142857142857\n",
            "trade accuracy =  0.7017543859649122\n",
            "epoch: 2875, total rewards: 302350.000000, mean rewards: 50815.126050\n",
            "\n",
            "action probability =  [0.7058823529411765, 0.29411764705882354, 0.0]\n",
            "buy =  0.7058823529411765  sell =  0.2941176470588235\n",
            "trade accuracy =  0.7105263157894737\n",
            "epoch: 2880, total rewards: 302830.000000, mean rewards: 50895.798319\n",
            "\n",
            "action probability =  [0.6386554621848739, 0.36134453781512604, 0.0]\n",
            "buy =  0.6386554621848739  sell =  0.3613445378151261\n",
            "trade accuracy =  0.7130434782608696\n",
            "epoch: 2885, total rewards: 309170.000000, mean rewards: 51961.344538\n",
            "\n",
            "action probability =  [0.6386554621848739, 0.36134453781512604, 0.0]\n",
            "buy =  0.6386554621848739  sell =  0.3613445378151261\n",
            "trade accuracy =  0.6724137931034483\n",
            "epoch: 2890, total rewards: 295620.000000, mean rewards: 49684.033613\n",
            "\n",
            "action probability =  [0.4789915966386555, 0.5210084033613446, 0.0]\n",
            "buy =  0.4789915966386555  sell =  0.5210084033613445\n",
            "trade accuracy =  0.75\n",
            "epoch: 2895, total rewards: 330880.000000, mean rewards: 55610.084034\n",
            "\n",
            "action probability =  [0.42016806722689076, 0.5798319327731093, 0.0]\n",
            "buy =  0.42016806722689076  sell =  0.5798319327731092\n",
            "trade accuracy =  0.7094017094017094\n",
            "epoch: 2900, total rewards: 247330.000000, mean rewards: 41568.067227\n",
            "\n",
            "action probability =  [0.36134453781512604, 0.6386554621848739, 0.0]\n",
            "buy =  0.36134453781512604  sell =  0.6386554621848739\n",
            "trade accuracy =  0.7606837606837606\n",
            "epoch: 2905, total rewards: 309120.000000, mean rewards: 51952.941176\n",
            "\n",
            "action probability =  [0.3865546218487395, 0.6134453781512605, 0.0]\n",
            "buy =  0.3865546218487395  sell =  0.6134453781512605\n",
            "trade accuracy =  0.7777777777777778\n",
            "epoch: 2910, total rewards: 311720.000000, mean rewards: 52389.915966\n",
            "\n",
            "action probability =  [0.44537815126050423, 0.5546218487394958, 0.0]\n",
            "buy =  0.44537815126050423  sell =  0.5546218487394958\n",
            "trade accuracy =  0.811965811965812\n",
            "epoch: 2915, total rewards: 399580.000000, mean rewards: 67156.302521\n",
            "\n",
            "action probability =  [0.5294117647058824, 0.47058823529411764, 0.0]\n",
            "buy =  0.5294117647058824  sell =  0.47058823529411764\n",
            "trade accuracy =  0.7457627118644068\n",
            "epoch: 2920, total rewards: 348080.000000, mean rewards: 58500.840336\n",
            "\n",
            "action probability =  [0.6386554621848739, 0.36134453781512604, 0.0]\n",
            "buy =  0.6386554621848739  sell =  0.3613445378151261\n",
            "trade accuracy =  0.7068965517241379\n",
            "epoch: 2925, total rewards: 306470.000000, mean rewards: 51507.563025\n",
            "\n",
            "action probability =  [0.773109243697479, 0.226890756302521, 0.0]\n",
            "buy =  0.773109243697479  sell =  0.22689075630252098\n",
            "trade accuracy =  0.5877192982456141\n",
            "epoch: 2930, total rewards: 243970.000000, mean rewards: 41003.361345\n",
            "\n",
            "action probability =  [0.8235294117647058, 0.17647058823529413, 0.0]\n",
            "buy =  0.8235294117647058  sell =  0.17647058823529416\n",
            "trade accuracy =  0.5315315315315315\n",
            "epoch: 2935, total rewards: 210430.000000, mean rewards: 35366.386555\n",
            "\n",
            "action probability =  [0.8319327731092437, 0.16806722689075632, 0.0]\n",
            "buy =  0.8319327731092437  sell =  0.16806722689075626\n",
            "trade accuracy =  0.5225225225225225\n",
            "epoch: 2940, total rewards: 202700.000000, mean rewards: 34067.226891\n",
            "\n",
            "action probability =  [0.7647058823529411, 0.23529411764705882, 0.0]\n",
            "buy =  0.7647058823529411  sell =  0.23529411764705888\n",
            "trade accuracy =  0.5982142857142857\n",
            "epoch: 2945, total rewards: 253940.000000, mean rewards: 42678.991597\n",
            "\n",
            "action probability =  [0.7647058823529411, 0.23529411764705882, 0.0]\n",
            "buy =  0.7647058823529411  sell =  0.23529411764705888\n",
            "trade accuracy =  0.5982142857142857\n",
            "epoch: 2950, total rewards: 256910.000000, mean rewards: 43178.151261\n",
            "\n",
            "action probability =  [0.7394957983193278, 0.2605042016806723, 0.0]\n",
            "buy =  0.7394957983193278  sell =  0.26050420168067223\n",
            "trade accuracy =  0.6607142857142857\n",
            "epoch: 2955, total rewards: 278760.000000, mean rewards: 46850.420168\n",
            "\n",
            "action probability =  [0.7647058823529411, 0.23529411764705882, 0.0]\n",
            "buy =  0.7647058823529411  sell =  0.23529411764705888\n",
            "trade accuracy =  0.6428571428571429\n",
            "epoch: 2960, total rewards: 268620.000000, mean rewards: 45146.218487\n",
            "\n",
            "action probability =  [0.7899159663865546, 0.21008403361344538, 0.0]\n",
            "buy =  0.7899159663865546  sell =  0.2100840336134454\n",
            "trade accuracy =  0.6727272727272727\n",
            "epoch: 2965, total rewards: 269000.000000, mean rewards: 45210.084034\n",
            "\n",
            "action probability =  [0.6890756302521008, 0.31092436974789917, 0.0]\n",
            "buy =  0.6890756302521008  sell =  0.31092436974789917\n",
            "trade accuracy =  0.6982758620689655\n",
            "epoch: 2970, total rewards: 288770.000000, mean rewards: 48532.773109\n",
            "\n",
            "action probability =  [0.5630252100840336, 0.4369747899159664, 0.0]\n",
            "buy =  0.5630252100840336  sell =  0.4369747899159664\n",
            "trade accuracy =  0.7948717948717948\n",
            "epoch: 2975, total rewards: 339190.000000, mean rewards: 57006.722689\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBYzscqhFhUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay = random.sample(agent.memory2, 18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL6J_oP5Gd3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYepHLr81cCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    tree_idx, replay = agent.memory.sample(128)\n",
        "except:\n",
        "    agent.memory = Memory(5000)\n",
        "\n",
        "states = np.array([a[0][0] for a in replay])\n",
        "new_states = np.array([a[0][3] for a in replay])\n",
        "actions = np.array([a[0][1] for a in replay]).reshape((-1, 2))\n",
        "rewards = np.array([a[0][2] for a in replay]).reshape((-1, 1))\n",
        "done = np.array([a[0][-1] for a in replay]).reshape((-1, 1))\n",
        "\n",
        "# target_q = self.sess.run(self.target_q, feed_dict={self.new_state:new_states}).reshape((-1,1))\n",
        "q = agent.sess.run(agent.q,feed_dict={agent.state:states,agent.action:actions})\n",
        "Q = agent.sess.run(agent.q,feed_dict={agent.state:states,agent.action:actions})\n",
        "new_q = agent.sess.run(agent.q_pi,feed_dict={agent.state:new_states})\n",
        "new_target_q = agent.sess.run(agent.target_q_pi, feed_dict={agent.new_state:new_states})\n",
        "\n",
        "for I in range(128):\n",
        "  q[I,np.argmax(actions[I])] = rewards[I] + done[I] * 0.99 * new_target_q[I,np.argmax(new_q[I])]\n",
        "# print(q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0x_7Cm2BjqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbnKMy0urf70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZUTUKDdrOC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_q[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B24qo9_r0NAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = agent.pred\n",
        "pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2yyJPjlw6ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = new_q[2]\n",
        "a = np.abs(a) / np.sum(a)\n",
        "a = softmax(a)\n",
        "# a += 0.2 * np.random.randn(2)\n",
        "# a = (agent.pred + a) / 2\n",
        "# a += 0.3 * np.random.randn(2)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxN-HDtOdM3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a += pred\n",
        "# a /= 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4ULtZKSdvgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.tanh(a)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQzVQmoAwxlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = a.copy()\n",
        "e = np.exp(a) / sum(np.exp(a))\n",
        "# e *= 0.1 * np.random.randn(2)\n",
        "# e = np.sort(e)[::-1]\n",
        "# e *= a\n",
        "e += 0.1 * np.random.randn(2)\n",
        "e"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}