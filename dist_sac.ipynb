{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dist_sac.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/tradingrl/blob/master/dist_sac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBVV8hQizHTI",
        "colab_type": "code",
        "outputId": "5e378dbd-23e8-4f06-c180-fea0d269b357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXQj6liny0Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ape_x import *\n",
        "import os\n",
        "import multiprocessing as mp\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "df = \"audpred60.csv\"\n",
        "\n",
        "_ = shutil.copy(\"/content/drive/My Drive/\"+df,\"/content\")\n",
        "# sac_one_step.ckpt\n",
        "saver_path = \"sac_rsi2.ckpt\"\n",
        "\n",
        "restore = False\n",
        "\n",
        "# if restore == True:\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/\" + saver_path + \".data-00000-of-00001\",\"/content\")\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/\" + saver_path + \".index\",\"/content\")\n",
        "#   _ = shutil.copy(\"/content/drive/My Drive/checkpoint\",\"/content\")\n",
        "  \n",
        "if restore == True:\n",
        "  _ = shutil.copy(\"/content/drive/My Drive/model/\" + saver_path + \".data-00000-of-00001\",\"/content\")\n",
        "  _ = shutil.copy(\"/content/drive/My Drive/model/\"+ saver_path + \".index\",\"/content\")\n",
        "  _ = shutil.copy(\"/content/drive/My Drive/model/checkpoint\",\"/content\")\n",
        "\n",
        "output_size = 2\n",
        "size = 240\n",
        "num_actor = 3\n",
        "mem_size = size * num_actor * 100\n",
        "  \n",
        "def actor_work(queues,epsilon, num):\n",
        "  sess = tf.InteractiveSession()\n",
        "  actor = Actor(df, 5, num, epsilon, sess,STEP_SIZE=size,OUTPUT_SIZE=output_size, save=False, saver_path=saver_path, restore=restore)\n",
        "  actor.run(queues, 10, 1000,200,24,n=4)\n",
        "\n",
        "def leaner_work(queues):\n",
        "        sess = tf.InteractiveSession()\n",
        "        leaner = Leaner(df, 5, sess,mem_size,output_size,'/gpu:0', save=True, saver_path=saver_path, restore=restore,noise=False, norm=False)\n",
        "        leaner.leaner(queues)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FBIJ0z4zKf7",
        "colab_type": "code",
        "outputId": "ce3ad643-dae9-440d-a213-a42bfcfef586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content\n",
        "\n",
        "queue = mp.Queue()\n",
        "ps = [mp.Process(target=leaner_work, args=(queue,))]\n",
        "for i in range(num_actor):\n",
        "  epsilon = 0.0 if i == 0 else np.random.rand()\n",
        "  ps.append(mp.Process(target=actor_work, args=(queue,epsilon,i)))\n",
        "            \n",
        "for p in ps:\n",
        "    p.start()\n",
        "    time.sleep(1)\n",
        "\n",
        "for p in ps:\n",
        "    p.join()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ape_x.py:483: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
            "  return gain.rolling(n).apply(rsiCalc)\n",
            "/content/drive/My Drive/ape_x.py:199: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
            "  return gain.rolling(n).apply(rsiCalc)\n",
            "/content/drive/My Drive/ape_x.py:199: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
            "  return gain.rolling(n).apply(rsiCalc)\n",
            "/content/drive/My Drive/ape_x.py:199: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
            "  return gain.rolling(n).apply(rsiCalc)\n",
            "/content/drive/My Drive/memory.py:127: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  max_weight = (p_min * n) ** (-self.PER_b)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "action probability =  [0.2217573221757322, 0.7782426778242678, 0.0]\n",
            "trade accuracy =  0.47058823529411764\n",
            "epoch: 10, total rewards: 3703.000000, mean rewards: 371.849372\n",
            "action probability =  [0.42677824267782427, 0.5732217573221757, 0.0]\n",
            "trade accuracy =  0.48739495798319327\n",
            "epoch: 20, total rewards: 688.000000, mean rewards: 69.087866\n",
            "action probability =  [0.8577405857740585, 0.14225941422594143, 0.0]\n",
            "trade accuracy =  0.6092436974789915\n",
            "epoch: 30, total rewards: 30996.000000, mean rewards: 3112.569038\n",
            "action probability =  [0.2217573221757322, 0.7782426778242678, 0.0]\n",
            "trade accuracy =  0.4495798319327731\n",
            "epoch: 40, total rewards: -2258.000000, mean rewards: -226.744770\n",
            "action probability =  [0.5439330543933054, 0.4560669456066946, 0.0]\n",
            "trade accuracy =  0.46382978723404256\n",
            "epoch: 50, total rewards: 801.000000, mean rewards: 80.435146\n",
            "action probability =  [0.8577405857740585, 0.14225941422594143, 0.0]\n",
            "trade accuracy =  0.5378151260504201\n",
            "epoch: 60, total rewards: 12198.000000, mean rewards: 1224.903766\n",
            "action probability =  [0.3682008368200837, 0.6317991631799164, 0.0]\n",
            "trade accuracy =  0.35443037974683544\n",
            "epoch: 70, total rewards: -6588.000000, mean rewards: -661.556485\n",
            "action probability =  [0.895397489539749, 0.10460251046025104, 0.0]\n",
            "trade accuracy =  0.5798319327731093\n",
            "epoch: 80, total rewards: 45202.000000, mean rewards: 4539.112971\n",
            "action probability =  [0.6150627615062761, 0.38493723849372385, 0.0]\n",
            "trade accuracy =  0.3739495798319328\n",
            "epoch: 90, total rewards: 3681.000000, mean rewards: 369.640167\n",
            "action probability =  [0.18828451882845187, 0.8117154811715481, 0.0]\n",
            "trade accuracy =  0.40336134453781514\n",
            "epoch: 100, total rewards: -1518.000000, mean rewards: -152.435146\n",
            "action probability =  [0.502092050209205, 0.497907949790795, 0.0]\n",
            "trade accuracy =  0.4831932773109244\n",
            "epoch: 110, total rewards: 1013.000000, mean rewards: 101.723849\n",
            "action probability =  [0.6276150627615062, 0.3723849372384937, 0.0]\n",
            "trade accuracy =  0.47478991596638653\n",
            "epoch: 120, total rewards: -1410.000000, mean rewards: -141.589958\n",
            "action probability =  [0.02510460251046025, 0.9748953974895398, 0.0]\n",
            "trade accuracy =  0.6848739495798319\n",
            "epoch: 130, total rewards: 39792.000000, mean rewards: 3995.849372\n",
            "action probability =  [0.27615062761506276, 0.7238493723849372, 0.0]\n",
            "trade accuracy =  0.5\n",
            "epoch: 140, total rewards: 3711.000000, mean rewards: 372.652720\n",
            "action probability =  [0.7782426778242678, 0.2217573221757322, 0.0]\n",
            "trade accuracy =  0.3659574468085106\n",
            "epoch: 150, total rewards: -9108.000000, mean rewards: -914.610879\n",
            "action probability =  [0.3054393305439331, 0.694560669456067, 0.0]\n",
            "trade accuracy =  0.4495798319327731\n",
            "epoch: 160, total rewards: -1944.000000, mean rewards: -195.213389\n",
            "action probability =  [0.23430962343096234, 0.7656903765690377, 0.0]\n",
            "trade accuracy =  0.4579831932773109\n",
            "epoch: 170, total rewards: 2858.000000, mean rewards: 286.995816\n",
            "action probability =  [0.4811715481171548, 0.5188284518828452, 0.0]\n",
            "trade accuracy =  0.5126050420168067\n",
            "epoch: 180, total rewards: 5512.000000, mean rewards: 553.506276\n",
            "action probability =  [0.37656903765690375, 0.6234309623430963, 0.0]\n",
            "trade accuracy =  0.4579831932773109\n",
            "epoch: 190, total rewards: 932.000000, mean rewards: 93.589958\n",
            "action probability =  [0.20502092050209206, 0.7949790794979079, 0.0]\n",
            "trade accuracy =  0.5588235294117647\n",
            "epoch: 200, total rewards: 12366.000000, mean rewards: 1241.774059\n",
            "action probability =  [0.5523012552301255, 0.4476987447698745, 0.0]\n",
            "trade accuracy =  0.5\n",
            "epoch: 210, total rewards: 16612.000000, mean rewards: 1668.150628\n",
            "action probability =  [0.4476987447698745, 0.5523012552301255, 0.0]\n",
            "trade accuracy =  0.46218487394957986\n",
            "epoch: 220, total rewards: 15565.000000, mean rewards: 1563.012552\n",
            "action probability =  [0.39748953974895396, 0.602510460251046, 0.0]\n",
            "trade accuracy =  0.48739495798319327\n",
            "epoch: 230, total rewards: 20218.000000, mean rewards: 2030.259414\n",
            "action probability =  [0.9414225941422594, 0.058577405857740586, 0.0]\n",
            "trade accuracy =  0.2616033755274262\n",
            "epoch: 240, total rewards: 39012.000000, mean rewards: 3917.523013\n",
            "action probability =  [0.08786610878661087, 0.9121338912133892, 0.0]\n",
            "trade accuracy =  0.42857142857142855\n",
            "epoch: 250, total rewards: 60346.000000, mean rewards: 6059.849372\n",
            "action probability =  [0.5732217573221757, 0.42677824267782427, 0.0]\n",
            "trade accuracy =  0.4641350210970464\n",
            "epoch: 260, total rewards: 7918.000000, mean rewards: 795.112971\n",
            "action probability =  [0.7238493723849372, 0.27615062761506276, 0.0]\n",
            "trade accuracy =  0.4579831932773109\n",
            "epoch: 270, total rewards: 6270.000000, mean rewards: 629.623431\n",
            "action probability =  [0.5523012552301255, 0.4476987447698745, 0.0]\n",
            "trade accuracy =  0.4789915966386555\n",
            "epoch: 280, total rewards: 6380.000000, mean rewards: 640.669456\n",
            "action probability =  [0.3682008368200837, 0.6317991631799164, 0.0]\n",
            "trade accuracy =  0.5361702127659574\n",
            "epoch: 290, total rewards: 19576.000000, mean rewards: 1965.790795\n",
            "action probability =  [0.08786610878661087, 0.9121338912133892, 0.0]\n",
            "trade accuracy =  0.5210084033613446\n",
            "epoch: 300, total rewards: 68910.000000, mean rewards: 6919.832636\n",
            "action probability =  [0.9665271966527197, 0.03347280334728033, 0.0]\n",
            "trade accuracy =  0.20168067226890757\n",
            "epoch: 310, total rewards: -22245.000000, mean rewards: -2233.807531\n",
            "action probability =  [0.8368200836820083, 0.16317991631799164, 0.0]\n",
            "trade accuracy =  0.39915966386554624\n",
            "epoch: 320, total rewards: -1419.000000, mean rewards: -142.493724\n",
            "action probability =  [0.14644351464435146, 0.8535564853556485, 0.0]\n",
            "trade accuracy =  0.6244725738396625\n",
            "epoch: 330, total rewards: 38478.000000, mean rewards: 3863.899582\n",
            "action probability =  [0.3472803347280335, 0.6527196652719666, 0.0]\n",
            "trade accuracy =  0.5756302521008403\n",
            "epoch: 340, total rewards: 21395.000000, mean rewards: 2148.451883\n",
            "action probability =  [0.6234309623430963, 0.37656903765690375, 0.0]\n",
            "trade accuracy =  0.5630252100840336\n",
            "epoch: 350, total rewards: 14572.000000, mean rewards: 1463.297071\n",
            "action probability =  [0.4476987447698745, 0.5523012552301255, 0.0]\n",
            "trade accuracy =  0.5630252100840336\n",
            "epoch: 360, total rewards: 16751.000000, mean rewards: 1682.108787\n",
            "action probability =  [0.7782426778242678, 0.2217573221757322, 0.0]\n",
            "trade accuracy =  0.5042016806722689\n",
            "epoch: 370, total rewards: 7164.000000, mean rewards: 719.397490\n",
            "action probability =  [0.41841004184100417, 0.5815899581589958, 0.0]\n",
            "trade accuracy =  0.5840336134453782\n",
            "epoch: 380, total rewards: 15611.000000, mean rewards: 1567.631799\n",
            "action probability =  [0.8075313807531381, 0.19246861924686193, 0.0]\n",
            "trade accuracy =  0.542016806722689\n",
            "epoch: 390, total rewards: 7908.000000, mean rewards: 794.108787\n",
            "action probability =  [0.5564853556485355, 0.4435146443514644, 0.0]\n",
            "trade accuracy =  0.459915611814346\n",
            "epoch: 400, total rewards: 2852.000000, mean rewards: 286.393305\n",
            "action probability =  [0.6820083682008368, 0.3179916317991632, 0.0]\n",
            "trade accuracy =  0.42857142857142855\n",
            "epoch: 410, total rewards: 3924.000000, mean rewards: 394.041841\n",
            "action probability =  [0.9581589958158996, 0.04184100418410042, 0.0]\n",
            "trade accuracy =  0.592436974789916\n",
            "epoch: 420, total rewards: 32292.000000, mean rewards: 3242.711297\n",
            "action probability =  [0.5188284518828452, 0.4811715481171548, 0.0]\n",
            "trade accuracy =  0.3697478991596639\n",
            "epoch: 430, total rewards: -1447.000000, mean rewards: -145.305439\n",
            "action probability =  [0.5104602510460251, 0.4895397489539749, 0.0]\n",
            "trade accuracy =  0.42616033755274263\n",
            "epoch: 440, total rewards: -2692.000000, mean rewards: -270.326360\n",
            "action probability =  [0.899581589958159, 0.100418410041841, 0.0]\n",
            "trade accuracy =  0.42016806722689076\n",
            "epoch: 450, total rewards: 5216.000000, mean rewards: 523.782427\n",
            "action probability =  [0.012552301255230125, 0.9874476987447699, 0.0]\n",
            "trade accuracy =  0.6848739495798319\n",
            "epoch: 460, total rewards: 99051.000000, mean rewards: 9946.543933\n",
            "action probability =  [0.39748953974895396, 0.602510460251046, 0.0]\n",
            "trade accuracy =  0.48739495798319327\n",
            "epoch: 470, total rewards: 6376.000000, mean rewards: 640.267782\n",
            "action probability =  [0.7489539748953975, 0.2510460251046025, 0.0]\n",
            "trade accuracy =  0.42016806722689076\n",
            "epoch: 480, total rewards: 6725.000000, mean rewards: 675.313808\n",
            "action probability =  [0.6694560669456067, 0.3305439330543933, 0.0]\n",
            "trade accuracy =  0.3755274261603376\n",
            "epoch: 490, total rewards: -225.000000, mean rewards: -22.594142\n",
            "action probability =  [0.606694560669456, 0.39330543933054396, 0.0]\n",
            "trade accuracy =  0.36554621848739494\n",
            "epoch: 500, total rewards: -4519.000000, mean rewards: -453.790795\n",
            "action probability =  [0.2217573221757322, 0.7782426778242678, 0.0]\n",
            "trade accuracy =  0.42857142857142855\n",
            "epoch: 510, total rewards: 12673.000000, mean rewards: 1272.602510\n",
            "action probability =  [0.6736401673640168, 0.3263598326359833, 0.0]\n",
            "trade accuracy =  0.46638655462184875\n",
            "epoch: 520, total rewards: 8138.000000, mean rewards: 817.205021\n",
            "action probability =  [0.4225941422594142, 0.5774058577405857, 0.0]\n",
            "trade accuracy =  0.46218487394957986\n",
            "epoch: 530, total rewards: 3772.000000, mean rewards: 378.778243\n",
            "action probability =  [0.5774058577405857, 0.4225941422594142, 0.0]\n",
            "trade accuracy =  0.44537815126050423\n",
            "epoch: 540, total rewards: 3155.000000, mean rewards: 316.820084\n",
            "action probability =  [0.7154811715481172, 0.28451882845188287, 0.0]\n",
            "trade accuracy =  0.5042016806722689\n",
            "epoch: 550, total rewards: 20404.000000, mean rewards: 2048.937238\n",
            "action probability =  [0.37656903765690375, 0.6234309623430963, 0.0]\n",
            "trade accuracy =  0.46218487394957986\n",
            "epoch: 560, total rewards: 7791.000000, mean rewards: 782.359833\n",
            "action probability =  [0.07112970711297072, 0.9288702928870293, 0.0]\n",
            "trade accuracy =  0.592436974789916\n",
            "epoch: 570, total rewards: 58620.000000, mean rewards: 5886.527197\n",
            "action probability =  [0.8242677824267782, 0.17573221757322174, 0.0]\n",
            "trade accuracy =  0.3949579831932773\n",
            "epoch: 580, total rewards: 19158.000000, mean rewards: 1923.815900\n",
            "action probability =  [0.8493723849372385, 0.1506276150627615, 0.0]\n",
            "trade accuracy =  0.3067226890756303\n",
            "epoch: 590, total rewards: 10377.000000, mean rewards: 1042.041841\n",
            "action probability =  [0.6903765690376569, 0.30962343096234307, 0.0]\n",
            "trade accuracy =  0.5084033613445378\n",
            "epoch: 600, total rewards: 19931.000000, mean rewards: 2001.439331\n",
            "action probability =  [0.3472803347280335, 0.6527196652719666, 0.0]\n",
            "trade accuracy =  0.48523206751054854\n",
            "epoch: 610, total rewards: 9269.000000, mean rewards: 930.778243\n",
            "action probability =  [0.22594142259414227, 0.7740585774058577, 0.0]\n",
            "trade accuracy =  0.4641350210970464\n",
            "epoch: 620, total rewards: 11625.000000, mean rewards: 1167.364017\n",
            "action probability =  [0.3682008368200837, 0.6317991631799164, 0.0]\n",
            "trade accuracy =  0.5021097046413502\n",
            "epoch: 630, total rewards: 8996.000000, mean rewards: 903.364017\n",
            "action probability =  [0.33472803347280333, 0.6652719665271967, 0.0]\n",
            "trade accuracy =  0.4810126582278481\n",
            "epoch: 640, total rewards: 6340.000000, mean rewards: 636.652720\n",
            "action probability =  [0.6527196652719666, 0.3472803347280335, 0.0]\n",
            "trade accuracy =  0.5210084033613446\n",
            "epoch: 650, total rewards: 7098.000000, mean rewards: 712.769874\n",
            "action probability =  [0.9790794979079498, 0.02092050209205021, 0.0]\n",
            "trade accuracy =  0.7521008403361344\n",
            "epoch: 660, total rewards: 146689.000000, mean rewards: 14730.276151\n",
            "action probability =  [0.7238493723849372, 0.27615062761506276, 0.0]\n",
            "trade accuracy =  0.4579831932773109\n",
            "epoch: 670, total rewards: 8372.000000, mean rewards: 840.702929\n",
            "action probability =  [0.0502092050209205, 0.9497907949790795, 0.0]\n",
            "trade accuracy =  0.5210084033613446\n",
            "epoch: 680, total rewards: 54372.000000, mean rewards: 5459.949791\n",
            "action probability =  [0.2175732217573222, 0.7824267782426778, 0.0]\n",
            "trade accuracy =  0.47058823529411764\n",
            "epoch: 690, total rewards: 6944.000000, mean rewards: 697.305439\n",
            "action probability =  [0.41422594142259417, 0.5857740585774058, 0.0]\n",
            "trade accuracy =  0.5084033613445378\n",
            "epoch: 700, total rewards: 10081.000000, mean rewards: 1012.317992\n",
            "action probability =  [0.2594142259414226, 0.7405857740585774, 0.0]\n",
            "trade accuracy =  0.39915966386554624\n",
            "epoch: 710, total rewards: -637.000000, mean rewards: -63.966527\n",
            "action probability =  [0.8661087866108786, 0.13389121338912133, 0.0]\n",
            "trade accuracy =  0.5588235294117647\n",
            "epoch: 720, total rewards: 21034.000000, mean rewards: 2112.200837\n",
            "action probability =  [0.5732217573221757, 0.42677824267782427, 0.0]\n",
            "trade accuracy =  0.542016806722689\n",
            "epoch: 730, total rewards: 7594.000000, mean rewards: 762.577406\n",
            "action probability =  [0.20920502092050208, 0.7907949790794979, 0.0]\n",
            "trade accuracy =  0.542016806722689\n",
            "epoch: 740, total rewards: 7057.000000, mean rewards: 708.652720\n",
            "action probability =  [0.33472803347280333, 0.6652719665271967, 0.0]\n",
            "trade accuracy =  0.5504201680672269\n",
            "epoch: 750, total rewards: 7152.000000, mean rewards: 718.192469\n",
            "action probability =  [0.9079497907949791, 0.09205020920502092, 0.0]\n",
            "trade accuracy =  0.6890756302521008\n",
            "epoch: 760, total rewards: 37091.000000, mean rewards: 3724.619247\n",
            "action probability =  [0.8577405857740585, 0.14225941422594143, 0.0]\n",
            "trade accuracy =  0.6470588235294118\n",
            "epoch: 770, total rewards: 30482.000000, mean rewards: 3060.953975\n",
            "action probability =  [0.39330543933054396, 0.606694560669456, 0.0]\n",
            "trade accuracy =  0.6092436974789915\n",
            "epoch: 780, total rewards: 8774.000000, mean rewards: 881.071130\n",
            "action probability =  [0.26359832635983266, 0.7364016736401674, 0.0]\n",
            "trade accuracy =  0.6134453781512605\n",
            "epoch: 790, total rewards: 11711.000000, mean rewards: 1176.000000\n",
            "action probability =  [0.36401673640167365, 0.6359832635983264, 0.0]\n",
            "trade accuracy =  0.6092436974789915\n",
            "epoch: 800, total rewards: 10726.000000, mean rewards: 1077.087866\n",
            "action probability =  [0.4602510460251046, 0.5397489539748954, 0.0]\n",
            "trade accuracy =  0.5168067226890757\n",
            "epoch: 810, total rewards: 6758.000000, mean rewards: 678.627615\n",
            "action probability =  [0.3514644351464435, 0.6485355648535565, 0.0]\n",
            "trade accuracy =  0.5294117647058824\n",
            "epoch: 820, total rewards: 15875.000000, mean rewards: 1594.142259\n",
            "action probability =  [0.9497907949790795, 0.0502092050209205, 0.0]\n",
            "trade accuracy =  0.6176470588235294\n",
            "epoch: 830, total rewards: 80785.000000, mean rewards: 8112.301255\n",
            "action probability =  [0.24267782426778242, 0.7573221757322176, 0.0]\n",
            "trade accuracy =  0.5210084033613446\n",
            "epoch: 840, total rewards: 24447.000000, mean rewards: 2454.928870\n",
            "action probability =  [0.029288702928870293, 0.9707112970711297, 0.0]\n",
            "trade accuracy =  0.5168067226890757\n",
            "epoch: 850, total rewards: 224377.000000, mean rewards: 22531.581590\n",
            "action probability =  [0.7238493723849372, 0.27615062761506276, 0.0]\n",
            "trade accuracy =  0.4495798319327731\n",
            "epoch: 860, total rewards: 12368.000000, mean rewards: 1241.974895\n",
            "action probability =  [0.9665271966527197, 0.03347280334728033, 0.0]\n",
            "trade accuracy =  0.542016806722689\n",
            "epoch: 870, total rewards: 80135.000000, mean rewards: 8047.029289\n",
            "action probability =  [0.33472803347280333, 0.6652719665271967, 0.0]\n",
            "trade accuracy =  0.5316455696202531\n",
            "epoch: 880, total rewards: 15971.000000, mean rewards: 1603.782427\n",
            "action probability =  [0.24267782426778242, 0.7573221757322176, 0.0]\n",
            "trade accuracy =  0.47478991596638653\n",
            "epoch: 890, total rewards: 10943.000000, mean rewards: 1098.878661\n",
            "action probability =  [0.24686192468619247, 0.7531380753138075, 0.0]\n",
            "trade accuracy =  0.5210084033613446\n",
            "epoch: 900, total rewards: 27582.000000, mean rewards: 2769.740586\n",
            "action probability =  [0.02092050209205021, 0.9790794979079498, 0.0]\n",
            "trade accuracy =  0.7563025210084033\n",
            "epoch: 910, total rewards: 105083.000000, mean rewards: 10552.267782\n",
            "action probability =  [0.8200836820083682, 0.1799163179916318, 0.0]\n",
            "trade accuracy =  0.4495798319327731\n",
            "epoch: 920, total rewards: -2204.000000, mean rewards: -221.322176\n",
            "action probability =  [0.5732217573221757, 0.42677824267782427, 0.0]\n",
            "trade accuracy =  0.4327731092436975\n",
            "epoch: 930, total rewards: -2363.000000, mean rewards: -237.288703\n",
            "action probability =  [0.6569037656903766, 0.34309623430962344, 0.0]\n",
            "trade accuracy =  0.38235294117647056\n",
            "epoch: 940, total rewards: -5100.000000, mean rewards: -512.133891\n",
            "action probability =  [0.28451882845188287, 0.7154811715481172, 0.0]\n",
            "trade accuracy =  0.5168067226890757\n",
            "epoch: 950, total rewards: 9037.000000, mean rewards: 907.481172\n",
            "action probability =  [0.7322175732217573, 0.26778242677824265, 0.0]\n",
            "trade accuracy =  0.42016806722689076\n",
            "epoch: 960, total rewards: -3640.000000, mean rewards: -365.523013\n",
            "action probability =  [0.3514644351464435, 0.6485355648535565, 0.0]\n",
            "trade accuracy =  0.5423728813559322\n",
            "epoch: 970, total rewards: 9159.000000, mean rewards: 919.732218\n",
            "action probability =  [0.6527196652719666, 0.3472803347280335, 0.0]\n",
            "trade accuracy =  0.3739495798319328\n",
            "epoch: 980, total rewards: -2983.000000, mean rewards: -299.548117\n",
            "action probability =  [0.8326359832635983, 0.16736401673640167, 0.0]\n",
            "trade accuracy =  0.5462184873949579\n",
            "epoch: 990, total rewards: 2335.000000, mean rewards: 234.476987\n",
            "action probability =  [0.7531380753138075, 0.24686192468619247, 0.0]\n",
            "trade accuracy =  0.5630252100840336\n",
            "epoch: 1000, total rewards: 5085.000000, mean rewards: 510.627615\n",
            "action probability =  [0.46443514644351463, 0.5355648535564853, 0.0]\n",
            "trade accuracy =  0.5084033613445378\n",
            "epoch: 1010, total rewards: 9671.000000, mean rewards: 971.146444\n",
            "action probability =  [0.008368200836820083, 0.9916317991631799, 0.0]\n",
            "trade accuracy =  0.8571428571428571\n",
            "epoch: 1020, total rewards: 239364.000000, mean rewards: 24036.552301\n",
            "action probability =  [0.6150627615062761, 0.38493723849372385, 0.0]\n",
            "trade accuracy =  0.5210084033613446\n",
            "epoch: 1030, total rewards: 13061.000000, mean rewards: 1311.564854\n",
            "action probability =  [0.5146443514644351, 0.48535564853556484, 0.0]\n",
            "trade accuracy =  0.5378151260504201\n",
            "epoch: 1040, total rewards: 14360.000000, mean rewards: 1442.008368\n",
            "action probability =  [0.6192468619246861, 0.3807531380753138, 0.0]\n",
            "trade accuracy =  0.5588235294117647\n",
            "epoch: 1050, total rewards: 14396.000000, mean rewards: 1445.623431\n",
            "action probability =  [0.15481171548117154, 0.8451882845188284, 0.0]\n",
            "trade accuracy =  0.47478991596638653\n",
            "epoch: 1060, total rewards: 37464.000000, mean rewards: 3762.075314\n",
            "action probability =  [0.3138075313807531, 0.6861924686192469, 0.0]\n",
            "trade accuracy =  0.5\n",
            "epoch: 1070, total rewards: 17017.000000, mean rewards: 1708.820084\n",
            "action probability =  [0.8577405857740585, 0.14225941422594143, 0.0]\n",
            "trade accuracy =  0.36554621848739494\n",
            "epoch: 1080, total rewards: -2735.000000, mean rewards: -274.644351\n",
            "action probability =  [0.99581589958159, 0.0041841004184100415, 0.0]\n",
            "trade accuracy =  0.08403361344537816\n",
            "epoch: 1090, total rewards: -39084.000000, mean rewards: -3924.753138\n",
            "action probability =  [0.6443514644351465, 0.35564853556485354, 0.0]\n",
            "trade accuracy =  0.5147679324894515\n",
            "epoch: 1100, total rewards: 10615.000000, mean rewards: 1065.941423\n",
            "action probability =  [0.24686192468619247, 0.7531380753138075, 0.0]\n",
            "trade accuracy =  0.5252100840336135\n",
            "epoch: 1110, total rewards: 6796.000000, mean rewards: 682.443515\n",
            "action probability =  [0.21338912133891214, 0.7866108786610879, 0.0]\n",
            "trade accuracy =  0.5294117647058824\n",
            "epoch: 1120, total rewards: 24290.000000, mean rewards: 2439.163180\n",
            "action probability =  [0.49372384937238495, 0.5062761506276151, 0.0]\n",
            "trade accuracy =  0.5126050420168067\n",
            "epoch: 1130, total rewards: 16688.000000, mean rewards: 1675.782427\n",
            "action probability =  [0.7447698744769874, 0.25523012552301255, 0.0]\n",
            "trade accuracy =  0.4369747899159664\n",
            "epoch: 1140, total rewards: 8035.000000, mean rewards: 806.861925\n",
            "action probability =  [0.8577405857740585, 0.14225941422594143, 0.0]\n",
            "trade accuracy =  0.40336134453781514\n",
            "epoch: 1150, total rewards: 5510.000000, mean rewards: 553.305439\n",
            "action probability =  [0.5774058577405857, 0.4225941422594142, 0.0]\n",
            "trade accuracy =  0.4369747899159664\n",
            "epoch: 1160, total rewards: 4891.000000, mean rewards: 491.146444\n",
            "action probability =  [0.11715481171548117, 0.8828451882845189, 0.0]\n",
            "trade accuracy =  0.5546218487394958\n",
            "epoch: 1170, total rewards: 16948.000000, mean rewards: 1701.891213\n",
            "action probability =  [0.13807531380753138, 0.8619246861924686, 0.0]\n",
            "trade accuracy =  0.5756302521008403\n",
            "epoch: 1180, total rewards: 15171.000000, mean rewards: 1523.447699\n",
            "action probability =  [0.9288702928870293, 0.07112970711297072, 0.0]\n",
            "trade accuracy =  0.38235294117647056\n",
            "epoch: 1190, total rewards: -5309.000000, mean rewards: -533.121339\n",
            "action probability =  [0.7615062761506276, 0.2384937238493724, 0.0]\n",
            "trade accuracy =  0.4789915966386555\n",
            "epoch: 1200, total rewards: 4574.000000, mean rewards: 459.313808\n",
            "action probability =  [0.8242677824267782, 0.17573221757322174, 0.0]\n",
            "trade accuracy =  0.3686440677966102\n",
            "epoch: 1210, total rewards: -6305.000000, mean rewards: -633.138075\n",
            "action probability =  [0.8242677824267782, 0.17573221757322174, 0.0]\n",
            "trade accuracy =  0.5296610169491526\n",
            "epoch: 1220, total rewards: 10286.000000, mean rewards: 1032.903766\n",
            "action probability =  [0.6443514644351465, 0.35564853556485354, 0.0]\n",
            "trade accuracy =  0.6244725738396625\n",
            "epoch: 1230, total rewards: 7055.000000, mean rewards: 708.451883\n",
            "action probability =  [0.22594142259414227, 0.7740585774058577, 0.0]\n",
            "trade accuracy =  0.4579831932773109\n",
            "epoch: 1240, total rewards: -6484.000000, mean rewards: -651.112971\n",
            "action probability =  [0.401673640167364, 0.5983263598326359, 0.0]\n",
            "trade accuracy =  0.4957983193277311\n",
            "epoch: 1250, total rewards: -2814.000000, mean rewards: -282.577406\n",
            "action probability =  [0.7238493723849372, 0.27615062761506276, 0.0]\n",
            "trade accuracy =  0.6033755274261603\n",
            "epoch: 1260, total rewards: 10297.000000, mean rewards: 1034.008368\n",
            "action probability =  [0.9037656903765691, 0.09623430962343096, 0.0]\n",
            "trade accuracy =  0.5672268907563025\n",
            "epoch: 1270, total rewards: 20171.000000, mean rewards: 2025.539749\n",
            "action probability =  [0.9288702928870293, 0.07112970711297072, 0.0]\n",
            "trade accuracy =  0.5840336134453782\n",
            "epoch: 1280, total rewards: 22702.000000, mean rewards: 2279.698745\n",
            "action probability =  [0.9623430962343096, 0.03765690376569038, 0.0]\n",
            "trade accuracy =  0.634453781512605\n",
            "epoch: 1290, total rewards: 65693.000000, mean rewards: 6596.786611\n",
            "action probability =  [0.15481171548117154, 0.8451882845188284, 0.0]\n",
            "trade accuracy =  0.5126050420168067\n",
            "epoch: 1300, total rewards: 4149.000000, mean rewards: 416.635983\n",
            "action probability =  [0.12552301255230125, 0.8744769874476988, 0.0]\n",
            "trade accuracy =  0.5882352941176471\n",
            "epoch: 1310, total rewards: 48322.000000, mean rewards: 4852.418410\n",
            "action probability =  [0.5857740585774058, 0.41422594142259417, 0.0]\n",
            "trade accuracy =  0.5063291139240507\n",
            "epoch: 1320, total rewards: 8533.000000, mean rewards: 856.870293\n",
            "action probability =  [0.19246861924686193, 0.8075313807531381, 0.0]\n",
            "trade accuracy =  0.5840336134453782\n",
            "epoch: 1330, total rewards: 49228.000000, mean rewards: 4943.397490\n",
            "action probability =  [0.3514644351464435, 0.6485355648535565, 0.0]\n",
            "trade accuracy =  0.540084388185654\n",
            "epoch: 1340, total rewards: 33600.000000, mean rewards: 3374.058577\n",
            "action probability =  [0.8451882845188284, 0.15481171548117154, 0.0]\n",
            "trade accuracy =  0.35294117647058826\n",
            "epoch: 1350, total rewards: 1323.000000, mean rewards: 132.853556\n",
            "action probability =  [0.28870292887029286, 0.7112970711297071, 0.0]\n",
            "trade accuracy =  0.5611814345991561\n",
            "epoch: 1360, total rewards: 40088.000000, mean rewards: 4025.573222\n",
            "action probability =  [0.2928870292887029, 0.7071129707112971, 0.0]\n",
            "trade accuracy =  0.5504201680672269\n",
            "epoch: 1370, total rewards: 27447.000000, mean rewards: 2756.184100\n",
            "action probability =  [0.502092050209205, 0.497907949790795, 0.0]\n",
            "trade accuracy =  0.5147679324894515\n",
            "epoch: 1380, total rewards: 11215.000000, mean rewards: 1126.192469\n",
            "action probability =  [0.5104602510460251, 0.4895397489539749, 0.0]\n",
            "trade accuracy =  0.5780590717299579\n",
            "epoch: 1390, total rewards: 16441.000000, mean rewards: 1650.979079\n",
            "action probability =  [0.4351464435146444, 0.5648535564853556, 0.0]\n",
            "trade accuracy =  0.4767932489451477\n",
            "epoch: 1400, total rewards: 12263.000000, mean rewards: 1231.430962\n",
            "action probability =  [0.3054393305439331, 0.694560669456067, 0.0]\n",
            "trade accuracy =  0.4789915966386555\n",
            "epoch: 1410, total rewards: 33982.000000, mean rewards: 3412.418410\n",
            "action probability =  [0.28870292887029286, 0.7112970711297071, 0.0]\n",
            "trade accuracy =  0.4810126582278481\n",
            "epoch: 1420, total rewards: 27517.000000, mean rewards: 2763.213389\n",
            "action probability =  [0.899581589958159, 0.100418410041841, 0.0]\n",
            "trade accuracy =  0.6428571428571429\n",
            "epoch: 1430, total rewards: 86921.000000, mean rewards: 8728.468619\n",
            "action probability =  [0.6443514644351465, 0.35564853556485354, 0.0]\n",
            "trade accuracy =  0.6386554621848739\n",
            "epoch: 1440, total rewards: 46640.000000, mean rewards: 4683.514644\n",
            "action probability =  [0.3263598326359833, 0.6736401673640168, 0.0]\n",
            "trade accuracy =  0.5294117647058824\n",
            "epoch: 1450, total rewards: 36625.000000, mean rewards: 3677.824268\n",
            "action probability =  [0.32217573221757323, 0.6778242677824268, 0.0]\n",
            "trade accuracy =  0.5254237288135594\n",
            "epoch: 1460, total rewards: 36717.000000, mean rewards: 3687.062762\n",
            "action probability =  [0.09205020920502092, 0.9079497907949791, 0.0]\n",
            "trade accuracy =  0.6260504201680672\n",
            "epoch: 1470, total rewards: 84655.000000, mean rewards: 8500.920502\n",
            "action probability =  [0.3472803347280335, 0.6527196652719666, 0.0]\n",
            "trade accuracy =  0.5210084033613446\n",
            "epoch: 1480, total rewards: 16065.000000, mean rewards: 1613.221757\n",
            "action probability =  [0.698744769874477, 0.301255230125523, 0.0]\n",
            "trade accuracy =  0.5294117647058824\n",
            "epoch: 1490, total rewards: 36100.000000, mean rewards: 3625.104603\n",
            "action probability =  [0.9623430962343096, 0.03765690376569038, 0.0]\n",
            "trade accuracy =  0.5714285714285714\n",
            "epoch: 1500, total rewards: 164471.000000, mean rewards: 16515.916318\n",
            "action probability =  [0.17573221757322174, 0.8242677824267782, 0.0]\n",
            "trade accuracy =  0.4831932773109244\n",
            "epoch: 1510, total rewards: 19265.000000, mean rewards: 1934.560669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoY9bXh69UtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def f(q):\n",
        "  for i in range(100):\n",
        "    rand = np.random.RandomState()\n",
        "    if rand.rand() < 0.2:\n",
        "      action = rand.choice(3, p=(0.2,0.3,0.5))\n",
        "      print(i)\n",
        "      print(action)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    q = Queue()\n",
        "    p = Process(target=f, args=(q,))\n",
        "    p.start()\n",
        "    p.join()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfAKRJrCaZFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.asanyarray([[1,1,1,1],[0,0,0,0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IABToLrT_8YF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = [i[0][0] for i in a]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuA8kBwRAVBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "import urllib.parse\n",
        "\n",
        "\n",
        "url = 'https://www.googleapis.com/drive/v2/files/trash'\n",
        "f = urllib.request.urlopen(url)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}